{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd36754b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:15<00:00,  5.01s/it]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"../src/\")\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from handcrafted_features import DocBasedFeatureExtractor, Doc2VecChunkVectorizer, CorpusBasedFeatureExtractor\n",
    "from utils import get_doc_paths, read_labels\n",
    "\n",
    "raw_docs_dir = \"../data/raw_docs/\"\n",
    "labels_dir = \"../data/labels/\"\n",
    "extracted_features_dir = \"../data/extracted_features/\"\n",
    "\n",
    "lang = \"eng\"\n",
    "doc_paths = get_doc_paths(raw_docs_dir, lang)[:3]\n",
    "\n",
    "sentences_per_chunk = 200\n",
    "# d2vcv = Doc2VecChunkVectorizer(lang, sentences_per_chunk)\n",
    "# d2vcv.fit_transform(doc_paths)\n",
    "\n",
    "\n",
    "all_chunk_based_features = []\n",
    "all_book_based_features = []\n",
    "all_average_sbert_sentence_embeddings = []\n",
    "all_doc2vec_chunk_embeddings = []\n",
    "for doc_path in tqdm(doc_paths):\n",
    "    fe = DocBasedFeatureExtractor(lang, doc_path, sentences_per_chunk)\n",
    "    chunk_based_features, book_based_features, average_sbert_sentence_embeddings, doc2vec_chunk_embeddings = fe.get_all_features()\n",
    "    all_chunk_based_features.extend(chunk_based_features)\n",
    "    all_book_based_features.append(book_based_features)\n",
    "    all_average_sbert_sentence_embeddings.append(average_sbert_sentence_embeddings)\n",
    "    all_doc2vec_chunk_embeddings.append(doc2vec_chunk_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d94ca86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:00<00:00,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/raw_docs/eng/Radcliffe_Ann_The-Italian_1797.txt\n",
      "../data/raw_docs/eng/Gissing_George_In-the-Year-of-Jubilee_1894.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.83it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/raw_docs/eng/Collins_Wilkie_Armadale_1864.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  8.07it/s]\n"
     ]
    }
   ],
   "source": [
    "cbfe = CorpusBasedFeatureExtractor(lang, doc_paths, all_average_sbert_sentence_embeddings=None, all_doc2vec_chunk_embeddings=None)\n",
    "all_corpus_based_features = cbfe.get_all_features(k=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db6cdc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.010713\n",
      "1    0.010713\n",
      "2    0.010713\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# book name x words\n",
    "mfws = all_corpus_based_features\n",
    "print(mfws.std(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc7911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# absolute values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eebd099",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zscore() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a384fcfd8a21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMFWTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'zscore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-a384fcfd8a21>\u001b[0m in \u001b[0;36mget_normalization\u001b[0;34m(self, normalization)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'zscore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0mnormalized_mfws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnormalization\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalized_mfws\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: zscore() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "class MFWTable():\n",
    "    def __init__(self, mfws):\n",
    "        # book name x words\n",
    "        self.mfws = mfws.set_index('book_name', drop=True)\n",
    "        self.normalized = {}\n",
    "\n",
    "    def get_normalization(self, normalization):\n",
    "        \n",
    "        def zscore(self):\n",
    "            normalized_mfws = (self.mfws - self.mfws.mean(axis=0))/self.mfws.std(axis=0)\n",
    "            return normalized_mfws\n",
    "        \n",
    "        if normalization in self.normalized:\n",
    "            normalized_mfws = self.normalized[normalization]\n",
    "        else:\n",
    "            if normalization == 'zscore':\n",
    "                normalized_mfws = zscore()\n",
    "        \n",
    "        self.normalized[normalization] = normalized_mfws\n",
    "        return normalized_mfws\n",
    "    \n",
    "n = MFWTable(mfws)\n",
    "n.get_normalization('zscore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09714aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _FunctionRegistry():\n",
    "    def __init__():\n",
    "        self.deltas = {}\n",
    "        \n",
    "    def add_delta(self, delta):\n",
    "        self.deltas[delta.name] = delta\n",
    "        \n",
    "    \n",
    "registry = _FunctionRegistry()\n",
    "\n",
    "class Delta():\n",
    "    def __init__(self, name, normalization, distance):\n",
    "        self.name = name\n",
    "        self.normalization = normalization\n",
    "        self.distance = distance\n",
    "        # register when instantiated\n",
    "        registry.add_delta(self)\n",
    "        \n",
    "    # call from registry with argument\n",
    "    def __call__(self, mfws):\n",
    "        df = pd.DataFrame(index=corpus.index, columns=corpus.index)\n",
    "        for a, b in combinations(df.index, 2):\n",
    "            delta = self.distance(corpus.loc[a,:], corpus.loc[b,:], *args, **kwargs)\n",
    "            df.at[a, b] = delta\n",
    "            df.at[b, a] = delta\n",
    "        return df.fillna(0)\n",
    "    \n",
    "    def prepare(self, corpus):\n",
    "        for normalization in self.normalizations:\n",
    "            corpus = normalization(corpus)\n",
    "        return corpus\n",
    "\n",
    "    def __call__(self, corpus):\n",
    "        return self.create_result(self.basis(self.prepare(corpus)), corpus)\n",
    "\n",
    "        \n",
    "Delta('Burrows', 'zscore', 'manhattan')\n",
    "for delta in registry:\n",
    "    delta(mfws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6b9dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "book_df = pd.DataFrame(all_book_based_features)\n",
    "book_df = book_df.merge(all_corpus_based_features, on=\"book_name\")\n",
    "book_and_averaged_chunk_df = book_df.merge(pd.DataFrame(all_chunk_based_features).groupby(\"book_name\").mean().reset_index(drop=False), on=\"book_name\")\n",
    "\n",
    "chunk_df = pd.DataFrame(all_chunk_based_features)\n",
    "chunk_and_copied_book_df = chunk_df.merge(pd.DataFrame(all_book_based_features), on=\"book_name\")\n",
    "chunk_and_copied_book_df = chunk_and_copied_book_df.merge(all_corpus_based_features, on=\"book_name\")\n",
    "\n",
    "os.makedirs(f\"{extracted_features_dir}/{lang}\", exist_ok=True)\n",
    "book_df.to_csv(f\"{extracted_features_dir}/{lang}/book_df.csv\", index=False)\n",
    "book_and_averaged_chunk_df.to_csv(f\"{extracted_features_dir}/{lang}/book_and_averaged_chunk_df.csv\", index=False)\n",
    "chunk_df.to_csv(f\"{extracted_features_dir}/{lang}/chunk_df.csv\", index=False)\n",
    "chunk_and_copied_book_df.to_csv(f\"{extracted_features_dir}/{lang}/chunk_and_copied_book_df.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1fcae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../src/\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "extracted_features_dir = \"../data/extracted_features/\"\n",
    "labels_dir = \"../data/labels/\"\n",
    "lang = \"eng\"\n",
    "\n",
    "book_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/book_df.csv\")\n",
    "book_and_averaged_chunk_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/book_and_averaged_chunk_df.csv\")\n",
    "chunk_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/chunk_df.csv\")\n",
    "chunk_and_copied_book_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/chunk_and_copied_book_df.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
