{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "546165c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_pickle_paths' from 'utils' (../src/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9c2ed1a2de90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_doc_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_pickle_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mraw_docs_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../data/raw_docs/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_pickle_paths' from 'utils' (../src/utils.py)"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"../src/\")\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from process import BertProcessor\n",
    "from utils import get_doc_paths, get_pickle_paths, read_labels\n",
    "\n",
    "raw_docs_dir = \"../data/raw_docs/\"\n",
    "labels_dir = \"../data/labels/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48c9020",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d361103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lang = \"eng\"\n",
    "raw_doc_paths = get_doc_paths(raw_docs_dir, lang)\n",
    "bp = BertProcessor(lang=lang, pad=False)\n",
    "bp.process(raw_doc_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f20d58a",
   "metadata": {},
   "source": [
    "# Create Bert Document Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d740178f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lang = \"eng\"\n",
    "bv = BertVectorizer(lang=lang, sentence_to_doc_agg=\"mean\")\n",
    "pickle_paths = get_pickle_paths(\"../data/processed_bert_512_tokens_not_padded/\", lang)\n",
    "bv.fit(pickle_paths)\n",
    "doc_vectors = bv.get_doc_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469b7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = doc_vectors.copy()\n",
    "labels = read_labels(lang)\n",
    "df['y'] = df[\"pickle_path\"].apply(lambda x: labels[x.split(\"/\")[-1][:-7]])\n",
    "df['book_name'] = df['pickle_path'].apply(lambda x: x.split(\"/\")[-1][:-7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e2f670",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c2f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = df.drop(columns=['y', 'book_name', 'pickle_path']).values\n",
    "y = df[\"y\"].values.ravel()\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "for index, (train_indices, validation_indices) in enumerate(kf.split(X)):\n",
    "    train_X = X[train_indices, :]\n",
    "    train_y = y[train_indices]\n",
    "    validation_X = X[validation_indices, :]\n",
    "    validation_y = y[validation_indices]\n",
    "    pca = PCA(n_components=30)\n",
    "    train_X = pca.fit_transform(train_X)\n",
    "    print(pca.explained_variance_ratio_.sum())\n",
    "    validation_X = pca.transform(validation_X)\n",
    "    model = SVR(C=40)\n",
    "    model.fit(train_X, train_y)\n",
    "    train_yhat = model.predict(train_X)\n",
    "    validation_yhat = model.predict(validation_X) # np.array([train_yhat.mean()] * validation_X.shape[0]) # \n",
    "    all_labels.extend(validation_y.tolist())\n",
    "    all_predictions.extend(validation_yhat.tolist())\n",
    "    train_mse = mean_squared_error(train_y, train_yhat)\n",
    "    train_mae = mean_absolute_error(train_y, train_yhat)\n",
    "    validation_mse = mean_squared_error(validation_y, validation_yhat)\n",
    "    validation_mae = mean_absolute_error(validation_y, validation_yhat)\n",
    "    print(f\"Fold: {index+1}, TrainMSE: {train_mse}, TrainMAE: {train_mae}, ValMSE: {validation_mse}, ValMAE: {validation_mae}\")\n",
    "all_labels = np.array(all_labels)\n",
    "all_predictions = np.array(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de15788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.scatter(all_labels, all_predictions)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8d6ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
