{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15df4db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsentiment file names for eng/ger\\nMerge labels and features depending on how labels are aggregated if there are multiple scores for a work.\\ndrop_column reset index???\\nchunk based features?\\ncomplexity features\\ntake out doc2vec_chunk_embedding from default drop columns\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "sentiment file names for eng/ger\n",
    "Merge labels and features depending on how labels are aggregated if there are multiple scores for a work.\n",
    "drop_column reset index???\n",
    "chunk based features?\n",
    "complexity features\n",
    "take out doc2vec_chunk_embedding from default drop columns\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c12bfc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../src/\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "extracted_features_dir = \"../data/extracted_features/\"\n",
    "results_dir = \"../data/results/\"\n",
    "sentiment_dir = \"../data/evaluationscore/\"\n",
    "canonization_labels_dir = \"/home/annina/scripts/great_unread_nlp/data/labels/\"\n",
    "lang = \"eng\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2696499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, f1_score, confusion_matrix\n",
    "from xgboost import XGBRegressor\n",
    "from copy import deepcopy\n",
    "from scipy.stats import pearsonr\n",
    "from utils import read_sentiment_scores, read_library_scores\n",
    "from math import sqrt\n",
    "get_ipython().run_line_magic(\"matplotlib\", \"inline\") # %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import statistics\n",
    "import datetime\n",
    "import random\n",
    "random.seed(9)\n",
    "\n",
    "labels = read_sentiment_scores(sentiment_dir, canonization_labels_dir, lang)\n",
    "library_scores = read_library_scores(sentiment_dir, canonization_labels_dir, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4594ed42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_name</th>\n",
       "      <th>y</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austen_Jane_Pride-and-Prejudice_1813</td>\n",
       "      <td>0.029731</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austen_Jane_Sense-and-Sensibility_1811</td>\n",
       "      <td>0.049103</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barrie_J-M_Auld-Licht-Idylls_1888</td>\n",
       "      <td>0.016107</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barrie_J-M_Sentimental-Tommy_1896</td>\n",
       "      <td>0.038327</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Beerbohm_Max_Zuleika-Dobson_1911</td>\n",
       "      <td>0.053656</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Wollstonecraft_Mary_Mary_1788</td>\n",
       "      <td>0.040233</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Scott_Walter_The-Black-Dwarf_1816</td>\n",
       "      <td>-0.021840</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Beckford_William_Vathek_1786</td>\n",
       "      <td>0.006286</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Radcliffe_Ann_Udolpho_1794</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Smollett_Tobias_Humphry-Clinker_1771</td>\n",
       "      <td>0.010482</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  book_name         y  c\n",
       "1      Austen_Jane_Pride-and-Prejudice_1813  0.029731  3\n",
       "2    Austen_Jane_Sense-and-Sensibility_1811  0.049103  3\n",
       "3         Barrie_J-M_Auld-Licht-Idylls_1888  0.016107  3\n",
       "4         Barrie_J-M_Sentimental-Tommy_1896  0.038327  3\n",
       "5          Beerbohm_Max_Zuleika-Dobson_1911  0.053656  3\n",
       "..                                      ...       ... ..\n",
       "148           Wollstonecraft_Mary_Mary_1788  0.040233  3\n",
       "170       Scott_Walter_The-Black-Dwarf_1816 -0.021840  2\n",
       "177            Beckford_William_Vathek_1786  0.006286  2\n",
       "234              Radcliffe_Ann_Udolpho_1794  0.004301  2\n",
       "241    Smollett_Tobias_Humphry-Clinker_1771  0.010482  2\n",
       "\n",
       "[191 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93415ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 in labels[\"c\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "764429a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197\n"
     ]
    }
   ],
   "source": [
    "## Labels statistics\n",
    "print(len(pd.unique(labels[\"book_name\"]))) #197\n",
    "\n",
    "# 254 labels, 197 different book_names -> 57 second/third... reviews\n",
    "# 36 book_names with more than 1 label, these 36 book_names have 93 labels\n",
    "# 93 = 36 first reviews + 57 second/third... reviews\n",
    "# 6 texts with opposing reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "933bfe04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels[\"y\"].plot.hist(grid=True, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b1785d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression(object):\n",
    "    def __init__(self, language, features, drop_columns_including, dimensionality_reduction, model_param, model, verbose):\n",
    "        assert isinstance(drop_columns_including, list)\n",
    "        for i in drop_columns_including:\n",
    "            assert isinstance(i, str)\n",
    "        assert (dimensionality_reduction in [\"k_best_f_reg_0_10\", \"k_best_mutual_info_0_10\", \"ss_pca_0_95\"]) or (dimensionality_reduction is None)\n",
    "        self._check_class_specific_assertions()\n",
    "        \n",
    "        self.language = language\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.labels = self._prepare_labels()\n",
    "        self.drop_columns_including = drop_columns_including\n",
    "        self.dimensionality_reduction = dimensionality_reduction\n",
    "        self.model_param = model_param\n",
    "        self.model = model\n",
    "        self.verbose = verbose\n",
    "        self.datetime = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "        if self.features == \"book\":\n",
    "            self.df = deepcopy(book_df)\n",
    "        elif self.features == \"chunk\":\n",
    "            self.df = deepcopy(chunk_df)\n",
    "        elif self.features == \"chunk_and_copied_book\":\n",
    "            self.df = deepcopy(chunk_and_copied_book_df)\n",
    "        elif self.features == \"book_and_averaged_chunk\":\n",
    "            self.df = deepcopy(book_and_averaged_chunk_df)\n",
    "\n",
    "        columns_before_drop = set(self.df.columns)\n",
    "        if self.drop_columns_including:\n",
    "            self.df = self.df[[column for column in self.df.columns if not self._drop_column(column)]].reset_index(drop=True)\n",
    "        columns_after_drop = set(self.df.columns)\n",
    "        if self.verbose:\n",
    "            print(f\"Dropped {len(columns_before_drop - columns_after_drop)} columns.\")\n",
    "            \n",
    "    def _check_class_specific_assertions(self):\n",
    "        assert model in [\"xgboost\", \"svr\", \"lasso\"]\n",
    "        assert features in [\"book\", \"chunk\", \"book_and_averaged_chunk\", \"chunk_and_copied_book\"]\n",
    "    \n",
    "    def _prepare_labels(self):\n",
    "        return self.labels.drop(columns=\"c\")\n",
    "\n",
    "    def _drop_column(self, column):\n",
    "        for string in self.drop_columns_including:\n",
    "            if string in column:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def _custom_pca(self, train_X):\n",
    "        for i in range(5, train_X.shape[1], int((train_X.shape[1] - 5) / 10)):\n",
    "            pca = PCA(n_components=i)\n",
    "            new_train_X = pca.fit_transform(train_X)\n",
    "            if pca.explained_variance_ratio_.sum() >= 0.95:\n",
    "                break\n",
    "        return new_train_X, pca\n",
    "\n",
    "    def _select_features(self, train_X, train_y, validation_X):\n",
    "        if self.dimensionality_reduction == \"ss_pca_0_95\":\n",
    "            ss = StandardScaler()\n",
    "            train_X = ss.fit_transform(train_X)\n",
    "            validation_X = ss.transform(validation_X)\n",
    "            train_X, pca = self._custom_pca(train_X)\n",
    "            validation_X = pca.transform(validation_X)\n",
    "        elif self.dimensionality_reduction == \"k_best_f_reg_0_10\":\n",
    "            k_best = SelectKBest(f_regression, k=np.minimum(int(0.10 * train_X.shape[0]), train_X.shape[1]))\n",
    "            train_X = k_best.fit_transform(train_X, train_y)\n",
    "            validation_X = k_best.transform(validation_X)\n",
    "        elif self.dimensionality_reduction == \"k_best_mutual_info_0_10\":\n",
    "            k_best = SelectKBest(mutual_info_regression, k=np.minimum(int(0.10 * train_X.shape[0]), train_X.shape[1]))\n",
    "            train_X = k_best.fit_transform(train_X, train_y)\n",
    "            validation_X = k_best.transform(validation_X)\n",
    "        elif self.dimensionality_reduction is None:\n",
    "            pass\n",
    "        return train_X, validation_X\n",
    "    \n",
    "    def _impute(self, train_X, validation_X):\n",
    "        imputer = KNNImputer()\n",
    "        train_X = imputer.fit_transform(train_X)\n",
    "        validation_X = imputer.transform(validation_X)\n",
    "        return train_X, validation_X\n",
    "    \n",
    "    def _get_model(self, model_param):\n",
    "        # if any of these performs better than others, we can try to tune the hyperparameters\n",
    "        # but I think for now it\"s more important to see which approach performs better\n",
    "        # chunk based or doc based\n",
    "        # use dimensionality reduction or not...\n",
    "        if self.model == \"xgboost\": #1,0.25,2\n",
    "            return XGBRegressor(n_estimators=1000, max_depth=model_param, learning_rate=0.01, colsample_bytree=0.33, min_child_weight=6) #max_depth=4\n",
    "        elif self.model == \"svr\":\n",
    "            return SVR(C=model_param)\n",
    "        elif self.model == \"lasso\":\n",
    "            return Lasso(alpha=model_param)\n",
    "        elif self.model == \"svc\":\n",
    "            return SVC(C=model_param)\n",
    "        \n",
    "    def _split_booknames(self, df, nr_splits):\n",
    "        \"\"\"\n",
    "        Distribute book names over splits.\n",
    "        All works of an author are in the same split.\n",
    "        \"\"\"\n",
    "        book_names = df[\"book_name\"].unique()\n",
    "        authors = []\n",
    "        booknames_authors_mapping = {}\n",
    "\n",
    "        #Get authors\n",
    "        for book_name in book_names:\n",
    "            author = \"_\".join(book_name.split(\"_\")[:2])\n",
    "            authors.append(author)\n",
    "            if author in booknames_authors_mapping:\n",
    "                booknames_authors_mapping[author].append(book_name)\n",
    "            else:\n",
    "                booknames_authors_mapping[author] = []\n",
    "                booknames_authors_mapping[author].append(book_name)\n",
    "        #Distribute authors over splits so that each split has approximately the same number of books\n",
    "        works_per_author = Counter(authors)\n",
    "        goal_sum = round(len(book_names)/nr_splits)\n",
    "        tolerance = 0.03\n",
    "        lower_threshold = goal_sum - round(tolerance*goal_sum)\n",
    "        upper_threshold = goal_sum + round(tolerance*goal_sum)\n",
    "        author_splits = []\n",
    "        popped_dict = {}\n",
    "\n",
    "        for i in range (0, nr_splits-1):\n",
    "            works_in_split = 0\n",
    "            split = []\n",
    "            curr_author_workcount = 0\n",
    "\n",
    "            # take values from popped dict first\n",
    "            if bool(popped_dict):  \n",
    "                popped = []\n",
    "                for curr_author, curr_author_workcount in popped_dict.items():\n",
    "                    # leave item in popped dict if value is too big\n",
    "                    if works_in_split + curr_author_workcount > upper_threshold:\n",
    "                        continue\n",
    "                    else:\n",
    "                        popped.append(curr_author)\n",
    "                        split.append(curr_author)\n",
    "                        works_in_split += curr_author_workcount\n",
    "                        if works_in_split >= lower_threshold:\n",
    "                            break\n",
    "                for current_author in popped:\n",
    "                    del popped_dict[current_author]\n",
    "            while works_in_split < upper_threshold:\n",
    "                if bool(works_per_author):\n",
    "                    curr_author = random.choice(list(works_per_author.keys()))\n",
    "                    curr_author_workcount = works_per_author.pop(curr_author)\n",
    "                    # Put values into separate dict if too big\n",
    "                    if works_in_split + curr_author_workcount > upper_threshold:\n",
    "                        popped_dict[curr_author] = curr_author_workcount\n",
    "                    else:\n",
    "                        split.append(curr_author)\n",
    "                        works_in_split += curr_author_workcount\n",
    "                        if works_in_split >= lower_threshold:\n",
    "                            break\n",
    "                else:\n",
    "                    #ignore upper threshold\n",
    "                    popped = []\n",
    "                    for curr_author, curr_author_workcount in popped_dict.items():\n",
    "                        popped.append(curr_author)\n",
    "                        split.append(curr_author)\n",
    "                        works_in_split += curr_author_workcount\n",
    "                        if works_in_split >= lower_threshold:\n",
    "                            break\n",
    "                    for current_author in popped:\n",
    "                        del popped_dict[current_author]\n",
    "\n",
    "            author_splits.append(split)\n",
    "        #Create last split directly from remaining dict\n",
    "        works_in_last_split = sum(works_per_author.values()) + sum(popped_dict.values())\n",
    "        split = list(works_per_author.keys()) + list(popped_dict.keys())\n",
    "        author_splits.append(split)\n",
    "\n",
    "        #Map author splits to book names\n",
    "        book_splits = []\n",
    "        for author_split in author_splits:\n",
    "            book_split = []\n",
    "            for author in author_split:\n",
    "                book_split.extend(booknames_authors_mapping[author])\n",
    "            book_splits.append(book_split)\n",
    "        return book_splits\n",
    "    \n",
    "    def _combine_df_labels(self, df):\n",
    "        #Average of sentiscores per book\n",
    "        agg_labels = self.labels.groupby(by=\"book_name\", as_index=False).mean()\n",
    "        df = df.merge(right=agg_labels, on=\"book_name\", how=\"inner\", validate=\"many_to_one\")\n",
    "        return df\n",
    "    \n",
    "    def run(self):\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "\n",
    "        train_mses = []\n",
    "        train_maes = []\n",
    "        train_r2s = []\n",
    "        train_corrs = []\n",
    "        \n",
    "        validation_mses = []\n",
    "        validation_maes = []\n",
    "        validation_r2s = []\n",
    "        validation_corrs = []\n",
    "        validation_corr_pvalues = []\n",
    "\n",
    "        df = self.df\n",
    "        df = self._combine_df_labels(df)\n",
    "        book_names_split = self._split_booknames(df, 5)\n",
    "        all_validation_books = []\n",
    "\n",
    "        for index, split in enumerate(book_names_split):\n",
    "            train_df = df[~df[\"book_name\"].isin(split)]\n",
    "            validation_df = df[df[\"book_name\"].isin(split)]\n",
    "            \n",
    "            train_X = train_df.drop(columns=[\"y\", \"book_name\"]).values\n",
    "            train_y = train_df[\"y\"].values.ravel()\n",
    "            validation_X = validation_df.drop(columns=[\"y\", \"book_name\"]).values\n",
    "            validation_y = validation_df[\"y\"].values.ravel()\n",
    "            train_X, validation_X = self._impute(train_X, validation_X)\n",
    "            #if self.verbose:\n",
    "            #    print(f\"train_X.shape before {self.dimensionality_reduction}: {train_X.shape}, validation_X.shape before {self.dimensionality_reduction}: {validation_X.shape}\")\n",
    "            train_X, validation_X = self._select_features(train_X, train_y, validation_X)\n",
    "            #if self.verbose:\n",
    "            #    print(f\"train_X.shape after {self.dimensionality_reduction}: {train_X.shape}, validation_X.shape after {self.dimensionality_reduction}: {validation_X.shape}\")\n",
    "            model = self._get_model(self.model_param)\n",
    "            model.fit(train_X, train_y)\n",
    "            \n",
    "            train_books = deepcopy(train_df[[\"book_name\", \"y\"]])\n",
    "            train_books[\"yhat\"] = model.predict(train_X)\n",
    "            validation_books = deepcopy(validation_df[[\"book_name\", \"y\"]])\n",
    "            validation_books[\"yhat\"] = model.predict(validation_X)\n",
    "            \n",
    "            train_books = train_books.groupby(\"book_name\").mean()\n",
    "            validation_books = validation_books.groupby(\"book_name\").mean()\n",
    "            all_validation_books.append(validation_books.reset_index())\n",
    "            \n",
    "            train_y = train_books[\"y\"].tolist()\n",
    "            train_yhat = train_books[\"yhat\"].tolist()\n",
    "            validation_y = validation_books[\"y\"].tolist()\n",
    "            validation_yhat = validation_books[\"yhat\"].tolist()\n",
    "            \n",
    "            all_labels.extend(validation_y)\n",
    "            all_predictions.extend(validation_yhat)\n",
    "            \n",
    "            train_mse = mean_squared_error(train_y, train_yhat)\n",
    "            train_mae = mean_absolute_error(train_y, train_yhat)\n",
    "            train_r2 = r2_score(train_y, train_yhat)\n",
    "            train_corr = pearsonr(train_y, train_yhat)[0]\n",
    "            \n",
    "            validation_mse = mean_squared_error(validation_y, validation_yhat)\n",
    "            validation_mae = mean_absolute_error(validation_y, validation_yhat)\n",
    "            validation_r2 = r2_score(validation_y, validation_yhat)\n",
    "            validation_corr = pearsonr(validation_y, validation_yhat)[0]\n",
    "            p_value = pearsonr(validation_y, validation_yhat)[1]\n",
    "            \n",
    "            train_mses.append(train_mse)\n",
    "            train_maes.append(train_mae)\n",
    "            train_r2s.append(train_r2)\n",
    "            train_corrs.append(train_corr)\n",
    "            \n",
    "            validation_mses.append(validation_mse)\n",
    "            validation_maes.append(validation_mae)\n",
    "            validation_r2s.append(validation_r2)\n",
    "            validation_corrs.append(validation_corr)\n",
    "            validation_corr_pvalues.append(p_value)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"Fold: {index+1}, TrainMSE: {np.round(train_mse, 3)}, TrainMAE: {np.round(train_mae, 3)}, ValMSE: {np.round(validation_mse, 3)}, ValMAE: {np.round(validation_mae, 3)}, ValR2: {np.round(validation_r2, 3)}, ValCorr: {np.round(validation_corr, 3)}\")\n",
    "        all_labels = np.array(all_labels)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        \n",
    "        # Save y and y_pred for examples\n",
    "        pd.concat(all_validation_books).to_csv(results_dir + \"/y-yhat-\" + self.language + \"-\" + self.datetime + \".csv\", index=False)\n",
    "        \n",
    "        mean_train_mse = np.mean(train_mses)\n",
    "        mean_train_rmse = np.mean([sqrt(x) for x in train_mses])\n",
    "        mean_train_mae = np.mean(train_maes)\n",
    "        mean_train_r2 = np.mean(train_r2s)\n",
    "        mean_train_corr = np.mean(train_corrs)\n",
    "        \n",
    "        mean_validation_mse = np.mean(validation_mses)\n",
    "        mean_validation_rmse = np.mean([sqrt(x) for x in validation_mses])\n",
    "        mean_validation_mae = np.mean(validation_maes)\n",
    "        mean_validation_r2 = np.mean(validation_r2s)\n",
    "        mean_validation_corr = np.mean(validation_corrs)\n",
    "        mean_p_value = self._get_pvalue(validation_corr_pvalues)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\"\"TrainMSE: {np.round(mean_train_mse, 3)}, TrainRMSE: {np.round(mean_train_rmse, 3)}, TrainMAE: {np.round(mean_train_mae, 3)}, TrainR2: {np.round(mean_train_r2, 3)}, TrainCorr: {np.round(mean_train_corr, 3)}, ValMSE: {np.round(mean_validation_mse, 3)}, ValRMSE: {np.round(mean_validation_rmse, 3)}, ValMAE: {np.round(mean_validation_mae, 3)}, ValR2: {np.round(mean_validation_r2, 3)}, ValCorr: {np.round(mean_validation_corr, 3)}, ValCorrPValue: {np.round(mean_p_value, 3)}\"\"\")\n",
    "            print(\"\\n---------------------------------------------------\\n\")\n",
    "            plt.figure(figsize=(4,4))\n",
    "            plt.xticks(fontsize=15)\n",
    "            plt.yticks(fontsize=15)\n",
    "            plt.xlim([0,1])\n",
    "            plt.ylim([0,1])\n",
    "\n",
    "            plt.scatter(all_labels, all_predictions, s=6)\n",
    "            plt.xlabel(\"Canonization Scores\", fontsize=20)\n",
    "            plt.ylabel(\"Predicted Scores\", fontsize=20)\n",
    "            plt.savefig(results_dir + lang + \"-\" + self.model + \"-\" + str(self.dimensionality_reduction) \n",
    "            + \"-\" + self.features + \"-\" + \"-\" + \"param\" + str(self.model_param) + \"-\" + self.datetime + \".png\", \n",
    "            dpi=400, bbox_inches=\"tight\")    \n",
    "    \n",
    "            plt.show();\n",
    "        return mean_train_mse, mean_train_rmse, mean_train_mae, mean_train_r2, mean_train_corr, mean_validation_mse, mean_validation_rmse, mean_validation_mae, mean_validation_r2, mean_validation_corr, mean_p_value, self.datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340d71a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Classification into reviewed/not reviewed\n",
    "'''\n",
    "\n",
    "class Classification(Regression):\n",
    "    def __init__(self, language, features, drop_columns_including, dimensionality_reduction, model_param, model, verbose):\n",
    "        super().__init__(language, features, drop_columns_including, dimensionality_reduction, model_param, model, verbose)\n",
    "\n",
    "    def _check_class_specific_assertions(self):\n",
    "        assert model in [\"svc\"]\n",
    "        assert features in [\"book\", \"chunk\", \"book_and_averaged_chunk\", \"chunk_and_copied_book\"]\n",
    "        \n",
    "    def _prepare_labels(self):\n",
    "        labels = self.labels.drop(columns=\"y\").rename(columns={\"c\":\"y\"})\n",
    "        labels = labels.replace(to_replace={\"positive\": 3, \"not_classified\": 2, \"negative\": 1})\n",
    "        labels = labels.drop_duplicates(subset=\"book_name\")\n",
    "        return labels\n",
    "        \n",
    "    def _combine_df_labels(self, df):\n",
    "        #Reviews zum englischen Korpus beginnnen mit 1759 und decken alles bis 1914 ab\n",
    "        agg_labels = self.labels[[\"book_name\"]].drop_duplicates()\n",
    "        agg_labels[\"y\"] = 1\n",
    "        df = df.merge(right=agg_labels, on=\"book_name\", how=\"left\", validate=\"many_to_one\")\n",
    "        df[\"y\"] = df[\"y\"].fillna(value=0)\n",
    "        #Select books written after 1759 (year of first review)\n",
    "        year = df[\"book_name\"].str.replace('-', '_').str.split('_').str[-1].astype('int64')\n",
    "        df = df.loc[year>=1759]\n",
    "        return df\n",
    "    \n",
    "    def _get_sample_weights(self, df):\n",
    "        # Weight \n",
    "        chunks_per_book = df[\"book_name\"].value_counts(sort=False).rename('chunks_per_book')\n",
    "        chunks_per_book = chunks_per_book.reset_index().rename(columns={\"index\":'book_name'})\n",
    "        chunks_per_book[\"chunks_per_book\"] = 1/chunks_per_book[\"chunks_per_book\"]\n",
    "        df = df.merge(right=chunks_per_book, how=\"left\", on=\"book_name\")\n",
    "        print(df)\n",
    "        sample_weights = df[\"chunks_per_book\"].tolist()\n",
    "        return sample_weights\n",
    "    \n",
    "    def _aggregate_chunk_predictions(self, df):\n",
    "        g = df.groupby(\"book_name\") \n",
    "        \n",
    "        # Majority vote\n",
    "        # If one value is more common, assign it to every chunk\n",
    "        # Therefore, accuracy is either 0 or 1\n",
    "        # If both values are equally likely, leave them unchanged, and accuracy is 0.5\n",
    "        def _get_mode_accuracy(group):\n",
    "            counts = group[\"yhat\"].value_counts()\n",
    "            if len(counts) == 1:\n",
    "                mode_acc = counts.index[0]\n",
    "            else:\n",
    "                mode_acc = 0.5\n",
    "            return mode_acc\n",
    "        mode_accs = g.apply(_get_mode_accuracy).rename(\"mode_acc\").reset_index() \n",
    "        mode_acc = mode_accs[\"mode_acc\"].mean()\n",
    "        \n",
    "        # Average accuracy within book\n",
    "        book_acc = g.apply(lambda group: accuracy_score(group[\"y\"], group[\"yhat\"])).mean()\n",
    "        #Accuracy when each chunk is treated as single document\n",
    "        chunk_acc = accuracy_score(df[\"y\"], df[\"yhat\"])#, sample_weight = self._get_sample_weights(df))\n",
    "        return {\"mode_acc\": mode_acc, \"book_acc\": book_acc, \"chunk_acc\": chunk_acc}\n",
    "        \n",
    "    def run(self):\n",
    "        train_accs = []\n",
    "        validation_accs = []\n",
    "\n",
    "        df = self.df\n",
    "        df = self._combine_df_labels(df)\n",
    "        book_names_split = self._split_booknames(df, 5)\n",
    "        all_validation_books = []\n",
    "\n",
    "        for index, split in enumerate(book_names_split):\n",
    "            train_df = df[~df[\"book_name\"].isin(split)]\n",
    "            validation_df = df[df[\"book_name\"].isin(split)]\n",
    "            \n",
    "            train_X = train_df.drop(columns=[\"y\", \"book_name\"]).values\n",
    "            train_y = train_df[\"y\"].values.ravel()\n",
    "            validation_X = validation_df.drop(columns=[\"y\", \"book_name\"]).values\n",
    "            validation_y = validation_df[\"y\"].values.ravel()\n",
    "            train_X, validation_X = self._impute(train_X, validation_X)\n",
    "            #if self.verbose:\n",
    "            #    print(f\"train_X.shape before {self.dimensionality_reduction}: {train_X.shape}, validation_X.shape before {self.dimensionality_reduction}: {validation_X.shape}\")\n",
    "            train_X, validation_X = self._select_features(train_X, train_y, validation_X)\n",
    "            #if self.verbose:\n",
    "            #    print(f\"train_X.shape after {self.dimensionality_reduction}: {train_X.shape}, validation_X.shape after {self.dimensionality_reduction}: {validation_X.shape}\")\n",
    "            model = self._get_model(self.model_param)\n",
    "            model.fit(train_X, train_y)\n",
    "            \n",
    "            train_books = deepcopy(train_df[[\"book_name\", \"y\"]])\n",
    "            train_books[\"yhat\"] = model.predict(train_X)\n",
    "            train_acc = self._aggregate_chunk_predictions(train_books)\n",
    "            validation_books = deepcopy(validation_df[[\"book_name\", \"y\"]])\n",
    "            validation_books[\"yhat\"] = model.predict(validation_X)\n",
    "            validation_acc = self._aggregate_chunk_predictions(validation_books)\n",
    "            \n",
    "            all_validation_books.append(validation_books)\n",
    "            \n",
    "            train_accs.append(train_acc)\n",
    "            validation_accs.append(validation_acc)\n",
    "            if self.verbose:\n",
    "                print(f\"Fold: {index+1}, TrainAcc: {np.round(train_acc, 3)}, ValAcc: {np.round(validation_acc, 3)}\")\n",
    "        \n",
    "        # Save y and y_pred for examples\n",
    "        all_validation_books = pd.concat(all_validation_books)\n",
    "        all_validation_books.to_csv(results_dir + \"/valiationbooks-class-\" + self.language + \"-\" + self.datetime + \".csv\", index=False)\n",
    "        \n",
    "        print(confusion_matrix(all_validation_books[\"y\"], all_validation_books[\"yhat\"]))\n",
    "        print(pd.crosstab(all_validation_books[\"y\"], all_validation_books[\"yhat\"], rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "                \n",
    "        train_accs = pd.DataFrame(train_accs)\n",
    "        validation_accs = pd.DataFrame(validation_accs)\n",
    "        \n",
    "        mean_train_mode_acc = train_accs[\"mode_acc\"].mean()\n",
    "        mean_train_book_acc = train_accs[\"book_acc\"].mean()\n",
    "        mean_train_chunk_acc = train_accs[\"chunk_acc\"].mean()\n",
    "        mean_validation_mode_acc = validation_accs[\"mode_acc\"].mean()\n",
    "        mean_validation_book_acc = validation_accs[\"book_acc\"].mean()\n",
    "        mean_validation_chunk_acc = validation_accs[\"chunk_acc\"].mean()\n",
    "        print(mean_train_mode_acc, mean_train_book_acc, mean_train_chunk_acc)\n",
    "        print(mean_validation_mode_acc, mean_validation_book_acc, mean_validation_chunk_acc)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\"\"TrainAcc: {np.round(mean_train_acc, 3)}, ValidationAcc: {np.round(mean_validation_acc, 3)}\"\"\")\n",
    "            print(\"\\n---------------------------------------------------\\n\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9de317b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Classification into in library/not in library\n",
    "'''\n",
    "\n",
    "class LibraryClassification(Classification):\n",
    "    def _prepare_labels(self):\n",
    "        return self.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0170865",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Classification into not reviewed/negative/not classified/positive\n",
    "'''\n",
    "\n",
    "class MulticlassClassification(Regression):\n",
    "    def __init__(self, language, features, drop_columns_including, dimensionality_reduction, model_param, model, verbose):\n",
    "        super().__init__(language, features, drop_columns_including, dimensionality_reduction, model_param, model, verbose)\n",
    "\n",
    "    def _check_class_specific_assertions(self):\n",
    "        assert model in [\"svc\"]\n",
    "        assert features in [\"book\", \"book_and_averaged_chunk\"]\n",
    "        \n",
    "    def _prepare_labels(self):\n",
    "        labels = self.labels.drop(columns=\"y\").rename(columns={\"c\":\"y\"})\n",
    "        return labels\n",
    "        \n",
    "    def _combine_df_labels(self, df):\n",
    "        #Reviews zum englischen Korpus beginnnen mit 1759 und decken alles bis 1914 ab\n",
    "        df = df.merge(right=self.labels, on=\"book_name\", how=\"left\", validate=\"many_to_one\")\n",
    "        df[\"y\"] = df[\"y\"].fillna(value=0)#(value=\"not_reviewed\")\n",
    "        #Select books written after 1759 (year of first review)\n",
    "        year = df[\"book_name\"].str.replace('-', '_').str.split('_').str[-1].astype('int64')\n",
    "        print(year)\n",
    "        df = df.loc[year>=1759]\n",
    "        return df\n",
    "    \n",
    "    def _get_sample_weights(self, df):\n",
    "        # Weight \n",
    "        chunks_per_book = df[\"book_name\"].value_counts(sort=False).rename('chunks_per_book')\n",
    "        chunks_per_book = chunks_per_book.reset_index().rename(columns={\"index\":'book_name'})\n",
    "        chunks_per_book[\"chunks_per_book\"] = 1/chunks_per_book[\"chunks_per_book\"]\n",
    "        df = df.merge(right=chunks_per_book, how=\"left\", on=\"book_name\")\n",
    "        sample_weights = df[\"chunks_per_book\"].tolist()\n",
    "        return sample_weights\n",
    "    \n",
    "    def _evaluate_predictions(self, df):\n",
    "        score = f1_score(df[\"y\"], df[\"yhat\"], average='macro')\n",
    "        return score\n",
    "        \n",
    "    def run(self):\n",
    "        train_f1s = []\n",
    "        validation_f1s = []\n",
    "\n",
    "        df = self.df\n",
    "        df = self._combine_df_labels(df)\n",
    "        book_names_split = self._split_booknames(df, 10)\n",
    "        all_validation_books = []\n",
    "\n",
    "        for index, split in enumerate(book_names_split):\n",
    "            train_df = df[~df[\"book_name\"].isin(split)]\n",
    "            validation_df = df[df[\"book_name\"].isin(split)]\n",
    "            \n",
    "            train_X = train_df.drop(columns=[\"y\", \"book_name\"]).values\n",
    "            train_y = train_df[\"y\"].values.ravel()\n",
    "            validation_X = validation_df.drop(columns=[\"y\", \"book_name\"]).values\n",
    "            validation_y = validation_df[\"y\"].values.ravel()\n",
    "            train_X, validation_X = self._impute(train_X, validation_X)\n",
    "            #if self.verbose:\n",
    "            #    print(f\"train_X.shape before {self.dimensionality_reduction}: {train_X.shape}, validation_X.shape before {self.dimensionality_reduction}: {validation_X.shape}\")\n",
    "            train_X, validation_X = self._select_features(train_X, train_y, validation_X)\n",
    "            #if self.verbose:\n",
    "            #    print(f\"train_X.shape after {self.dimensionality_reduction}: {train_X.shape}, validation_X.shape after {self.dimensionality_reduction}: {validation_X.shape}\")\n",
    "            model = SVC(C=self.model_param, class_weight='balanced')\n",
    "            model.fit(train_X, train_y)\n",
    "            \n",
    "            train_books = deepcopy(train_df[[\"book_name\", \"y\"]])\n",
    "            train_books[\"yhat\"] = model.predict(train_X)\n",
    "            train_f1 = self._evaluate_predictions(train_books)\n",
    "            validation_books = deepcopy(validation_df[[\"book_name\", \"y\"]])\n",
    "            validation_books[\"yhat\"] = model.predict(validation_X)\n",
    "            validation_f1 = self._evaluate_predictions(validation_books)\n",
    "            all_validation_books.append(validation_books)\n",
    "            \n",
    "            train_f1s.append(train_f1)\n",
    "            validation_f1s.append(validation_f1)\n",
    "            if self.verbose:\n",
    "                print(f\"Fold: {index+1}, TrainF1: {np.round(train_f1, 3)}, ValF1: {np.round(validation_f1, 3)}\")\n",
    "        \n",
    "        # Save y and y_pred for examples\n",
    "        all_validation_books = pd.concat(all_validation_books)\n",
    "        all_validation_books.to_csv(results_dir + \"/valiationbooks-class-\" + self.language + \"-\" + self.datetime + \".csv\", index=False)\n",
    "        \n",
    "        print(confusion_matrix(all_validation_books[\"y\"], all_validation_books[\"yhat\"]))\n",
    "        print(pd.crosstab(all_validation_books[\"y\"], all_validation_books[\"yhat\"], rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "        mean_train_f1 = statistics.mean(train_f1s)\n",
    "        mean_validation_f1 = statistics.mean(validation_f1s)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\"\"TrainF1: {np.round(mean_train_f1, 3)}, ValidationF1: {np.round(mean_validation_f1, 3)}\"\"\")\n",
    "            print(\"\\n---------------------------------------------------\\n\")\n",
    "        return mean_train_f1, mean_validation_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56c1f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop some columns by default before running cv\n",
    "def drop_default_columns(df, drop_default_columns_including):\n",
    "    def _drop_column(column):\n",
    "        for string in drop_default_columns_including:\n",
    "            if string in column:\n",
    "                return True\n",
    "    df = df[[column for column in df.columns if not _drop_column(column)]].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "### Cross-validation\n",
    "\n",
    "# Feature split\n",
    "complexity_features = []\n",
    "\n",
    "\n",
    "# Superfluous featues\n",
    "drop_default_columns_including = [\"average_sentence_embedding\", \"100_most_common_\", \"doc2vec_chunk_embedding\"]\n",
    "\n",
    "# All parameters\n",
    "models = [\"svr\", \"lasso\", \"xgboost\", \"svc\"]\n",
    "model_params = {\"svr\": [1], \"lasso\": [1, 4], \"xgboost\": [1, 4], \"svc\": [0.1, 1, 10, 100, 1000, 10000]} #\n",
    "dimensionality_reduction = [\"ss_pca_0_95\", 'k_best_f_reg_0_10', 'k_best_mutual_info_0_10', None]\n",
    "features = [\"book\", \"chunk\", \"book_and_averaged_chunk\", \"chunk_and_copied_book\"]\n",
    "\n",
    "# Which parameters to use\n",
    "full_cv_params = {\"model\": models, \"dimensionality_reduction\": dimensionality_reduction, \"features\": features}\n",
    "testing_params = {\"model\": models[3], \"dimensionality_reduction\": dimensionality_reduction[3], \n",
    "                  \"features\": features[2]}\n",
    "twoclass_params = {\"model\": models[3], \"dimensionality_reduction\": dimensionality_reduction, \n",
    "                  \"features\": features}\n",
    "multiclass_params = {\"model\": models[3], \"dimensionality_reduction\": dimensionality_reduction, \n",
    "                  \"features\": [\"book\", \"book_and_averaged_chunk\"] }\n",
    "# Old results from chr2021 paper\n",
    "eng_params = {\"model\": models[0], \"dimensionality_reduction\": dimensionality_reduction[0], \n",
    "                  \"features\": features[2], }, # svr, pca, book_and_average_chunk\n",
    "ger_params = {\"model\": models[0], \"dimensionality_reduction\": dimensionality_reduction[0], \n",
    "                  \"features\": features[1]}, # svr, pca, chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3a11a8",
   "metadata": {},
   "source": [
    "book_df = pd.read_csv(f\"{extracted_features_dir}{lang}/book_df.csv\")\n",
    "book_and_averaged_chunk_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/book_and_averaged_chunk_df.csv\")\n",
    "chunk_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/chunk_df.csv\")\n",
    "chunk_and_copied_book_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/chunk_and_copied_book_df.csv\")\n",
    "book_df = drop_default_columns(book_df, drop_default_columns_including)\n",
    "book_and_averaged_chunk_df = drop_default_columns(book_and_averaged_chunk_df, drop_default_columns_including)\n",
    "chunk_df = drop_default_columns(chunk_df, drop_default_columns_including)\n",
    "chunk_and_copied_book_df = drop_default_columns(chunk_and_copied_book_df, drop_default_columns_including)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff09a045",
   "metadata": {},
   "source": [
    "print(len(book_df.columns), len(book_and_averaged_chunk_df.columns),len(chunk_df.columns),len(chunk_and_copied_book_df.columns),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c542ff4",
   "metadata": {},
   "source": [
    "len(list(book_and_averaged_chunk_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46b3cb2",
   "metadata": {},
   "source": [
    "for i in list(book_and_averaged_chunk_df.columns):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b049efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Run two class classification\n",
    "'''\n",
    "results = []\n",
    "param_dict = \"multiclass\" #\"full_cv\", \"language_specific\"\n",
    "for lang in [\"eng\"]: #, \"ger\"]:    \n",
    "    if param_dict == \"testing\":\n",
    "        param_dir = testing_params\n",
    "    elif param_dict == \"multiclass\":\n",
    "        param_dir = multiclass_params\n",
    "    elif param_dict == \"full_cv\":\n",
    "        param_dir = full_cv_params\n",
    "    elif param_dict == \"language_specific\":\n",
    "        if lang == \"eng\":\n",
    "            param_dir = eng_params\n",
    "        else: \n",
    "            param_dir = ger_params\n",
    "    \n",
    "    #Eng: 606 books, 14146 chunks, 13170 chunks of books published after 1759\n",
    "    book_df = pd.read_csv(f\"{extracted_features_dir}{lang}/book_df.csv\")\n",
    "    book_and_averaged_chunk_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/book_and_averaged_chunk_df.csv\")\n",
    "    chunk_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/chunk_df.csv\")\n",
    "    chunk_and_copied_book_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/chunk_and_copied_book_df.csv\")\n",
    "    \n",
    "    book_df = drop_default_columns(book_df, drop_default_columns_including)\n",
    "    book_and_averaged_chunk_df = drop_default_columns(book_and_averaged_chunk_df, drop_default_columns_including)\n",
    "    chunk_df = drop_default_columns(chunk_df, drop_default_columns_including)\n",
    "    chunk_and_copied_book_df = drop_default_columns(chunk_and_copied_book_df, drop_default_columns_including)\n",
    "    \n",
    "    for model in [] + [param_dir['model']]:\n",
    "        model_param = model_params[model]\n",
    "        for model_param in model_param:\n",
    "            for dimensionality_reduction in param_dir[\"dimensionality_reduction\"]:\n",
    "                for features in param_dir[\"features\"]:\n",
    "                    for drop_columns_including in [[]]:\n",
    "                        #try:\n",
    "                        print(lang, model, features, drop_columns_including, dimensionality_reduction, 'param=', model_param)\n",
    "                        experiment = MulticlassClassification(\n",
    "                            language=lang,\n",
    "                            features=features,\n",
    "                            drop_columns_including=drop_columns_including,\n",
    "                            dimensionality_reduction=dimensionality_reduction,\n",
    "                            model_param=model_param,\n",
    "                            model=model,\n",
    "                            verbose=True\n",
    "                        )\n",
    "                        mean_train_f1, mean_validation_f1 = experiment.run()\n",
    "                        results.append((lang, model, features, drop_columns_including, dimensionality_reduction, model_param, mean_train_f1, mean_validation_f1))\n",
    "                        ########################################\n",
    "                        #Library\n",
    "#                             experiment = LibraryClassification(\n",
    "#                                 language=lang,\n",
    "#                                 features=features,\n",
    "#                                 drop_columns_including=drop_columns_including,\n",
    "#                                 dimensionality_reduction=dimensionality_reduction,\n",
    "#                                 model_param=model_param,\n",
    "#                                 model=model,\n",
    "#                                 verbose=False\n",
    "#                             )\n",
    "                        #################################################\n",
    "\n",
    "                        #except Exception as e:\n",
    "#                             print(f\"Error in {lang}, {model}, {features}, {drop_columns_including}, {dimensionality_reduction}\")\n",
    "#                             print(e)\n",
    "results_df = pd.DataFrame(results, columns=[\"lang\", \"model\", \"features\", \"drop_columns_including\", \n",
    "\"dimensionality_reduction\", \"model_param\", \"mean_train_f1\", \"mean_validation_f1\"])\n",
    "results_df.to_csv(results_dir + lang + '_' + param_dict + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e4e21fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ger svc book [] ss_pca_0_95 param= 0.1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.336, ValF1: 0.223\n",
      "Fold: 2, TrainF1: 0.359, ValF1: 0.139\n",
      "Fold: 3, TrainF1: 0.381, ValF1: 0.182\n",
      "Fold: 4, TrainF1: 0.391, ValF1: 0.156\n",
      "Fold: 5, TrainF1: 0.258, ValF1: 0.096\n",
      "Fold: 6, TrainF1: 0.294, ValF1: 0.153\n",
      "Fold: 7, TrainF1: 0.414, ValF1: 0.304\n",
      "Fold: 8, TrainF1: 0.384, ValF1: 0.068\n",
      "Fold: 9, TrainF1: 0.333, ValF1: 0.133\n",
      "Fold: 10, TrainF1: 0.326, ValF1: 0.145\n",
      "[[154  63  88  51]\n",
      " [  5   0   4   1]\n",
      " [ 38   4  20  24]\n",
      " [ 32   6  28  11]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        154   63   88   51  356\n",
      "1.0          5    0    4    1   10\n",
      "2.0         38    4   20   24   86\n",
      "3.0         32    6   28   11   77\n",
      "All        229   73  140   87  529\n",
      "TrainF1: 0.348, ValidationF1: 0.16\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] ss_pca_0_95 param= 0.1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.365, ValF1: 0.245\n",
      "Fold: 2, TrainF1: 0.393, ValF1: 0.205\n",
      "Fold: 3, TrainF1: 0.42, ValF1: 0.316\n",
      "Fold: 4, TrainF1: 0.365, ValF1: 0.215\n",
      "Fold: 5, TrainF1: 0.347, ValF1: 0.098\n",
      "Fold: 6, TrainF1: 0.344, ValF1: 0.321\n",
      "Fold: 7, TrainF1: 0.397, ValF1: 0.207\n",
      "Fold: 8, TrainF1: 0.377, ValF1: 0.265\n",
      "Fold: 9, TrainF1: 0.446, ValF1: 0.171\n",
      "Fold: 10, TrainF1: 0.334, ValF1: 0.16\n",
      "[[170  39  94  53]\n",
      " [  5   0   3   2]\n",
      " [ 38   4  31  13]\n",
      " [ 29   3  30  15]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        170   39   94   53  356\n",
      "1.0          5    0    3    2   10\n",
      "2.0         38    4   31   13   86\n",
      "3.0         29    3   30   15   77\n",
      "All        242   46  158   83  529\n",
      "TrainF1: 0.379, ValidationF1: 0.22\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_f_reg_0_10 param= 0.1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.177, ValF1: 0.173\n",
      "Fold: 2, TrainF1: 0.126, ValF1: 0.195\n",
      "Fold: 3, TrainF1: 0.126, ValF1: 0.121\n",
      "Fold: 4, TrainF1: 0.066, ValF1: 0.062\n",
      "Fold: 5, TrainF1: 0.15, ValF1: 0.108\n",
      "Fold: 6, TrainF1: 0.202, ValF1: 0.152\n",
      "Fold: 7, TrainF1: 0.081, ValF1: 0.068\n",
      "Fold: 8, TrainF1: 0.113, ValF1: 0.173\n",
      "Fold: 9, TrainF1: 0.135, ValF1: 0.098\n",
      "Fold: 10, TrainF1: 0.215, ValF1: 0.153\n",
      "[[ 55  60  95 146]\n",
      " [  2   0   1   7]\n",
      " [  7  10  23  46]\n",
      " [  4  12  15  46]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         55   60   95  146  356\n",
      "1.0          2    0    1    7   10\n",
      "2.0          7   10   23   46   86\n",
      "3.0          4   12   15   46   77\n",
      "All         68   82  134  245  529\n",
      "TrainF1: 0.139, ValidationF1: 0.13\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_f_reg_0_10 param= 0.1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.065, ValF1: 0.067\n",
      "Fold: 2, TrainF1: 0.085, ValF1: 0.128\n",
      "Fold: 3, TrainF1: 0.141, ValF1: 0.136\n",
      "Fold: 4, TrainF1: 0.217, ValF1: 0.202\n",
      "Fold: 5, TrainF1: 0.01, ValF1: 0.0\n",
      "Fold: 6, TrainF1: 0.065, ValF1: 0.067\n",
      "Fold: 7, TrainF1: 0.081, ValF1: 0.069\n",
      "Fold: 8, TrainF1: 0.25, ValF1: 0.215\n",
      "Fold: 9, TrainF1: 0.036, ValF1: 0.01\n",
      "Fold: 10, TrainF1: 0.091, ValF1: 0.049\n",
      "[[ 86  94  76 100]\n",
      " [  3   1   4   2]\n",
      " [  9  25  21  31]\n",
      " [ 15  29  16  17]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         86   94   76  100  356\n",
      "1.0          3    1    4    2   10\n",
      "2.0          9   25   21   31   86\n",
      "3.0         15   29   16   17   77\n",
      "All        113  149  117  150  529\n",
      "TrainF1: 0.104, ValidationF1: 0.094\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_mutual_info_0_10 param= 0.1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.009, ValF1: 0.01\n",
      "Fold: 2, TrainF1: 0.104, ValF1: 0.091\n",
      "Fold: 3, TrainF1: 0.082, ValF1: 0.061\n",
      "Fold: 4, TrainF1: 0.088, ValF1: 0.056\n",
      "Fold: 5, TrainF1: 0.091, ValF1: 0.076\n",
      "Fold: 6, TrainF1: 0.11, ValF1: 0.079\n",
      "Fold: 7, TrainF1: 0.202, ValF1: 0.103\n",
      "Fold: 8, TrainF1: 0.152, ValF1: 0.14\n",
      "Fold: 9, TrainF1: 0.068, ValF1: 0.116\n",
      "Fold: 10, TrainF1: 0.068, ValF1: 0.03\n",
      "[[ 11  86 153 106]\n",
      " [  0   2   7   1]\n",
      " [  2  15  42  27]\n",
      " [  2  21  37  17]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         11   86  153  106  356\n",
      "1.0          0    2    7    1   10\n",
      "2.0          2   15   42   27   86\n",
      "3.0          2   21   37   17   77\n",
      "All         15  124  239  151  529\n",
      "TrainF1: 0.097, ValidationF1: 0.076\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_mutual_info_0_10 param= 0.1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.248, ValF1: 0.164\n",
      "Fold: 2, TrainF1: 0.009, ValF1: 0.01\n",
      "Fold: 3, TrainF1: 0.084, ValF1: 0.082\n",
      "Fold: 4, TrainF1: 0.224, ValF1: 0.213\n",
      "Fold: 5, TrainF1: 0.237, ValF1: 0.213\n",
      "Fold: 6, TrainF1: 0.055, ValF1: 0.035\n",
      "Fold: 7, TrainF1: 0.217, ValF1: 0.189\n",
      "Fold: 8, TrainF1: 0.069, ValF1: 0.068\n",
      "Fold: 9, TrainF1: 0.219, ValF1: 0.232\n",
      "Fold: 10, TrainF1: 0.171, ValF1: 0.21\n",
      "[[168  98  46  44]\n",
      " [  3   3   2   2]\n",
      " [ 36  22  13  15]\n",
      " [ 33  27   4  13]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        168   98   46   44  356\n",
      "1.0          3    3    2    2   10\n",
      "2.0         36   22   13   15   86\n",
      "3.0         33   27    4   13   77\n",
      "All        240  150   65   74  529\n",
      "TrainF1: 0.153, ValidationF1: 0.142\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] None param= 0.1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.083, ValF1: 0.061\n",
      "Fold: 2, TrainF1: 0.028, ValF1: 0.01\n",
      "Fold: 3, TrainF1: 0.168, ValF1: 0.148\n",
      "Fold: 4, TrainF1: 0.291, ValF1: 0.246\n",
      "Fold: 5, TrainF1: 0.204, ValF1: 0.233\n",
      "Fold: 6, TrainF1: 0.01, ValF1: 0.0\n",
      "Fold: 7, TrainF1: 0.09, ValF1: 0.075\n",
      "Fold: 8, TrainF1: 0.25, ValF1: 0.222\n",
      "Fold: 9, TrainF1: 0.009, ValF1: 0.01\n",
      "Fold: 10, TrainF1: 0.073, ValF1: 0.062\n",
      "[[100 137 102  17]\n",
      " [  1   2   4   3]\n",
      " [ 32  23  24   7]\n",
      " [ 17  29  27   4]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        100  137  102   17  356\n",
      "1.0          1    2    4    3   10\n",
      "2.0         32   23   24    7   86\n",
      "3.0         17   29   27    4   77\n",
      "All        150  191  157   31  529\n",
      "TrainF1: 0.121, ValidationF1: 0.107\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] None param= 0.1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.082, ValF1: 0.075\n",
      "Fold: 2, TrainF1: 0.136, ValF1: 0.111\n",
      "Fold: 3, TrainF1: 0.013, ValF1: 0.019\n",
      "Fold: 4, TrainF1: 0.096, ValF1: 0.098\n",
      "Fold: 5, TrainF1: 0.229, ValF1: 0.162\n",
      "Fold: 6, TrainF1: 0.01, ValF1: 0.0\n",
      "Fold: 7, TrainF1: 0.083, ValF1: 0.085\n",
      "Fold: 8, TrainF1: 0.105, ValF1: 0.077\n",
      "Fold: 9, TrainF1: 0.191, ValF1: 0.152\n",
      "Fold: 10, TrainF1: 0.064, ValF1: 0.065\n",
      "[[ 27 102 176  51]\n",
      " [  2   2   4   2]\n",
      " [  8  27  46   5]\n",
      " [  9  23  36   9]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         27  102  176   51  356\n",
      "1.0          2    2    4    2   10\n",
      "2.0          8   27   46    5   86\n",
      "3.0          9   23   36    9   77\n",
      "All         46  154  262   67  529\n",
      "TrainF1: 0.101, ValidationF1: 0.084\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] ss_pca_0_95 param= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.741, ValF1: 0.445\n",
      "Fold: 2, TrainF1: 0.725, ValF1: 0.375\n",
      "Fold: 3, TrainF1: 0.737, ValF1: 0.177\n",
      "Fold: 4, TrainF1: 0.74, ValF1: 0.258\n",
      "Fold: 5, TrainF1: 0.711, ValF1: 0.281\n",
      "Fold: 6, TrainF1: 0.721, ValF1: 0.23\n",
      "Fold: 7, TrainF1: 0.735, ValF1: 0.206\n",
      "Fold: 8, TrainF1: 0.716, ValF1: 0.23\n",
      "Fold: 9, TrainF1: 0.751, ValF1: 0.494\n",
      "Fold: 10, TrainF1: 0.761, ValF1: 0.226\n",
      "[[219   0  50  87]\n",
      " [  8   0   0   2]\n",
      " [ 43   0  16  27]\n",
      " [ 43   0  13  21]]\n",
      "Predicted  0.0  2.0  3.0  All\n",
      "True                         \n",
      "0.0        219   50   87  356\n",
      "1.0          8    0    2   10\n",
      "2.0         43   16   27   86\n",
      "3.0         43   13   21   77\n",
      "All        313   79  137  529\n",
      "TrainF1: 0.734, ValidationF1: 0.292\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] ss_pca_0_95 param= 1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.713, ValF1: 0.356\n",
      "Fold: 2, TrainF1: 0.744, ValF1: 0.316\n",
      "Fold: 3, TrainF1: 0.723, ValF1: 0.297\n",
      "Fold: 4, TrainF1: 0.706, ValF1: 0.353\n",
      "Fold: 5, TrainF1: 0.723, ValF1: 0.256\n",
      "Fold: 6, TrainF1: 0.732, ValF1: 0.18\n",
      "Fold: 7, TrainF1: 0.723, ValF1: 0.192\n",
      "Fold: 8, TrainF1: 0.748, ValF1: 0.218\n",
      "Fold: 9, TrainF1: 0.713, ValF1: 0.287\n",
      "Fold: 10, TrainF1: 0.725, ValF1: 0.238\n",
      "[[217   2  55  82]\n",
      " [  8   0   0   2]\n",
      " [ 44   1  14  27]\n",
      " [ 41   0  14  22]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        217    2   55   82  356\n",
      "1.0          8    0    0    2   10\n",
      "2.0         44    1   14   27   86\n",
      "3.0         41    0   14   22   77\n",
      "All        310    3   83  133  529\n",
      "TrainF1: 0.725, ValidationF1: 0.269\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_f_reg_0_10 param= 1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.225, ValF1: 0.202\n",
      "Fold: 2, TrainF1: 0.264, ValF1: 0.175\n",
      "Fold: 3, TrainF1: 0.225, ValF1: 0.113\n",
      "Fold: 4, TrainF1: 0.248, ValF1: 0.237\n",
      "Fold: 5, TrainF1: 0.251, ValF1: 0.191\n",
      "Fold: 6, TrainF1: 0.224, ValF1: 0.151\n",
      "Fold: 7, TrainF1: 0.228, ValF1: 0.248\n",
      "Fold: 8, TrainF1: 0.22, ValF1: 0.138\n",
      "Fold: 9, TrainF1: 0.218, ValF1: 0.198\n",
      "Fold: 10, TrainF1: 0.251, ValF1: 0.193\n",
      "[[ 63  51  97 145]\n",
      " [  1   0   4   5]\n",
      " [ 12  11  21  42]\n",
      " [  9   4  16  48]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         63   51   97  145  356\n",
      "1.0          1    0    4    5   10\n",
      "2.0         12   11   21   42   86\n",
      "3.0          9    4   16   48   77\n",
      "All         85   66  138  240  529\n",
      "TrainF1: 0.235, ValidationF1: 0.184\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_f_reg_0_10 param= 1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.185, ValF1: 0.2\n",
      "Fold: 2, TrainF1: 0.214, ValF1: 0.221\n",
      "Fold: 3, TrainF1: 0.186, ValF1: 0.189\n",
      "Fold: 4, TrainF1: 0.174, ValF1: 0.137\n",
      "Fold: 5, TrainF1: 0.211, ValF1: 0.034\n",
      "Fold: 6, TrainF1: 0.227, ValF1: 0.3\n",
      "Fold: 7, TrainF1: 0.217, ValF1: 0.173\n",
      "Fold: 8, TrainF1: 0.191, ValF1: 0.335\n",
      "Fold: 9, TrainF1: 0.18, ValF1: 0.143\n",
      "Fold: 10, TrainF1: 0.199, ValF1: 0.076\n",
      "[[ 42  31 142 141]\n",
      " [  1   2   3   4]\n",
      " [  7  15  38  26]\n",
      " [  4   9  34  30]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         42   31  142  141  356\n",
      "1.0          1    2    3    4   10\n",
      "2.0          7   15   38   26   86\n",
      "3.0          4    9   34   30   77\n",
      "All         54   57  217  201  529\n",
      "TrainF1: 0.198, ValidationF1: 0.181\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_mutual_info_0_10 param= 1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.252, ValF1: 0.124\n",
      "Fold: 2, TrainF1: 0.139, ValF1: 0.14\n",
      "Fold: 3, TrainF1: 0.258, ValF1: 0.184\n",
      "Fold: 4, TrainF1: 0.233, ValF1: 0.18\n",
      "Fold: 5, TrainF1: 0.193, ValF1: 0.151\n",
      "Fold: 6, TrainF1: 0.255, ValF1: 0.238\n",
      "Fold: 7, TrainF1: 0.278, ValF1: 0.205\n",
      "Fold: 8, TrainF1: 0.235, ValF1: 0.202\n",
      "Fold: 9, TrainF1: 0.222, ValF1: 0.226\n",
      "Fold: 10, TrainF1: 0.27, ValF1: 0.141\n",
      "[[ 78  67  74 137]\n",
      " [  2   2   3   3]\n",
      " [ 16  25   5  40]\n",
      " [ 10   6  12  49]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         78   67   74  137  356\n",
      "1.0          2    2    3    3   10\n",
      "2.0         16   25    5   40   86\n",
      "3.0         10    6   12   49   77\n",
      "All        106  100   94  229  529\n",
      "TrainF1: 0.234, ValidationF1: 0.179\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_mutual_info_0_10 param= 1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.235, ValF1: 0.23\n",
      "Fold: 2, TrainF1: 0.228, ValF1: 0.122\n",
      "Fold: 3, TrainF1: 0.206, ValF1: 0.199\n",
      "Fold: 4, TrainF1: 0.269, ValF1: 0.337\n",
      "Fold: 5, TrainF1: 0.228, ValF1: 0.113\n",
      "Fold: 6, TrainF1: 0.152, ValF1: 0.166\n",
      "Fold: 7, TrainF1: 0.15, ValF1: 0.167\n",
      "Fold: 8, TrainF1: 0.218, ValF1: 0.253\n",
      "Fold: 9, TrainF1: 0.216, ValF1: 0.258\n",
      "Fold: 10, TrainF1: 0.13, ValF1: 0.084\n",
      "[[ 75  55 101 125]\n",
      " [  3   1   3   3]\n",
      " [  9  11  35  31]\n",
      " [ 12   8  24  33]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         75   55  101  125  356\n",
      "1.0          3    1    3    3   10\n",
      "2.0          9   11   35   31   86\n",
      "3.0         12    8   24   33   77\n",
      "All         99   75  163  192  529\n",
      "TrainF1: 0.203, ValidationF1: 0.193\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] None param= 1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.246, ValF1: 0.227\n",
      "Fold: 2, TrainF1: 0.23, ValF1: 0.282\n",
      "Fold: 3, TrainF1: 0.23, ValF1: 0.278\n",
      "Fold: 4, TrainF1: 0.23, ValF1: 0.235\n",
      "Fold: 5, TrainF1: 0.251, ValF1: 0.179\n",
      "Fold: 6, TrainF1: 0.24, ValF1: 0.25\n",
      "Fold: 7, TrainF1: 0.243, ValF1: 0.157\n",
      "Fold: 8, TrainF1: 0.176, ValF1: 0.176\n",
      "Fold: 9, TrainF1: 0.255, ValF1: 0.108\n",
      "Fold: 10, TrainF1: 0.246, ValF1: 0.165\n",
      "[[ 69  55  99 133]\n",
      " [  1   1   4   4]\n",
      " [  9  14  24  39]\n",
      " [  6   7  18  46]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         69   55   99  133  356\n",
      "1.0          1    1    4    4   10\n",
      "2.0          9   14   24   39   86\n",
      "3.0          6    7   18   46   77\n",
      "All         85   77  145  222  529\n",
      "TrainF1: 0.235, ValidationF1: 0.206\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] None param= 1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.202, ValF1: 0.129\n",
      "Fold: 2, TrainF1: 0.15, ValF1: 0.193\n",
      "Fold: 3, TrainF1: 0.162, ValF1: 0.175\n",
      "Fold: 4, TrainF1: 0.19, ValF1: 0.134\n",
      "Fold: 5, TrainF1: 0.215, ValF1: 0.216\n",
      "Fold: 6, TrainF1: 0.176, ValF1: 0.137\n",
      "Fold: 7, TrainF1: 0.154, ValF1: 0.167\n",
      "Fold: 8, TrainF1: 0.204, ValF1: 0.11\n",
      "Fold: 9, TrainF1: 0.192, ValF1: 0.267\n",
      "Fold: 10, TrainF1: 0.17, ValF1: 0.102\n",
      "[[ 30  28 163 135]\n",
      " [  1   0   6   3]\n",
      " [  5   4  50  27]\n",
      " [  8   3  37  29]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         30   28  163  135  356\n",
      "1.0          1    0    6    3   10\n",
      "2.0          5    4   50   27   86\n",
      "3.0          8    3   37   29   77\n",
      "All         44   35  256  194  529\n",
      "TrainF1: 0.182, ValidationF1: 0.163\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] ss_pca_0_95 param= 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.96, ValF1: 0.268\n",
      "Fold: 2, TrainF1: 0.956, ValF1: 0.335\n",
      "Fold: 3, TrainF1: 0.957, ValF1: 0.358\n",
      "Fold: 4, TrainF1: 0.96, ValF1: 0.195\n",
      "Fold: 5, TrainF1: 0.961, ValF1: 0.243\n",
      "Fold: 6, TrainF1: 0.962, ValF1: 0.245\n",
      "Fold: 7, TrainF1: 0.967, ValF1: 0.273\n",
      "Fold: 8, TrainF1: 0.959, ValF1: 0.356\n",
      "Fold: 9, TrainF1: 0.957, ValF1: 0.164\n",
      "Fold: 10, TrainF1: 0.954, ValF1: 0.302\n",
      "[[284   1  33  38]\n",
      " [ 10   0   0   0]\n",
      " [ 61   0  12  13]\n",
      " [ 53   0  14  10]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        284    1   33   38  356\n",
      "1.0         10    0    0    0   10\n",
      "2.0         61    0   12   13   86\n",
      "3.0         53    0   14   10   77\n",
      "All        408    1   59   61  529\n",
      "TrainF1: 0.959, ValidationF1: 0.274\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] ss_pca_0_95 param= 10\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.96, ValF1: 0.203\n",
      "Fold: 2, TrainF1: 0.961, ValF1: 0.398\n",
      "Fold: 3, TrainF1: 0.967, ValF1: 0.231\n",
      "Fold: 4, TrainF1: 0.957, ValF1: 0.261\n",
      "Fold: 5, TrainF1: 0.962, ValF1: 0.253\n",
      "Fold: 6, TrainF1: 0.96, ValF1: 0.278\n",
      "Fold: 7, TrainF1: 0.961, ValF1: 0.242\n",
      "Fold: 8, TrainF1: 0.961, ValF1: 0.393\n",
      "Fold: 9, TrainF1: 0.97, ValF1: 0.261\n",
      "Fold: 10, TrainF1: 0.971, ValF1: 0.388\n",
      "[[290   0  32  34]\n",
      " [  9   0   1   0]\n",
      " [ 66   1  11   8]\n",
      " [ 54   0  10  13]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        290    0   32   34  356\n",
      "1.0          9    0    1    0   10\n",
      "2.0         66    1   11    8   86\n",
      "3.0         54    0   10   13   77\n",
      "All        419    1   54   55  529\n",
      "TrainF1: 0.963, ValidationF1: 0.291\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_f_reg_0_10 param= 10\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.296, ValF1: 0.137\n",
      "Fold: 2, TrainF1: 0.272, ValF1: 0.212\n",
      "Fold: 3, TrainF1: 0.268, ValF1: 0.262\n",
      "Fold: 4, TrainF1: 0.299, ValF1: 0.26\n",
      "Fold: 5, TrainF1: 0.233, ValF1: 0.109\n",
      "Fold: 6, TrainF1: 0.28, ValF1: 0.246\n",
      "Fold: 7, TrainF1: 0.29, ValF1: 0.201\n",
      "Fold: 8, TrainF1: 0.243, ValF1: 0.271\n",
      "Fold: 9, TrainF1: 0.267, ValF1: 0.208\n",
      "Fold: 10, TrainF1: 0.282, ValF1: 0.227\n",
      "[[108  64  45 139]\n",
      " [  2   1   2   5]\n",
      " [ 19  15  10  42]\n",
      " [ 11  12   6  48]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        108   64   45  139  356\n",
      "1.0          2    1    2    5   10\n",
      "2.0         19   15   10   42   86\n",
      "3.0         11   12    6   48   77\n",
      "All        140   92   63  234  529\n",
      "TrainF1: 0.273, ValidationF1: 0.213\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_f_reg_0_10 param= 10\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.201, ValF1: 0.172\n",
      "Fold: 2, TrainF1: 0.245, ValF1: 0.216\n",
      "Fold: 3, TrainF1: 0.259, ValF1: 0.116\n",
      "Fold: 4, TrainF1: 0.224, ValF1: 0.119\n",
      "Fold: 5, TrainF1: 0.223, ValF1: 0.044\n",
      "Fold: 6, TrainF1: 0.23, ValF1: 0.143\n",
      "Fold: 7, TrainF1: 0.192, ValF1: 0.316\n",
      "Fold: 8, TrainF1: 0.165, ValF1: 0.111\n",
      "Fold: 9, TrainF1: 0.221, ValF1: 0.23\n",
      "Fold: 10, TrainF1: 0.218, ValF1: 0.164\n",
      "[[ 54  65 113 124]\n",
      " [  2   1   6   1]\n",
      " [  7  18  37  24]\n",
      " [ 12  10  25  30]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         54   65  113  124  356\n",
      "1.0          2    1    6    1   10\n",
      "2.0          7   18   37   24   86\n",
      "3.0         12   10   25   30   77\n",
      "All         75   94  181  179  529\n",
      "TrainF1: 0.218, ValidationF1: 0.163\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_mutual_info_0_10 param= 10\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.244, ValF1: 0.25\n",
      "Fold: 2, TrainF1: 0.263, ValF1: 0.28\n",
      "Fold: 3, TrainF1: 0.293, ValF1: 0.149\n",
      "Fold: 4, TrainF1: 0.228, ValF1: 0.353\n",
      "Fold: 5, TrainF1: 0.264, ValF1: 0.215\n",
      "Fold: 6, TrainF1: 0.293, ValF1: 0.119\n",
      "Fold: 7, TrainF1: 0.272, ValF1: 0.278\n",
      "Fold: 8, TrainF1: 0.274, ValF1: 0.117\n",
      "Fold: 9, TrainF1: 0.284, ValF1: 0.183\n",
      "Fold: 10, TrainF1: 0.287, ValF1: 0.236\n",
      "[[ 94  68  46 148]\n",
      " [  3   0   2   5]\n",
      " [ 16  11  16  43]\n",
      " [  9   8  10  50]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         94   68   46  148  356\n",
      "1.0          3    0    2    5   10\n",
      "2.0         16   11   16   43   86\n",
      "3.0          9    8   10   50   77\n",
      "All        122   87   74  246  529\n",
      "TrainF1: 0.27, ValidationF1: 0.218\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_mutual_info_0_10 param= 10\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.223, ValF1: 0.083\n",
      "Fold: 2, TrainF1: 0.186, ValF1: 0.147\n",
      "Fold: 3, TrainF1: 0.214, ValF1: 0.07\n",
      "Fold: 4, TrainF1: 0.206, ValF1: 0.277\n",
      "Fold: 5, TrainF1: 0.218, ValF1: 0.222\n",
      "Fold: 6, TrainF1: 0.277, ValF1: 0.22\n",
      "Fold: 7, TrainF1: 0.227, ValF1: 0.201\n",
      "Fold: 8, TrainF1: 0.224, ValF1: 0.173\n",
      "Fold: 9, TrainF1: 0.228, ValF1: 0.15\n",
      "Fold: 10, TrainF1: 0.243, ValF1: 0.155\n",
      "[[ 84  98  40 134]\n",
      " [  3   2   2   3]\n",
      " [ 16  25   8  37]\n",
      " [  9  19  11  38]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         84   98   40  134  356\n",
      "1.0          3    2    2    3   10\n",
      "2.0         16   25    8   37   86\n",
      "3.0          9   19   11   38   77\n",
      "All        112  144   61  212  529\n",
      "TrainF1: 0.225, ValidationF1: 0.17\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] None param= 10\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.242, ValF1: 0.314\n",
      "Fold: 2, TrainF1: 0.28, ValF1: 0.133\n",
      "Fold: 3, TrainF1: 0.267, ValF1: 0.163\n",
      "Fold: 4, TrainF1: 0.246, ValF1: 0.182\n",
      "Fold: 5, TrainF1: 0.223, ValF1: 0.265\n",
      "Fold: 6, TrainF1: 0.259, ValF1: 0.229\n",
      "Fold: 7, TrainF1: 0.271, ValF1: 0.252\n",
      "Fold: 8, TrainF1: 0.283, ValF1: 0.165\n",
      "Fold: 9, TrainF1: 0.281, ValF1: 0.189\n",
      "Fold: 10, TrainF1: 0.297, ValF1: 0.195\n",
      "[[ 93 100  37 126]\n",
      " [  2   2   3   3]\n",
      " [ 21  21   9  35]\n",
      " [ 12  11   8  46]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         93  100   37  126  356\n",
      "1.0          2    2    3    3   10\n",
      "2.0         21   21    9   35   86\n",
      "3.0         12   11    8   46   77\n",
      "All        128  134   57  210  529\n",
      "TrainF1: 0.265, ValidationF1: 0.209\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] None param= 10\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.209, ValF1: 0.248\n",
      "Fold: 2, TrainF1: 0.208, ValF1: 0.094\n",
      "Fold: 3, TrainF1: 0.176, ValF1: 0.041\n",
      "Fold: 4, TrainF1: 0.226, ValF1: 0.128\n",
      "Fold: 5, TrainF1: 0.202, ValF1: 0.172\n",
      "Fold: 6, TrainF1: 0.196, ValF1: 0.138\n",
      "Fold: 7, TrainF1: 0.224, ValF1: 0.121\n",
      "Fold: 8, TrainF1: 0.186, ValF1: 0.252\n",
      "Fold: 9, TrainF1: 0.235, ValF1: 0.149\n",
      "Fold: 10, TrainF1: 0.215, ValF1: 0.168\n",
      "[[ 31  43 162 120]\n",
      " [  1   1   6   2]\n",
      " [  5   5  52  24]\n",
      " [  8   4  40  25]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         31   43  162  120  356\n",
      "1.0          1    1    6    2   10\n",
      "2.0          5    5   52   24   86\n",
      "3.0          8    4   40   25   77\n",
      "All         45   53  260  171  529\n",
      "TrainF1: 0.208, ValidationF1: 0.151\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] ss_pca_0_95 param= 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 1.0, ValF1: 0.38\n",
      "Fold: 2, TrainF1: 1.0, ValF1: 0.228\n",
      "Fold: 3, TrainF1: 1.0, ValF1: 0.321\n",
      "Fold: 4, TrainF1: 1.0, ValF1: 0.235\n",
      "Fold: 5, TrainF1: 1.0, ValF1: 0.347\n",
      "Fold: 6, TrainF1: 1.0, ValF1: 0.446\n",
      "Fold: 7, TrainF1: 1.0, ValF1: 0.226\n",
      "Fold: 8, TrainF1: 1.0, ValF1: 0.288\n",
      "Fold: 9, TrainF1: 1.0, ValF1: 0.272\n",
      "Fold: 10, TrainF1: 1.0, ValF1: 0.254\n",
      "[[297   0  31  28]\n",
      " [ 10   0   0   0]\n",
      " [ 59   0  17  10]\n",
      " [ 59   0  13   5]]\n",
      "Predicted  0.0  2.0  3.0  All\n",
      "True                         \n",
      "0.0        297   31   28  356\n",
      "1.0         10    0    0   10\n",
      "2.0         59   17   10   86\n",
      "3.0         59   13    5   77\n",
      "All        425   61   43  529\n",
      "TrainF1: 1.0, ValidationF1: 0.3\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] ss_pca_0_95 param= 100\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 1.0, ValF1: 0.278\n",
      "Fold: 2, TrainF1: 1.0, ValF1: 0.264\n",
      "Fold: 3, TrainF1: 1.0, ValF1: 0.319\n",
      "Fold: 4, TrainF1: 1.0, ValF1: 0.29\n",
      "Fold: 5, TrainF1: 1.0, ValF1: 0.205\n",
      "Fold: 6, TrainF1: 1.0, ValF1: 0.407\n",
      "Fold: 7, TrainF1: 1.0, ValF1: 0.306\n",
      "Fold: 8, TrainF1: 1.0, ValF1: 0.392\n",
      "Fold: 9, TrainF1: 1.0, ValF1: 0.208\n",
      "Fold: 10, TrainF1: 1.0, ValF1: 0.263\n",
      "[[295   1  36  24]\n",
      " [ 10   0   0   0]\n",
      " [ 62   0  17   7]\n",
      " [ 57   0  12   8]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        295    1   36   24  356\n",
      "1.0         10    0    0    0   10\n",
      "2.0         62    0   17    7   86\n",
      "3.0         57    0   12    8   77\n",
      "All        424    1   65   39  529\n",
      "TrainF1: 1.0, ValidationF1: 0.293\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_f_reg_0_10 param= 100\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.308, ValF1: 0.27\n",
      "Fold: 2, TrainF1: 0.299, ValF1: 0.264\n",
      "Fold: 3, TrainF1: 0.311, ValF1: 0.237\n",
      "Fold: 4, TrainF1: 0.276, ValF1: 0.196\n",
      "Fold: 5, TrainF1: 0.325, ValF1: 0.155\n",
      "Fold: 6, TrainF1: 0.317, ValF1: 0.199\n",
      "Fold: 7, TrainF1: 0.291, ValF1: 0.12\n",
      "Fold: 8, TrainF1: 0.309, ValF1: 0.306\n",
      "Fold: 9, TrainF1: 0.338, ValF1: 0.139\n",
      "Fold: 10, TrainF1: 0.295, ValF1: 0.26\n",
      "[[104  73  64 115]\n",
      " [  2   1   4   3]\n",
      " [ 15  17  16  38]\n",
      " [ 14  17   7  39]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        104   73   64  115  356\n",
      "1.0          2    1    4    3   10\n",
      "2.0         15   17   16   38   86\n",
      "3.0         14   17    7   39   77\n",
      "All        135  108   91  195  529\n",
      "TrainF1: 0.307, ValidationF1: 0.215\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_f_reg_0_10 param= 100\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.223, ValF1: 0.221\n",
      "Fold: 2, TrainF1: 0.223, ValF1: 0.22\n",
      "Fold: 3, TrainF1: 0.212, ValF1: 0.144\n",
      "Fold: 4, TrainF1: 0.211, ValF1: 0.12\n",
      "Fold: 5, TrainF1: 0.253, ValF1: 0.169\n",
      "Fold: 6, TrainF1: 0.241, ValF1: 0.211\n",
      "Fold: 7, TrainF1: 0.278, ValF1: 0.187\n",
      "Fold: 8, TrainF1: 0.233, ValF1: 0.127\n",
      "Fold: 9, TrainF1: 0.309, ValF1: 0.148\n",
      "Fold: 10, TrainF1: 0.25, ValF1: 0.229\n",
      "[[ 60  38 143 115]\n",
      " [  2   0   5   3]\n",
      " [  8   6  42  30]\n",
      " [ 12   6  37  22]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         60   38  143  115  356\n",
      "1.0          2    0    5    3   10\n",
      "2.0          8    6   42   30   86\n",
      "3.0         12    6   37   22   77\n",
      "All         82   50  227  170  529\n",
      "TrainF1: 0.243, ValidationF1: 0.178\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_mutual_info_0_10 param= 100\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.312, ValF1: 0.217\n",
      "Fold: 2, TrainF1: 0.323, ValF1: 0.24\n",
      "Fold: 3, TrainF1: 0.271, ValF1: 0.267\n",
      "Fold: 4, TrainF1: 0.31, ValF1: 0.338\n",
      "Fold: 5, TrainF1: 0.296, ValF1: 0.283\n",
      "Fold: 6, TrainF1: 0.3, ValF1: 0.143\n",
      "Fold: 7, TrainF1: 0.321, ValF1: 0.17\n",
      "Fold: 8, TrainF1: 0.314, ValF1: 0.178\n",
      "Fold: 9, TrainF1: 0.293, ValF1: 0.143\n",
      "Fold: 10, TrainF1: 0.317, ValF1: 0.165\n",
      "[[109  55  73 119]\n",
      " [  2   1   4   3]\n",
      " [ 17   9  20  40]\n",
      " [ 14  10  14  39]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        109   55   73  119  356\n",
      "1.0          2    1    4    3   10\n",
      "2.0         17    9   20   40   86\n",
      "3.0         14   10   14   39   77\n",
      "All        142   75  111  201  529\n",
      "TrainF1: 0.306, ValidationF1: 0.214\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_mutual_info_0_10 param= 100\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.281, ValF1: 0.321\n",
      "Fold: 2, TrainF1: 0.216, ValF1: 0.145\n",
      "Fold: 3, TrainF1: 0.348, ValF1: 0.227\n",
      "Fold: 4, TrainF1: 0.255, ValF1: 0.116\n",
      "Fold: 5, TrainF1: 0.22, ValF1: 0.15\n",
      "Fold: 6, TrainF1: 0.242, ValF1: 0.232\n",
      "Fold: 7, TrainF1: 0.28, ValF1: 0.182\n",
      "Fold: 8, TrainF1: 0.294, ValF1: 0.081\n",
      "Fold: 9, TrainF1: 0.261, ValF1: 0.137\n",
      "Fold: 10, TrainF1: 0.22, ValF1: 0.243\n",
      "[[ 83  59  96 118]\n",
      " [  1   1   4   4]\n",
      " [ 10  21  26  29]\n",
      " [ 11   8  24  34]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         83   59   96  118  356\n",
      "1.0          1    1    4    4   10\n",
      "2.0         10   21   26   29   86\n",
      "3.0         11    8   24   34   77\n",
      "All        105   89  150  185  529\n",
      "TrainF1: 0.262, ValidationF1: 0.183\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] None param= 100\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.302, ValF1: 0.26\n",
      "Fold: 2, TrainF1: 0.305, ValF1: 0.158\n",
      "Fold: 3, TrainF1: 0.313, ValF1: 0.243\n",
      "Fold: 4, TrainF1: 0.308, ValF1: 0.272\n",
      "Fold: 5, TrainF1: 0.331, ValF1: 0.281\n",
      "Fold: 6, TrainF1: 0.298, ValF1: 0.282\n",
      "Fold: 7, TrainF1: 0.315, ValF1: 0.268\n",
      "Fold: 8, TrainF1: 0.313, ValF1: 0.175\n",
      "Fold: 9, TrainF1: 0.313, ValF1: 0.215\n",
      "Fold: 10, TrainF1: 0.293, ValF1: 0.27\n",
      "[[114  58  66 118]\n",
      " [  2   1   4   3]\n",
      " [ 18  15  19  34]\n",
      " [ 15  13   7  42]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        114   58   66  118  356\n",
      "1.0          2    1    4    3   10\n",
      "2.0         18   15   19   34   86\n",
      "3.0         15   13    7   42   77\n",
      "All        149   87   96  197  529\n",
      "TrainF1: 0.309, ValidationF1: 0.243\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] None param= 100\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.244, ValF1: 0.224\n",
      "Fold: 2, TrainF1: 0.239, ValF1: 0.243\n",
      "Fold: 3, TrainF1: 0.229, ValF1: 0.141\n",
      "Fold: 4, TrainF1: 0.229, ValF1: 0.298\n",
      "Fold: 5, TrainF1: 0.221, ValF1: 0.173\n",
      "Fold: 6, TrainF1: 0.243, ValF1: 0.194\n",
      "Fold: 7, TrainF1: 0.26, ValF1: 0.07\n",
      "Fold: 8, TrainF1: 0.197, ValF1: 0.142\n",
      "Fold: 9, TrainF1: 0.255, ValF1: 0.156\n",
      "Fold: 10, TrainF1: 0.156, ValF1: 0.139\n",
      "[[ 73  54 149  80]\n",
      " [  2   1   6   1]\n",
      " [  9  13  47  17]\n",
      " [ 14   7  40  16]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         73   54  149   80  356\n",
      "1.0          2    1    6    1   10\n",
      "2.0          9   13   47   17   86\n",
      "3.0         14    7   40   16   77\n",
      "All         98   75  242  114  529\n",
      "TrainF1: 0.227, ValidationF1: 0.178\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] ss_pca_0_95 param= 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 1.0, ValF1: 0.37\n",
      "Fold: 2, TrainF1: 1.0, ValF1: 0.253\n",
      "Fold: 3, TrainF1: 1.0, ValF1: 0.291\n",
      "Fold: 4, TrainF1: 1.0, ValF1: 0.327\n",
      "Fold: 5, TrainF1: 1.0, ValF1: 0.184\n",
      "Fold: 6, TrainF1: 1.0, ValF1: 0.328\n",
      "Fold: 7, TrainF1: 1.0, ValF1: 0.253\n",
      "Fold: 8, TrainF1: 1.0, ValF1: 0.202\n",
      "Fold: 9, TrainF1: 1.0, ValF1: 0.199\n",
      "Fold: 10, TrainF1: 1.0, ValF1: 0.336\n",
      "[[305   0  30  21]\n",
      " [ 10   0   0   0]\n",
      " [ 60   0  12  14]\n",
      " [ 59   0  11   7]]\n",
      "Predicted  0.0  2.0  3.0  All\n",
      "True                         \n",
      "0.0        305   30   21  356\n",
      "1.0         10    0    0   10\n",
      "2.0         60   12   14   86\n",
      "3.0         59   11    7   77\n",
      "All        434   53   42  529\n",
      "TrainF1: 1.0, ValidationF1: 0.274\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] ss_pca_0_95 param= 1000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 1.0, ValF1: 0.272\n",
      "Fold: 2, TrainF1: 1.0, ValF1: 0.183\n",
      "Fold: 3, TrainF1: 1.0, ValF1: 0.32\n",
      "Fold: 4, TrainF1: 1.0, ValF1: 0.38\n",
      "Fold: 5, TrainF1: 1.0, ValF1: 0.324\n",
      "Fold: 6, TrainF1: 1.0, ValF1: 0.48\n",
      "Fold: 7, TrainF1: 1.0, ValF1: 0.384\n",
      "Fold: 8, TrainF1: 1.0, ValF1: 0.2\n",
      "Fold: 9, TrainF1: 1.0, ValF1: 0.247\n",
      "Fold: 10, TrainF1: 1.0, ValF1: 0.328\n",
      "[[298   0  34  24]\n",
      " [  9   0   1   0]\n",
      " [ 66   0  16   4]\n",
      " [ 58   0  10   9]]\n",
      "Predicted  0.0  2.0  3.0  All\n",
      "True                         \n",
      "0.0        298   34   24  356\n",
      "1.0          9    1    0   10\n",
      "2.0         66   16    4   86\n",
      "3.0         58   10    9   77\n",
      "All        431   61   37  529\n",
      "TrainF1: 1.0, ValidationF1: 0.312\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_f_reg_0_10 param= 1000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.37, ValF1: 0.341\n",
      "Fold: 2, TrainF1: 0.378, ValF1: 0.296\n",
      "Fold: 3, TrainF1: 0.364, ValF1: 0.157\n",
      "Fold: 4, TrainF1: 0.383, ValF1: 0.264\n",
      "Fold: 5, TrainF1: 0.324, ValF1: 0.297\n",
      "Fold: 6, TrainF1: 0.408, ValF1: 0.269\n",
      "Fold: 7, TrainF1: 0.403, ValF1: 0.201\n",
      "Fold: 8, TrainF1: 0.404, ValF1: 0.232\n",
      "Fold: 9, TrainF1: 0.439, ValF1: 0.199\n",
      "Fold: 10, TrainF1: 0.392, ValF1: 0.129\n",
      "[[131  61  64 100]\n",
      " [  4   0   3   3]\n",
      " [ 28   7  19  32]\n",
      " [ 19   8  16  34]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        131   61   64  100  356\n",
      "1.0          4    0    3    3   10\n",
      "2.0         28    7   19   32   86\n",
      "3.0         19    8   16   34   77\n",
      "All        182   76  102  169  529\n",
      "TrainF1: 0.386, ValidationF1: 0.239\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_f_reg_0_10 param= 1000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.329, ValF1: 0.151\n",
      "Fold: 2, TrainF1: 0.246, ValF1: 0.264\n",
      "Fold: 3, TrainF1: 0.353, ValF1: 0.305\n",
      "Fold: 4, TrainF1: 0.254, ValF1: 0.248\n",
      "Fold: 5, TrainF1: 0.25, ValF1: 0.095\n",
      "Fold: 6, TrainF1: 0.238, ValF1: 0.26\n",
      "Fold: 7, TrainF1: 0.333, ValF1: 0.204\n",
      "Fold: 8, TrainF1: 0.311, ValF1: 0.267\n",
      "Fold: 9, TrainF1: 0.27, ValF1: 0.146\n",
      "Fold: 10, TrainF1: 0.257, ValF1: 0.241\n",
      "[[104  34 137  81]\n",
      " [  3   0   4   3]\n",
      " [ 17   7  36  26]\n",
      " [ 14   9  25  29]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        104   34  137   81  356\n",
      "1.0          3    0    4    3   10\n",
      "2.0         17    7   36   26   86\n",
      "3.0         14    9   25   29   77\n",
      "All        138   50  202  139  529\n",
      "TrainF1: 0.284, ValidationF1: 0.218\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_mutual_info_0_10 param= 1000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.349, ValF1: 0.36\n",
      "Fold: 2, TrainF1: 0.386, ValF1: 0.191\n",
      "Fold: 3, TrainF1: 0.376, ValF1: 0.152\n",
      "Fold: 4, TrainF1: 0.369, ValF1: 0.308\n",
      "Fold: 5, TrainF1: 0.37, ValF1: 0.205\n",
      "Fold: 6, TrainF1: 0.419, ValF1: 0.163\n",
      "Fold: 7, TrainF1: 0.354, ValF1: 0.205\n",
      "Fold: 8, TrainF1: 0.354, ValF1: 0.281\n",
      "Fold: 9, TrainF1: 0.387, ValF1: 0.114\n",
      "Fold: 10, TrainF1: 0.388, ValF1: 0.288\n",
      "[[125  65  68  98]\n",
      " [  2   1   4   3]\n",
      " [ 21  10  18  37]\n",
      " [ 16  14  14  33]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        125   65   68   98  356\n",
      "1.0          2    1    4    3   10\n",
      "2.0         21   10   18   37   86\n",
      "3.0         16   14   14   33   77\n",
      "All        164   90  104  171  529\n",
      "TrainF1: 0.375, ValidationF1: 0.227\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_mutual_info_0_10 param= 1000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.253, ValF1: 0.152\n",
      "Fold: 2, TrainF1: 0.355, ValF1: 0.162\n",
      "Fold: 3, TrainF1: 0.361, ValF1: 0.187\n",
      "Fold: 4, TrainF1: 0.311, ValF1: 0.178\n",
      "Fold: 5, TrainF1: 0.255, ValF1: 0.266\n",
      "Fold: 6, TrainF1: 0.225, ValF1: 0.203\n",
      "Fold: 7, TrainF1: 0.241, ValF1: 0.149\n",
      "Fold: 8, TrainF1: 0.242, ValF1: 0.168\n",
      "Fold: 9, TrainF1: 0.288, ValF1: 0.346\n",
      "Fold: 10, TrainF1: 0.342, ValF1: 0.134\n",
      "[[ 94  46 128  88]\n",
      " [  3   1   4   2]\n",
      " [  9  18  34  25]\n",
      " [ 18   9  31  19]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         94   46  128   88  356\n",
      "1.0          3    1    4    2   10\n",
      "2.0          9   18   34   25   86\n",
      "3.0         18    9   31   19   77\n",
      "All        124   74  197  134  529\n",
      "TrainF1: 0.287, ValidationF1: 0.195\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] None param= 1000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.408, ValF1: 0.222\n",
      "Fold: 2, TrainF1: 0.415, ValF1: 0.158\n",
      "Fold: 3, TrainF1: 0.36, ValF1: 0.292\n",
      "Fold: 4, TrainF1: 0.374, ValF1: 0.221\n",
      "Fold: 5, TrainF1: 0.396, ValF1: 0.182\n",
      "Fold: 6, TrainF1: 0.393, ValF1: 0.133\n",
      "Fold: 7, TrainF1: 0.385, ValF1: 0.258\n",
      "Fold: 8, TrainF1: 0.358, ValF1: 0.159\n",
      "Fold: 9, TrainF1: 0.364, ValF1: 0.329\n",
      "Fold: 10, TrainF1: 0.388, ValF1: 0.187\n",
      "[[119  56  80 101]\n",
      " [  4   1   2   3]\n",
      " [ 24   7  18  37]\n",
      " [ 25   8  10  34]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        119   56   80  101  356\n",
      "1.0          4    1    2    3   10\n",
      "2.0         24    7   18   37   86\n",
      "3.0         25    8   10   34   77\n",
      "All        172   72  110  175  529\n",
      "TrainF1: 0.384, ValidationF1: 0.214\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] None param= 1000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.246, ValF1: 0.13\n",
      "Fold: 2, TrainF1: 0.248, ValF1: 0.22\n",
      "Fold: 3, TrainF1: 0.234, ValF1: 0.138\n",
      "Fold: 4, TrainF1: 0.209, ValF1: 0.134\n",
      "Fold: 5, TrainF1: 0.23, ValF1: 0.203\n",
      "Fold: 6, TrainF1: 0.214, ValF1: 0.187\n",
      "Fold: 7, TrainF1: 0.242, ValF1: 0.149\n",
      "Fold: 8, TrainF1: 0.24, ValF1: 0.227\n",
      "Fold: 9, TrainF1: 0.26, ValF1: 0.163\n",
      "Fold: 10, TrainF1: 0.256, ValF1: 0.216\n",
      "[[ 74  38 155  89]\n",
      " [  3   1   5   1]\n",
      " [  8  10  48  20]\n",
      " [ 15   4  42  16]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         74   38  155   89  356\n",
      "1.0          3    1    5    1   10\n",
      "2.0          8   10   48   20   86\n",
      "3.0         15    4   42   16   77\n",
      "All        100   53  250  126  529\n",
      "TrainF1: 0.238, ValidationF1: 0.177\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] ss_pca_0_95 param= 10000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, TrainF1: 1.0, ValF1: 0.193\n",
      "Fold: 2, TrainF1: 1.0, ValF1: 0.244\n",
      "Fold: 3, TrainF1: 1.0, ValF1: 0.279\n",
      "Fold: 4, TrainF1: 1.0, ValF1: 0.245\n",
      "Fold: 5, TrainF1: 1.0, ValF1: 0.27\n",
      "Fold: 6, TrainF1: 1.0, ValF1: 0.488\n",
      "Fold: 7, TrainF1: 1.0, ValF1: 0.198\n",
      "Fold: 8, TrainF1: 1.0, ValF1: 0.276\n",
      "Fold: 9, TrainF1: 1.0, ValF1: 0.164\n",
      "Fold: 10, TrainF1: 1.0, ValF1: 0.255\n",
      "[[297   0  28  31]\n",
      " [ 10   0   0   0]\n",
      " [ 58   0  15  13]\n",
      " [ 59   0  14   4]]\n",
      "Predicted  0.0  2.0  3.0  All\n",
      "True                         \n",
      "0.0        297   28   31  356\n",
      "1.0         10    0    0   10\n",
      "2.0         58   15   13   86\n",
      "3.0         59   14    4   77\n",
      "All        424   57   48  529\n",
      "TrainF1: 1.0, ValidationF1: 0.261\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] ss_pca_0_95 param= 10000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 1.0, ValF1: 0.425\n",
      "Fold: 2, TrainF1: 1.0, ValF1: 0.225\n",
      "Fold: 3, TrainF1: 1.0, ValF1: 0.218\n",
      "Fold: 4, TrainF1: 1.0, ValF1: 0.263\n",
      "Fold: 5, TrainF1: 1.0, ValF1: 0.248\n",
      "Fold: 6, TrainF1: 1.0, ValF1: 0.252\n",
      "Fold: 7, TrainF1: 1.0, ValF1: 0.29\n",
      "Fold: 8, TrainF1: 1.0, ValF1: 0.34\n",
      "Fold: 9, TrainF1: 1.0, ValF1: 0.272\n",
      "Fold: 10, TrainF1: 1.0, ValF1: 0.247\n",
      "[[299   1  27  29]\n",
      " [  9   0   1   0]\n",
      " [ 63   1  12  10]\n",
      " [ 59   0  11   7]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        299    1   27   29  356\n",
      "1.0          9    0    1    0   10\n",
      "2.0         63    1   12   10   86\n",
      "3.0         59    0   11    7   77\n",
      "All        430    2   51   46  529\n",
      "TrainF1: 1.0, ValidationF1: 0.278\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_f_reg_0_10 param= 10000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.538, ValF1: 0.443\n",
      "Fold: 2, TrainF1: 0.597, ValF1: 0.263\n",
      "Fold: 3, TrainF1: 0.549, ValF1: 0.297\n",
      "Fold: 4, TrainF1: 0.539, ValF1: 0.177\n",
      "Fold: 5, TrainF1: 0.547, ValF1: 0.22\n",
      "Fold: 6, TrainF1: 0.483, ValF1: 0.234\n",
      "Fold: 7, TrainF1: 0.571, ValF1: 0.21\n",
      "Fold: 8, TrainF1: 0.448, ValF1: 0.165\n",
      "Fold: 9, TrainF1: 0.524, ValF1: 0.216\n",
      "Fold: 10, TrainF1: 0.515, ValF1: 0.32\n",
      "[[154  33  79  90]\n",
      " [  4   1   3   2]\n",
      " [ 32   6  23  25]\n",
      " [ 28   2  17  30]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        154   33   79   90  356\n",
      "1.0          4    1    3    2   10\n",
      "2.0         32    6   23   25   86\n",
      "3.0         28    2   17   30   77\n",
      "All        218   42  122  147  529\n",
      "TrainF1: 0.531, ValidationF1: 0.255\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_f_reg_0_10 param= 10000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.24, ValF1: 0.136\n",
      "Fold: 2, TrainF1: 0.389, ValF1: 0.218\n",
      "Fold: 3, TrainF1: 0.251, ValF1: 0.168\n",
      "Fold: 4, TrainF1: 0.217, ValF1: 0.22\n",
      "Fold: 5, TrainF1: 0.269, ValF1: 0.133\n",
      "Fold: 6, TrainF1: 0.192, ValF1: 0.122\n",
      "Fold: 7, TrainF1: 0.245, ValF1: 0.211\n",
      "Fold: 8, TrainF1: 0.422, ValF1: 0.203\n",
      "Fold: 9, TrainF1: 0.228, ValF1: 0.164\n",
      "Fold: 10, TrainF1: 0.408, ValF1: 0.205\n",
      "[[ 89  64 115  88]\n",
      " [  5   1   3   1]\n",
      " [ 10  10  34  32]\n",
      " [ 14  10  29  24]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         89   64  115   88  356\n",
      "1.0          5    1    3    1   10\n",
      "2.0         10   10   34   32   86\n",
      "3.0         14   10   29   24   77\n",
      "All        118   85  181  145  529\n",
      "TrainF1: 0.286, ValidationF1: 0.178\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_mutual_info_0_10 param= 10000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.459, ValF1: 0.201\n",
      "Fold: 2, TrainF1: 0.477, ValF1: 0.264\n",
      "Fold: 3, TrainF1: 0.502, ValF1: 0.23\n",
      "Fold: 4, TrainF1: 0.478, ValF1: 0.222\n",
      "Fold: 5, TrainF1: 0.518, ValF1: 0.238\n",
      "Fold: 6, TrainF1: 0.453, ValF1: 0.325\n",
      "Fold: 7, TrainF1: 0.504, ValF1: 0.239\n",
      "Fold: 8, TrainF1: 0.507, ValF1: 0.238\n",
      "Fold: 9, TrainF1: 0.473, ValF1: 0.18\n",
      "Fold: 10, TrainF1: 0.517, ValF1: 0.22\n",
      "[[141  35  82  98]\n",
      " [  4   1   3   2]\n",
      " [ 25   6  23  32]\n",
      " [ 24   5  19  29]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        141   35   82   98  356\n",
      "1.0          4    1    3    2   10\n",
      "2.0         25    6   23   32   86\n",
      "3.0         24    5   19   29   77\n",
      "All        194   47  127  161  529\n",
      "TrainF1: 0.489, ValidationF1: 0.236\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_mutual_info_0_10 param= 10000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.428, ValF1: 0.2\n",
      "Fold: 2, TrainF1: 0.308, ValF1: 0.263\n",
      "Fold: 3, TrainF1: 0.333, ValF1: 0.185\n",
      "Fold: 4, TrainF1: 0.217, ValF1: 0.101\n",
      "Fold: 5, TrainF1: 0.199, ValF1: 0.124\n",
      "Fold: 6, TrainF1: 0.369, ValF1: 0.178\n",
      "Fold: 7, TrainF1: 0.435, ValF1: 0.352\n",
      "Fold: 8, TrainF1: 0.217, ValF1: 0.163\n",
      "Fold: 9, TrainF1: 0.359, ValF1: 0.128\n",
      "Fold: 10, TrainF1: 0.393, ValF1: 0.338\n",
      "[[116  49  73 118]\n",
      " [  1   2   3   4]\n",
      " [ 26   8  20  32]\n",
      " [ 16  12  20  29]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        116   49   73  118  356\n",
      "1.0          1    2    3    4   10\n",
      "2.0         26    8   20   32   86\n",
      "3.0         16   12   20   29   77\n",
      "All        159   71  116  183  529\n",
      "TrainF1: 0.326, ValidationF1: 0.203\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] None param= 10000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.563, ValF1: 0.317\n",
      "Fold: 2, TrainF1: 0.517, ValF1: 0.183\n",
      "Fold: 3, TrainF1: 0.526, ValF1: 0.224\n",
      "Fold: 4, TrainF1: 0.52, ValF1: 0.296\n",
      "Fold: 5, TrainF1: 0.532, ValF1: 0.228\n",
      "Fold: 6, TrainF1: 0.535, ValF1: 0.367\n",
      "Fold: 7, TrainF1: 0.505, ValF1: 0.172\n",
      "Fold: 8, TrainF1: 0.525, ValF1: 0.198\n",
      "Fold: 9, TrainF1: 0.488, ValF1: 0.201\n",
      "Fold: 10, TrainF1: 0.524, ValF1: 0.228\n",
      "[[154  25  74 103]\n",
      " [  6   0   4   0]\n",
      " [ 34   5  21  26]\n",
      " [ 29   2  17  29]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        154   25   74  103  356\n",
      "1.0          6    0    4    0   10\n",
      "2.0         34    5   21   26   86\n",
      "3.0         29    2   17   29   77\n",
      "All        223   32  116  158  529\n",
      "TrainF1: 0.524, ValidationF1: 0.241\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] None param= 10000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.219, ValF1: 0.159\n",
      "Fold: 2, TrainF1: 0.267, ValF1: 0.134\n",
      "Fold: 3, TrainF1: 0.256, ValF1: 0.178\n",
      "Fold: 4, TrainF1: 0.218, ValF1: 0.151\n",
      "Fold: 5, TrainF1: 0.232, ValF1: 0.083\n",
      "Fold: 6, TrainF1: 0.202, ValF1: 0.194\n",
      "Fold: 7, TrainF1: 0.253, ValF1: 0.135\n",
      "Fold: 8, TrainF1: 0.241, ValF1: 0.118\n",
      "Fold: 9, TrainF1: 0.186, ValF1: 0.175\n",
      "Fold: 10, TrainF1: 0.171, ValF1: 0.192\n",
      "[[ 62  70 151  73]\n",
      " [  3   1   5   1]\n",
      " [  8  16  50  12]\n",
      " [ 14  19  37   7]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         62   70  151   73  356\n",
      "1.0          3    1    5    1   10\n",
      "2.0          8   16   50   12   86\n",
      "3.0         14   19   37    7   77\n",
      "All         87  106  243   93  529\n",
      "TrainF1: 0.224, ValidationF1: 0.152\n",
      "\n",
      "---------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# '''\n",
    "# Run Multiclass Classification\n",
    "# '''\n",
    "# results = []\n",
    "# param_dict = \"multiclass\" #\"full_cv\", \"language_specific\"\n",
    "# for lang in [\"ger\"]: #, \"ger\"]:    \n",
    "#     if param_dict == \"testing\":\n",
    "#         param_dir = testing_params\n",
    "#     elif param_dict == \"multiclass\":\n",
    "#         param_dir = multiclass_params\n",
    "#     elif param_dict == \"full_cv\":\n",
    "#         param_dir = full_cv_params\n",
    "#     elif param_dict == \"language_specific\":\n",
    "#         if lang == \"eng\":\n",
    "#             param_dir = eng_params\n",
    "#         else: \n",
    "#             param_dir = ger_params\n",
    "    \n",
    "#     #Eng: 606 books, 14146 chunks, 13170 chunks of books published after 1759\n",
    "#     book_df = pd.read_csv(f\"{extracted_features_dir}{lang}/book_df.csv\")\n",
    "#     book_and_averaged_chunk_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/book_and_averaged_chunk_df.csv\")\n",
    "#     #chunk_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/chunk_df.csv\")\n",
    "#     #chunk_and_copied_book_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/chunk_and_copied_book_df.csv\")\n",
    "    \n",
    "#     book_df = drop_default_columns(book_df, drop_default_columns_including)\n",
    "#     book_and_averaged_chunk_df = drop_default_columns(book_and_averaged_chunk_df, drop_default_columns_including)\n",
    "#     #chunk_df = drop_default_columns(chunk_df, drop_default_columns_including)\n",
    "#     #chunk_and_copied_book_df = drop_default_columns(chunk_and_copied_book_df, drop_default_columns_including)\n",
    "    \n",
    "#     for model in [] + [param_dir['model']]:\n",
    "#         model_param = model_params[model]\n",
    "#         for model_param in model_param:\n",
    "#             for dimensionality_reduction in param_dir[\"dimensionality_reduction\"]:\n",
    "#                 for features in param_dir[\"features\"]:\n",
    "#                     for drop_columns_including in [[]]:\n",
    "#                         #try:\n",
    "#                         print(lang, model, features, drop_columns_including, dimensionality_reduction, 'param=', model_param)\n",
    "#                         experiment = MulticlassClassification(\n",
    "#                             language=lang,\n",
    "#                             features=features,\n",
    "#                             drop_columns_including=drop_columns_including,\n",
    "#                             dimensionality_reduction=dimensionality_reduction,\n",
    "#                             model_param=model_param,\n",
    "#                             model=model,\n",
    "#                             verbose=True\n",
    "#                         )\n",
    "#                         mean_train_f1, mean_validation_f1 = experiment.run()\n",
    "#                         results.append((lang, model, features, drop_columns_including, dimensionality_reduction, model_param, mean_train_f1, mean_validation_f1))\n",
    "\n",
    "# results_df = pd.DataFrame(results, columns=[\"lang\", \"model\", \"features\", \"drop_columns_including\", \n",
    "# \"dimensionality_reduction\", \"model_param\", \"mean_train_f1\", \"mean_validation_f1\"])\n",
    "# results_df.to_csv(results_dir + lang + '_' + param_dict + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1720f4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 378 texts without reviews, 197 different books with reviews, 6 of which have opposing reviews and are left out.\n",
    "# 378 + 197 - 6 = 569 texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "162f01d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Run Regression\n",
    "# '''\n",
    "# results = []\n",
    "# param_dict = \"testing\" #\"full_cv\", \"language_specific\"\n",
    "# for lang in [\"eng\"]: #, \"ger\"]:    \n",
    "#     if param_dict == \"testing\":\n",
    "#         param_dir = testing_params\n",
    "#     elif param_dict == \"multiclass\":\n",
    "#         param_dir = multiclass_params\n",
    "#     elif param_dict == \"full_cv\":\n",
    "#         param_dir = full_cv_params\n",
    "#     elif param_dict == \"language_specific\":\n",
    "#         if lang == \"eng\":\n",
    "#             param_dir = eng_params\n",
    "#         else: \n",
    "#             param_dir = ger_params\n",
    "    \n",
    "#     #Eng: 606 books, 14146 chunks, 13170 chunks of books published after 1759\n",
    "#     #book_df = pd.read_csv(f\"{extracted_features_dir}{lang}/book_df.csv\")\n",
    "#     book_and_averaged_chunk_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/book_and_averaged_chunk_df.csv\")\n",
    "#     #chunk_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/chunk_df.csv\")\n",
    "#     #chunk_and_copied_book_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/chunk_and_copied_book_df.csv\")\n",
    "    \n",
    "#     #book_df = drop_default_columns(book_df, drop_default_columns_including)\n",
    "#     book_and_averaged_chunk_df = drop_default_columns(book_and_averaged_chunk_df, drop_default_columns_including)\n",
    "#     #chunk_df = drop_default_columns(chunk_df, drop_default_columns_including)\n",
    "#     #chunk_and_copied_book_df = drop_default_columns(chunk_and_copied_book_df, drop_default_columns_including)\n",
    "    \n",
    "#     for model in [] + [param_dir['model']]:\n",
    "#         model_param = model_params[model]\n",
    "#         for model_param in model_param:\n",
    "#             for dimensionality_reduction in [param_dir[\"dimensionality_reduction\"]]:\n",
    "#                 for features in [param_dir[\"features\"]]:\n",
    "#                     for drop_columns_including in [[]]:\n",
    "#                                                         #try:\n",
    "#                         experiment = Regression(\n",
    "#                             language=lang,\n",
    "#                             features=features,\n",
    "#                             drop_columns_including=drop_columns_including,\n",
    "#                             dimensionality_reduction=dimensionality_reduction,\n",
    "#                             model_param=model_param,\n",
    "#                             model=model,\n",
    "#                             verbose=True\n",
    "#                         )\n",
    "#                         print(lang, model, features, drop_columns_including, dimensionality_reduction, 'param=', model_param)\n",
    "#                         mean_train_mse, mean_train_rmse, mean_train_mae, mean_train_r2, mean_train_corr, mean_validation_mse, mean_validation_rmse, mean_validation_mae, mean_validation_r2, mean_validation_corr, mean_p_value, datetime = experiment.run()\n",
    "#                         results.append((lang, model, features, drop_columns_including, dimensionality_reduction, model_param, mean_train_mse, mean_train_rmse, mean_train_mae, mean_train_r2, mean_train_corr, mean_validation_mse, mean_validation_rmse, mean_validation_mae, mean_validation_r2, mean_validation_corr, mean_p_value))\n",
    "#                         #except Exception as e:\n",
    "# #                             print(f\"Error in {lang}, {model}, {features}, {drop_columns_including}, {dimensionality_reduction}\")\n",
    "# #                             print(e)\n",
    "# results_df = pd.DataFrame(results, columns=[\"lang\", \"model\", \"features\", \"drop_columns_including\", \n",
    "# \"dimensionality_reduction\", \"model_param\", \"mean_train_mse\", \"mean_train_rmse\", \n",
    "# \"mean_train_mae\", \"mean_train_r2\", \"mean_train_corr\", \"mean_validation_mse\", \"mean_validation_rmse\",\n",
    "# \"mean_validation_mae\", \"mean_validation_r2\", \"mean_validation_corr\", \"mean_p_value\"])\n",
    "# results_df.to_csv(results_dir + lang + '_' + regression_' + param_dict + datetime + \".csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
