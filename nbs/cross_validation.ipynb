{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15df4db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsentiment file names for eng/ger\\nMerge labels and features depending on how labels are aggregated if there are multiple scores for a work.\\ndrop_column reset index???\\nchunk based features?\\ncomplexity features\\ntake out doc2vec_chunk_embedding from default drop columns\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "sentiment file names for eng/ger\n",
    "Merge labels and features depending on how labels are aggregated if there are multiple scores for a work.\n",
    "drop_column reset index???\n",
    "chunk based features?\n",
    "complexity features\n",
    "take out doc2vec_chunk_embedding from default drop columns\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c12bfc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../src/\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "extracted_features_dir = \"../data/extracted_features/\"\n",
    "results_dir = \"../data/results/\"\n",
    "sentiment_dir = \"../data/evaluationscore/\"\n",
    "canonization_labels_dir = \"/home/annina/scripts/great_unread_nlp/data/labels/\"\n",
    "lang = \"ger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2696499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GER_reviews_senti_classified.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmwAAAE4CAYAAADmYq9ZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABIzklEQVR4nO3debwdVZX3/88iDA6ogERkDmpQ44SaBqduRVABbRNt7AZbxeFpmp/i7E9jd/ugPSjaODSK0qDYoCiNKBAhygyKMiSEkIGQkZCEzPN8b26ynj/W2lTlcO6Q3ENybvJ9v173dc6pU8Peu/betWpXnbrm7oiIiIhI+9prVydARERERHqmgE1ERESkzSlgExEREWlzCthERERE2pwCNhEREZE2p4BNREREpM3tvasT0EoHH3ywDxkyZFcnQ0RERKRXDzzwwDJ3H9yXeXergG3IkCGMGzduVydDREREpFdm9lhf59UlUREREZE2p4BNREREpM0pYBMRERFpcwrYRERERNpcSwI2MzvFzKaZ2UwzG9Xk+5eY2T1m1mFmX2j4bo6ZTTKzCWY2rjb9IDO7xcxm5OuBrUiriIiIyEDT74DNzAYBFwGnAsOAM81sWMNsK4BPARd0s5oT3f04dx9emzYKuM3dhwK35WcRERGRPU4rRtiOB2a6+2x37wSuAkbUZ3D3Je4+Fti8HesdAVye7y8HRrYgrSIiIiIDTisCtsOBebXP83NaXzlws5k9YGZn16Yf4u4LAfL1ef1OqYiIiMgA1IoH51qTab4dy7/R3ReY2fOAW8zsEXf/Q583HkHe2QBHHXXUdmxWREREZGBoxQjbfODI2ucjgAV9XdjdF+TrEuBa4hIrwGIzOxQgX5d0s/wl7j7c3YcPHtyn/+4gIiIiMqC0ImAbCww1s2PMbF/gDGB0XxY0s2ea2bPKe+DtwOT8ejRwVr4/C7i+BWkVERER2aWGjLqRIaNu3K5l+n1J1N27zOxc4CZgEHCZu08xs3Py+4vN7PnAOODZwFYz+wzxi9KDgWvNrKTlF+7++1z1+cDVZvYxYC7wvv6mVURERGQgask/f3f3McCYhmkX194vIi6VNloDvKqbdS4HTmpF+kREREQGMv2nAxEREZE2p4BNREREpM0pYBMRERFpcwrYRERERNqcAjYRERGRNqeATURERKTNKWATERERaXMK2ERERETanAI2ERERkTangE1ERESkzSlgExEREWlzCthERERE2pwCNhEREZE2p4BNREREpM0pYBMRERFpcwrYRERERNqcAjYRERGRNqeATURERKTNKWATERERaXMK2ERERETanAI2ERERkTangE1ERESkzSlgExEREWlzLQnYzOwUM5tmZjPNbFST719iZveYWYeZfaE2/Ugzu8PMpprZFDP7dO27r5rZ42Y2If9Oa0VaRURERAaavfu7AjMbBFwEvA2YD4w1s9Hu/nBtthXAp4CRDYt3AZ939/Fm9izgATO7pbbsd939gv6mUURERGQga8UI2/HATHef7e6dwFXAiPoM7r7E3ccCmxumL3T38fl+LTAVOLwFaRIRERHZbbQiYDscmFf7PJ8dCLrMbAjwauC+2uRzzWyimV1mZgf2K5UiIiIiA1QrAjZrMs23awVm+wO/Bj7j7mty8o+AFwLHAQuBb3ez7NlmNs7Mxi1dunR7NisiIiIyILQiYJsPHFn7fASwoK8Lm9k+RLB2pbv/pkx398XuvsXdtwKXEpden8TdL3H34e4+fPDgwTuUAREREZF21oqAbSww1MyOMbN9gTOA0X1Z0MwM+Akw1d2/0/DdobWP7wEmtyCtIiIiIgNOv38l6u5dZnYucBMwCLjM3aeY2Tn5/cVm9nxgHPBsYKuZfQYYBrwS+CAwycwm5Cr/yd3HAN8ys+OIy6tzgH/sb1pFREREBqJ+B2wAGWCNaZh2ce39IuJSaaO7aX4PHO7+wVakTURERGSg0386EBEREWlzCthERERE2pwCNhEREZE2p4BNREREpM0pYBMRERFpcwrYRERERNqcAjYRERGRNqeATURERKTNKWATERERaXMK2ERERER2giGjbtzhZRWwiYiIiLQ5BWwiIiIibU4Bm4iIiEibU8AmIiIi0uYUsImIiIi0OQVsIiIiIm1OAZuIiIhIm1PAJiIiItLmFLCJiIiItDkFbCIiIiJtTgGbiIiISJtTwCYiIiLS5hSwiYiIiLS5lgRsZnaKmU0zs5lmNqrJ9y8xs3vMrMPMvtCXZc3sIDO7xcxm5OuBrUiriIiIyEDT74DNzAYBFwGnAsOAM81sWMNsK4BPARdsx7KjgNvcfShwW34WERER2eO0YoTteGCmu892907gKmBEfQZ3X+LuY4HN27HsCODyfH85MLIFaRUREREZcFoRsB0OzKt9np/T+rvsIe6+ECBfn9fPdIqIiIgMSK0I2KzJNN8Jy8YKzM42s3FmNm7p0qXbs6iIiIjIgNCKgG0+cGTt8xHAghYsu9jMDgXI1yXNVuDul7j7cHcfPnjw4O1KuIiIiMhA0IqAbSww1MyOMbN9gTOA0S1YdjRwVr4/C7i+BWkVERERGXD27u8K3L3LzM4FbgIGAZe5+xQzOye/v9jMng+MA54NbDWzzwDD3H1Ns2Vz1ecDV5vZx4C5wPv6m1YRERGRgajfARuAu48BxjRMu7j2fhFxubNPy+b05cBJrUifiIiIyECm/3QgIiIi0uYUsImIiIi0OQVsIiIiIm1OAZuIiIhIm1PAJiIiItLmFLCJiIiItDkFbCIiIiJtTgGbiIiISJtTwCYiIiLS5hSwiYiIiLQ5BWwiIiIibU4Bm4iIiEibU8AmIiIi8hQZMupGhoy6sd/rUcAmIiIi0uYUsImIiIi0OQVsIiIiIm1OAZuIiIhIm1PAJiIiItJirfihQZ0CNhEREZE2p4BNREREpM0pYBMRERFpcwrYRERERNqcAjYRERGRNteSgM3MTjGzaWY208xGNfnezOzC/H6imb0mp7/YzCbU/taY2Wfyu6+a2eO1705rRVpFREREngqt+jdUzezd3xWY2SDgIuBtwHxgrJmNdveHa7OdCgzNvxOAHwEnuPs04Ljaeh4Hrq0t9113v6C/aRQREREZyFoxwnY8MNPdZ7t7J3AVMKJhnhHAFR7uBQ4ws0Mb5jkJmOXuj7UgTSIiIiK7jVYEbIcD82qf5+e07Z3nDOCXDdPOzUuol5nZgS1Iq4iIiEhLPVWXQetaEbBZk2m+PfOY2b7Au4Ff1b7/EfBC4pLpQuDbTTdudraZjTOzcUuXLt2OZIuIiIgMDK0I2OYDR9Y+HwEs2M55TgXGu/viMsHdF7v7FnffClxKXHp9Ene/xN2Hu/vwwYMH9yMbIiIiIu2pFQHbWGComR2TI2VnAKMb5hkNfCh/Lfo6YLW7L6x9fyYNl0Mb7nF7DzC5BWkVERER6ben8hehzfT7V6Lu3mVm5wI3AYOAy9x9ipmdk99fDIwBTgNmAhuAj5TlzewZxC9M/7Fh1d8ys+OIS6dzmnwvIiIiskfod8AG4O5jiKCsPu3i2nsHPtHNshuA5zaZ/sFWpE1ERERkoNN/OhARERFpcwrYRERERNqcAjYRERGRNqeATURERKTNKWATERERaXMK2ERERETanAI2ERERkT7amQ/LrVPAJiIiItKDnf1fDZpRwCYiIiLS5hSwiYiIiLQ5BWwiIiIibU4Bm4iIiEibU8AmIiIi0uYUsImIiIi0OQVsIiIisscrj+2oP8JjVz/Ko04Bm4iIiEibU8AmIiIie6R2eCBuXylgExEREWlzCthERERE2pwCNhEREdmjDJTLoHUK2ERERETanAI2ERER2W01e1zHQKSATURERKTNtSRgM7NTzGyamc00s1FNvjczuzC/n2hmr6l9N8fMJpnZBDMbV5t+kJndYmYz8vXAVqRVREREZKDpd8BmZoOAi4BTgWHAmWY2rGG2U4Gh+Xc28KOG70909+PcfXht2ijgNncfCtyWn0VERET2OK0YYTsemOnus929E7gKGNEwzwjgCg/3AgeY2aG9rHcEcHm+vxwY2YK0ioiIiAw4rQjYDgfm1T7Pz2l9nceBm83sATM7uzbPIe6+ECBfn9eCtIqIiMhuqh3/B2irtCJgsybTfDvmeaO7v4a4bPoJM/ur7dq42dlmNs7Mxi1dunR7FhUREZEBbncMzpppRcA2Hziy9vkIYEFf53H38roEuJa4xAqwuFw2zdclzTbu7pe4+3B3Hz548OB+ZkVERESk/bQiYBsLDDWzY8xsX+AMYHTDPKOBD+WvRV8HrHb3hWb2TDN7FoCZPRN4OzC5tsxZ+f4s4PoWpFVERER2A3vKyFrR74DN3buAc4GbgKnA1e4+xczOMbNzcrYxwGxgJnAp8PGcfghwt5k9BNwP3Ojuv8/vzgfeZmYzgLflZxEREdnD7M73pvVVS57D5u5j3P1Yd3+hu/9HTrvY3S/O9+7un8jvX+Hu43L6bHd/Vf69rCyb3y1395PcfWi+rmhFWkVERKQ9NAvEFJw1p/90ICIiItLmFLCJiIjITqORsx2jgE1ERESkzSlgExERkaecRtb6RwGbiIiISJtTwCYiIiJPCY2qtY4CNhEREWkpBWqtp4BNRERE+k1B2lNLAZuIiIjsMAVqO4cCNhEREelW/T8P6L8Q7DoK2ERERGQb9eBM2oMCNhEREQE0ctbOFLCJiIiItDkFbCIiInswXf4cGBSwiYiIiLQ5BWwiIiK7Of3Sc+BTwCYiIiLS5hSwiYiIDHDNRs50b9ruRQGbiIjIAKWAbM+hgE1ERKRNaeRMCgVsIiIibUYBmTRSwCYiIrILaeRM+kIBm4iIyE6i4Ex2VEsCNjM7xcymmdlMMxvV5Hszswvz+4lm9pqcfqSZ3WFmU81sipl9urbMV83scTObkH+ntSKtIiIirdbs2WZ63pm0Ur8DNjMbBFwEnAoMA840s2ENs50KDM2/s4Ef5fQu4PPu/lLgdcAnGpb9rrsfl39j+ptWERGR/lIgJrtCK0bYjgdmuvtsd+8ErgJGNMwzArjCw73AAWZ2qLsvdPfxAO6+FpgKHN6CNImIiOwQjZJJO2pFwHY4MK/2eT5PDrp6ncfMhgCvBu6rTT43L6FeZmYHtiCtIiIiT2gWnIm0o1YEbNZkmm/PPGa2P/Br4DPuviYn/wh4IXAcsBD4dtONm51tZuPMbNzSpUu3M+kiIrK76+n+MpGBohUB23zgyNrnI4AFfZ3HzPYhgrUr3f03ZQZ3X+zuW9x9K3Apcen1Sdz9Encf7u7DBw8e3O/MiIjIwKJLmLInaEXANhYYambHmNm+wBnA6IZ5RgMfyl+Lvg5Y7e4LzcyAnwBT3f079QXM7NDax/cAk1uQVhERGSCaPQJDj8WQPVW/AzZ37wLOBW4ifjRwtbtPMbNzzOycnG0MMBuYSYyWfTynvxH4IPDWJo/v+JaZTTKzicCJwGf7m1YREdk1egu6FIiJ9GzvVqwkH7kxpmHaxbX3DnyiyXJ30/z+Ntz9g61Im4iI7DpDRt3InPPfuauTITLg6T8diIhIS2mUTKT1FLCJiIiItDkFbCIist16ug9NRFpPAZuIiDxBPwgQaU8K2EREdgO9PYust2kKxETamwI2EZE21tegS0R2bwrYRETahAIxEemOAjYRkV1MwZmI9EYBm4jITqRfVIrIjlDAJiKyg3p7tIWCMxFpFQVsIrJH6+tjLPSLShHZlRSwicgeQ0GXiAxUCthEZMDTiJiI7O4UsIlI21IgJiISFLCJyE6np+6LiGwfBWwi0i878i+RRERk+yhgE5E+05P4RUR2DQVsItKUgjMRkfahgE1EFJyJiLQ5BWwiexgFZyIiA48CNpHdTG//JklERAYeBWwiA0Rf/3WSiIjsfhSwiewi2/s/LEVEZM/VkoDNzE4xs2lmNtPMRjX53szswvx+opm9prdlzewgM7vFzGbk64GtSKvIrqSHwoqIyI7od8BmZoOAi4BTgWHAmWY2rGG2U4Gh+Xc28KM+LDsKuM3dhwK35WeRAUlBmoiI9EcrRtiOB2a6+2x37wSuAkY0zDMCuMLDvcABZnZoL8uOAC7P95cDI1uQVpGnnP7FkoiItForArbDgXm1z/NzWl/m6WnZQ9x9IUC+Pq8FaRXZLn29v0zBmYiIPKXcvV9/wPuAH9c+fxD4fsM8NwJvqn2+DXhtT8sCqxrWsbKb7Z8NjAPGHXXUUX70l25wd/ejv3TDNu+7m9b4fbtP60ue2n1au5RlX6aJiIg8VYBx3sd4qxUjbPOBI2ufjwAW9HGenpZdnJdNydclzTbu7pe4+3B3Hz548OAdzoTInPPf2fS9iIjIrtaKgG0sMNTMjjGzfYEzgNEN84wGPpS/Fn0dsNrjMmdPy44Gzsr3ZwHXtyCtsocrgZiCMxERGUj27u8K3L3LzM4FbgIGAZe5+xQzOye/vxgYA5wGzAQ2AB/padlc9fnA1Wb2MWAucflUpEfNAjEFZCIiMtD1O2ADcPcxRFBWn3Zx7b0Dn+jrsjl9OXBSK9InA19vgZiCMhER2Z3pPx3ILtFT0KVATEREZFstGWET6Y6CLxERkf5TwCYto+BMRETkqaFLotJvCs5ERESeWhphk+2iX16KiIjsfArYpFsKzkRERNqDLomKiIiItDmNsMk2NJomIiLSfjTCJoACNRERkXamEbY9mII0ERGRgUEB225O/z1ARERk4NMlUREREZE2p4BNREREpM3pkugA1dd/ni4iIiIDnwK2NqVATERERApdEm0zCspERESkkQI2ERERkTangK0NaFRNREREeqKAbRdSoCYiIiJ9oYDtKaQfDoiIiEgrKGBrEf0nAREREXmqKGATERERaXMK2ERERETaXL8CNjM7yMxuMbMZ+XpgN/OdYmbTzGymmY2qTf9PM3vEzCaa2bVmdkBOH2JmG81sQv5d3J90ioiIiAxk/R1hGwXc5u5Dgdvy8zbMbBBwEXAqMAw408yG5de3AC9391cC04Ev1xad5e7H5d85/UxnS+l+NREREdmZ+huwjQAuz/eXAyObzHM8MNPdZ7t7J3BVLoe73+zuXTnfvcAR/UzPU0rBmYiIiOwK/Q3YDnH3hQD5+rwm8xwOzKt9np/TGn0U+F3t8zFm9qCZ3WVmf9nPdIqIiIgMWL3+83czuxV4fpOv/rmP27Am07xhG/8MdAFX5qSFwFHuvtzMXgtcZ2Yvc/c1TdJ3NnA2wFFHHdV0Y/2hUTURERHZ1XoN2Nz95O6+M7PFZnaouy80s0OBJU1mmw8cWft8BLCgto6zgHcBJ7m75zY7gI58/4CZzQKOBcY1Sd8lwCUAw4cP92W9ZaiPFKiJiIhIu+jvJdHRwFn5/izg+ibzjAWGmtkxZrYvcEYuh5mdAnwJeLe7bygLmNng/LECZvYCYCgwu59pFRERERmQ+huwnQ+8zcxmAG/Lz5jZYWY2BiB/VHAucBMwFbja3afk8j8AngXc0vD4jr8CJprZQ8A1wDnuvqKfae2VRtVERESkHfV6SbQn7r4cOKnJ9AXAabXPY4AxTeZ7UTfr/TXw6/6kTURERGR3of90gEbWREREpL0pYBMRERFpcwrYRERERNqcAjYRERGRNqeATURERKTNKWATERERaXMK2ERERETanAI2ERERkTangE1ERESkzSlgExEREWlze2zApv9uICIiIgPFHhuwiYiIiAwU/frn7wONRtVERERkINojRtgUqImIiMhAtkcEbCIiIiIDmQI2ERERkTangE1ERESkzSlgExEREWlzCthERERE2txu+1gP/TJUREREdhe73QibAjURERHZ3ex2AZuIiIjI7kYBm4iIiEib61fAZmYHmdktZjYjXw/sZr5TzGyamc00s1G16V81s8fNbEL+nVb77ss5/zQze0d/0ikiIiIykPV3hG0UcJu7DwVuy8/bMLNBwEXAqcAw4EwzG1ab5bvuflz+jcllhgFnAC8DTgF+mOsRERER2eP0N2AbAVye7y8HRjaZ53hgprvPdvdO4Kpcrrf1XuXuHe7+KDAz1yMiIiKyx+lvwHaIuy8EyNfnNZnncGBe7fP8nFaca2YTzeyy2iXV3pYRERER2WP0GrCZ2a1mNrnJX2+jZE+sosk0z9cfAS8EjgMWAt/uwzKN6TvbzMaZ2bilS5f2MUkiIiIiA0evD85195O7+87MFpvZoe6+0MwOBZY0mW0+cGTt8xHAglz34tq6LgVu6G2ZJum7BLgEYPjw4U2DOhEREZGBrL+XREcDZ+X7s4Drm8wzFhhqZseY2b7EjwlGA2SQV7wHmFxb7xlmtp+ZHQMMBe7vZ1pFREREBqT+/muq84GrzexjwFzgfQBmdhjwY3c/zd27zOxc4CZgEHCZu0/J5b9lZscRlzvnAP8I4O5TzOxq4GGgC/iEu2/pZ1pFREREBiRz332uIg4fPtzHjRu3q5MhIiIi0isze8Ddh/dlXv2nAxEREZE2t1uNsJnZUuAx4GBgWe0VTet1WjukYU+b1g5p2NOmtUMa9rRp7ZCGPW1aO6RhT5u2o+t5prsPpi/cfbf7A8bVXzWt92ntkIY9bVo7pGFPm9YOadjTprVDGva0ae2Qhj1tWn/X05c/XRIVERERaXMK2ERERETa3O4asF3S8KppvU9rhzTsadPaIQ172rR2SMOeNq0d0rCnTWuHNOxp0/q7nl7tVj86EBEREdkd7a4jbCIiIiK7DQVsIiIiIm1u712dABER2bOZ2QuJ/yd9JPHvCGcAjwIvA1YT/7rwPndfV1vmFHf//Q5s6yXACOBw4t8iLgBGu/vU7VzP8YC7+1gzGwacAjzi7mO2N027Su3/ey9w91vN7P3AG4CpwCXuvrmHZU8Aprr7GjN7OjAKeA3xLyW/7u6r+5iGK9z9Q/3NS219nwKudfd5rVpnu9jj7mEzs+e5+5J8b8DxbNtw73d3N7Pnuvvy7VjvPo2V28wOdvdl3S2znek+Cljj7qvMbAgwnOgcJu/g+vYCcPet2WhfDsxx9xXdzP9xd//hjqW+x3TsC2z2rIhmdiLZ6N39d70sO5xaB+/uj3Qz3/7AscDsLL+WlmUP6eu1TvRUB3dge69094n9THbbbOep1s+690Q/0sM8L+muTjaZt9v21dd6vqOa9AVn5Fdr6UN93J58drP8p4C/JoKzOcAE4GjgpHz/KmA28Czgk+5+fS43HnhbYz9tZh9x95/W+/Cyv8zsS8CZwFXAKmAdcETm+Sp3P79hXdv0HbXp3wf+ghj0uAU4AbgTOBm4yd3/o4f8PqnubO/xpj8ayuVKIg/PIMpjf+A3RNmbu5/Vw3qmAK/y+H/hlwAbgGty2Ve5+3ubLDO6cRJwInA7gLu/u3+5AzNbQ+zXWcBvgZ+6+9L+rrdhG722/ybL9H8fb89D29rxD3hlD999ATiIaPy3A9OBLcBGoBPYmq/rgT/lPOvy82yiAs8GrgZeBLwWOBDYj+jYDwHOBh4HlhIN904iALgDWAP8OzCeOEt8PP825ronA98HTicafAmgjTgD/Dzw98BFxNnmI8B38/Ua4izoPmAi8AvghcA3gF8C/wUcUMoIuC7XdyrwN8BiYGFu577M92rgH4DP5d9XgP8/l1uW035YW8+/18r64/X9QTT81wAHNNtHwCsynw/l+k4kGtfDwMU5/delXHI9ZX1vBsYBdwErgRuyTCYDXwP+QBwAXgK8F5iX+2NBLrccmA/8Ry53PTA3y+jrZdnavjgh1/OeWnrOze+H5/R3A6/PaW/L8l0G3AwMqa1vAvB3mY93Z9puAX6cf78HZgIfBf6KqG/HEHXklJz2itynpwNvz9eTibo9E7gQuBR4ecM+adpWiFsj9gI+DuxLBJAHNcxzUubzfKLdLAQuJ+rDFKLuLAXGAjdmua4DVhD19Ls5fU7utzc2KduP1t7/FdkecvsnAl8l6l29zN8K/CvRTruATUR7m0zV5mYRbXEpMAn4Qe7jR7J8v0hV9/4tl1mR+/A3wPuAP+Y6HgTekvk4MNNQ2sO+mafnZDl1EX3JWmBaTns70Va/ldv6H6K+L8/1/BvwQeAnwD25nVup6vnCnP6y3F9DMu8XEm35DuDnRIB3S5bBA8BlwM+A9wMHZ5kelfMszu3/L9CR79cTdbfUx7fnMs8n2tdFwHNzn3QC12Yafga8P+cdQvRH03K7exF19Y5cZynXLbnPNgOHAXdnPt9C9JVvy22szvRdSNSBjlzPY8CVtXwtznKbnftyTM772tyvM4m6+Wgu++Ysr3W53b/NfM3KcriX2Pfzcp9uIE6uvkn0vZuIAAXg6Tnt+UQbvBY4LufdSNSxtURffRDwjlz3qtprV/5tzmVW5DYWEsewXwCH1PqnE4m+cnlu50e1/bMwt3k10WZWEe13S25jS857Z05fAPyOqPebqNr1EuL4eFGW4905f0embyNRvw+o9XOlbY+n6jfHE/VzXL7enGn4MfCNXPaHRD14MNOwmehLpwL/H9E2Juf+KcfC44g2fRxRV14AnJVlvQy4P5e/iqptdGWZ31ibtp7ow15NtOOf5DzXAC+mOm7MJ9r/QbU+qvRLf038+vPg2vTZmd5VRL1bnem8F/hwn+OdXR1wtSBgKwepm7Oyfo44AF9PNKr1uWO2ZsXyrICbgdty2WnEwWdWFuaK3Mn/STS+0bnc5lxPF9FwOrNCLQM+TVT2LuIA9uP8bktWrulER7UuK08n0bFszmU2Ep3MqKwMpfGsy+9mEYHWFmAwEWD8D9GQrgA+m/P/PPPnRMfy7lzXVqIBdOT7O4E3ZfksyvnnZbq25LyL87tv5LoeIQ4cD+d2PdM3LfP6uVz3/KyQ9+U6yz76t9o+6gL+mehQ1me5r8vtzCIa14osq/r+W5DfDyYa/99lmjpyO52ZruW1bc8DvlPbfyuJDqMrl5tO1Ul6LrMg8zsn03Jv/s3N77dmnmdnuku5Tsr83Jfl8ABxeWcR0QmW9JU8PZjpu6FWp6/MeTZRda4zqOrelszLH3O7c3O9m4H/S9RHz/nLScrM/PxYw364jOjU1lC1lRL4fIwqOF6f6ynbXpr7qivLaGzOUw6iC3O9pYNbn/OvJurOlkxjJ9GJbcx1rqvlewMRvFxc279dWV6lzEu93UAcnDfkuv6Ueb8817cql52U6y4H4/L6ONEflHq4Fbgp35c6sSjzXg4iK3Kd9+Q+2AD8d27/0fzuJqqDbtl2aZvrcrv1+rSFql8oB+w/EW1wUpbfmlp5lHJYltubRvQHS4k2sJSo74uAkURftpJoe4/mdj+X2/Kc9jlixH1hpmVDbX+Uk91STiVPm7Mcz85t/DrL/Pws4/szf06cVJX6WerTwtq+7AA2ZFvYRPSb03Jbx1Ed7DYRfevyXHZuzuNZrmsyvSVvpW97gOjbVxMH03GZxs5cZm1uc2F+tyFfl+Yy49m2v1ya215M9MOTib6iHG8811n6eacKjFdmWqYT7WIBcUJzfS7zJSKQWEe03Y5M1wziWDGP2PfT87vydz1Vv3Ya0d43EwHLYuK4Nj3LaVWmeXPut7VEwLWW6E++ntsfR/Q5W6kGJ36e27qJGCi4lwh2O3Idt2ee/5xp/QTw7dwPlxF10qmOp/cTfcZ8oh6dkOmbShxXpxPB4gzimO+5T0q7Kn+ba3+P5+u4zMcSos1uIU72luf3D+V6/zHLZ1Lmp8QRpe8u+7D0uXflsqUersp5/pjlsiHz/yfiZGM6cTxaCwwl+qiv7ykB24NE59KRBbCIquPanIW4kWgY5wFdudwMYih4I3Fg3ofoAO4jDjidOd+kXO/MrDClA+/KbW/JnVGGYTfl38z8vrO2nXFZiafmDt6QaX+EOPA/mvPfk9MuJIKyzfm6Iivm96lGDJZnBbww0zSfaJRbgAuogqCpRGcwN9fx89zeJuJsfQNx9ruJ6Ahm5TpKJ1wCpn/Nsp6c5XAfccD2LPs1mcefZMVdkeu5ljiol0DEiVGXuZnuf8u8v5poLA/mNsbm+h4lzpRX5/wXZr6X5t8W4sxvTS53d+Z9BtH5biFG6DYCz6TqoIZnesqyU4gOeXZ+Xw6IvyU6r8eJBubEiNzynHcMVcPfnOn7ab6/kmpkd2rmbULmY2ZO6wSGZJ1bn/txYr5/OJc/IdNSDpSduY0uIlDoymmX5vxnUY0GbCDq8eNEh72V6uD/37kvnKgX9xIdbRfRbi7N99dkfsYTox5ridG/R3NfdGRZrskyGU+Mbm/I9E4jOvoHct4rM/8zc91fJ9rFrNw/H8/8bMx9t4EIIjtqZb4py2hdlt1Dmbe92PZg/2Du23H5eS3Rbudken9P/F+/rZnmko+pWQZ35vKTc12P535ZT4yifzXL5rws+0eJA+kUYrR5Sk6fRYyOllGDh4mRkK25X1+b8x2XaTiaqAtbiPa0mWgr5aSsnNCMy+9GEiMUpW2eTdXOrybq5bqc9yf52pnl0QE8O/N4U+ZxHfCrXF8JPruIk48NuR9WUrXRGbmdP2eeLiHqxpJMYwleFuW63k70AROpDoJL8/WVVMHEBKJP3JsqSNxCjAb9MPNxa37uyv35cO6r0lbmEqPUm2rzXZLp2Uqc3I6vpWdLlt9moi09RtSXs3LaybmORUQ9W0ScqJeT8H8nrvJsIvuVrKNbidHDH+b7smwJOKflfCVonVZ770T7KVeIVlPV842Z3wuo+tktRN29I6fV55tEBJhlNG8+cdJSTmxupQout1Idn0pg/yhxXConTmVgYEvuLyfqxpZc98LadpyoK2W//zNR195JVbfvyPIfT9S18VT1oJTH40S/+2iW9V3A1lp84ERfVoLwuzI90/O7ibmOEjRuzvnW5rTFVCfMS7NszqMauLiB6gT3Yqpjz0aijpX6PiPnuyPzeUdJJ9FXPdKXeGd3+JWoe9x7NJToUG4mzjCPpLrkshp4GjFc32VmbyI6lXLgupdoBPsQlwkWAWvN7GtEBRlEVJhOosFuIu5peHW+fy9x0JlI7MgpwKHEJbmtwKeIHff0fH0OsfMt025ExzQy0/C83N5HiI6vI9f1DKJCvYu4/HIwUVE3ZPrLmcXvcrv/Q1Tm/YiDxlLifozNRAf6tFzPsVmW1xJnQR8hKv+cTNvHqM4mn01ckpuey5zo7kPyu3cTFXUY8NIst4tzvr8iLgN+jujknbiXZAVRYYdmWf46992xxAF8X6pO4C+JMxMj77Eggq+S92k5/wuIA98ziEsTz8/vJ+c2LiX283qiwxpEnPltybKGasSzjGCeRJx5LScuG+PuIzNfhxHD5QdQjTzOpLrMcDNRB/cj7pfx3NYSojHfmml4wMzmEPXkIqqAuYO41+o+quBrM3Hwuje3UQ6Qm4gzOXf3y7OsH8x8lpGSxcTBer8sv3cS7cTd/QNEAF/OxPenCvrGZJmbu9+SaT4607k28zuptp3nEaPC+2QZzctplmV8FtW9e2cS7cjy85rM06Lcp8PyuyuJA1sp865M515m9pVcFqoz9yGZtgOIA8V+uQ/3Bc4hLkvtTwRN03Ibv860riDq0Bqi7ziMqEv75ftDcj+cSlyW2ivLEqpAs4wKlr72UaJ/WEns26NzWbLcHsx1Tszl/2/t89NzPd/LPAC8Lr/7bH6+jKiTW4ig5fW5zEzihGxvIlBcQ1yOM6LOdBDBxl1Ev/IKqpPDk6lGy6YTB5r3Uo0SrMoyWZvlfjrRb24lRnf2yrx8P6ftR9Sd5cTBbz/iMnUXcdl+MHF5+ALigH0rcbD+fe6jhbn+O4lbVZZmuZWrEh05rfQjkzO/5YTmm1SjMkdRndz9kehnn5bLORGkbSL2+wZgRbarBUQfs4Gow98k6vko4iRwC3C4u19AnBAdBhxuZs/K7/6JOElZkuU3KNP3CPCYmX0R2MfMbsh9tHfef7eeuN/uESL4PzPTd1Lu171y3VuoRrQ7qU6I9868Hky0m7X5eXq+/26m40J3PznLZBCwxd3LyVkXcdn1de7+YSIYmUO0kbuJPmc4Uc+Pz7J6DnGyv4IIzrYQI++3Ev3Of2T6fpLb6yCCodfnPtqL6NePJNrsoLz/dzkRcB2YZXw24Gb2nSzrzUS/PZkYpf5BbvuLub0jqUbMy0nrlNwnczP/64k2vg/hO+RVHXd/FxG4rSHqcSfRZywjbvvYTJxU35jvHyWOs9/JPOLuW6n6xJ7t6hGyVoywNXweQRywTs/K8SfiwFAuLdYvKy3KHfj9LNByRj2J6qygvL+e6BRelzvy9KxYjxKjQpOJM8JHidGYhbnzbqEadSmXwdZmWpYT94hdTtXBlxG8jqw4X810ziGGnL9Gdbl1OXHNfENWmk35/sBM+0NZsdbk+pcRHd2/EJ2SUY1mbCYObh8ggooJmc4TiE5lMRG4lMskszI/pay3Uh1k1hIHrtuJSrsxt/Xm2n5aTjSEsp0y+teZ6yyX+jZn+X+ttr5HqALIu4mDVLkMdXuW/08z37/N9Zey+GOW6wzijH91/i0nDggriVGIR4iD5SbissT7iSCmpKuD6FzeT3WZr4u4x2IucaP0oFq5lDPTxbUyepgIbL+c3y2jGqX7FdFp/DJfx1Ndvnss51md+3lpfrci5/8Z1QjK1WQbIervE/sh3y/I8v6/mcbnZxm+iagXV9XStDLT/gPgw7V9uImoty8m6t7/1vJZgrdFRFCxjBiZLKOYHbmNOVSjmdcRnefGnG8F1Vn+0tx+KfP6CORK4v6qJVkuHVQjSCuI/f5HqjPuK4j7gcpl89W5vhfl/htHHAxeQtSJcqm89CPXEnXu8pz3S0Q9W59lVy7BbaW6b/Ux4gRjVub57kz31tq++yNx0vUr4kSinCScluW5NLezJee/h9jXNxMnrWOpRkZXUt2yUS4TryVO5u7I9f1vlv3fE8FqGXWYTowSDcvvxuV3G2rteBxRZy4B/pDTynY6iQBmBlH39sr1Ts0yqpfrBmB5Q1/+lkxbGQ0aQ1xOu7o2bR1xQN6nNn8JsjYSI5BjifpXX9+0LMd5WYYPEfXxfzOPnyL681cTff+FRJ0qdWkqEaT9ppbeDVSX0jqAI2ojKJOJuvlgpq2kZSFRL28m+p9HiHpS6nu5LL4p0/Bhog+8gug3HiQC169n2dyaebkS+D9Z9icSx7dVmedSNuUKwqXEifUmok5+KMttFVE/v5DpuZQ4Xs3JvD9CFRDOz+8PqqXrZ0Tg/W3ihGE68OUsk98AJ+f7Mjp+Xi6znBh9HE/Vx00l2u3dxDG1M/fhyszDVcS9Y/dmvsr7lUS/9Cqibfwu0/1fVIMw9xD7+/Is8yXEMfY84tabr2d53Jnldi9Rn+4hRohvzzR8O9c5gahXC6mOzaWuPlor13Lf92DgU32Jdwb8r0TN7P3u/ouGac8kAp0TiAPoRUTnUIZBNxMN6DwisHgDVUUeRgQuexOVfTrRuY7JdSzI9T5E3CT9WmLnDCIOSOuInfgG4rJGCerKyMhLc90riLPrEgCtIyriTKJynUs0jH1y/m+4+8OZvxcRgdoLiYa0mLjev5Y4G3k9cda3T25jDdGxHkD8gunuWlmdnPl+M1Hp30OcdQzK1w/V8nRspmUJ8Qupt2X+v0ac1f8tETBfn/nanxjB+Zy7lxGA+n7anzhwHEecsc3PsnprlrURIyG353zPyvX9BTF0fy5x8/Y/EJeWn0M0hgnkjblE4PFsokN6H/DJ3BeTiMDqacTZZll2X+AzOW0JsR//IsuzjOgdkN//kqgvq4kg4hPEmdOz3P2x/AXqCCIAIdexhDjw/gEY6u6/MrODiZGo3+d8g3K7RxGXKP+eCKIPIDrkZxOjjauIgx1Z1jcTHfUJRAB2G1H3R7j7L7ppK39B1Ll/IkZcPkg1EjacOKh8MstuDBGUHkbUgxcR9fL2XM8kd99UW/cJxH58R5bRa7Ocn02MFj1KHEw7iBHpYUT7KgHJDUQdfBfViN39xGXYUuYfJQ5Gw4g2cDCxzw/M/ehEJzs/y/UZuc0vEiNHL8ty3UB0wOVy4YeBu939GjP7fK7/NVnG3yP6l2VEO55PtKtVZjaIaA9Dcl13EQfMo7P8DiJO+u7IvPxNbn8GcS/Tq4iTgLm57wZnHlcRfdbtxEnV3xD7+T3EKMtc4CJ3X59lfzNxcP2Cu38wH0HxLCI4GJVpHkwcWK/JdZ1Z2+6+Od+ILHeIuruaGG15Q27nZCIY/Hfiss5qMzuMOFC/k6hbl+Z+HZbb2R+40t1vMrNP5/69EXiTu5+e6z2B6pERz8i0vJdoN1/2fGSEmX0LuNndb800ll///g/Rzq4k+vARRB/4G3e/18xeRlwenUa0odK3zScO7C8nRocmu/vN+SiQI4iD9RFEW74v9+2Bmb/Dcl++lmqEfRNRz9+f6x9CjMSsJgKH5xLBWxdRt9YQ/dlNxGjle919XnlURe7vaz0fWZGPEzmf6uSpPshwJPCoV4/rOIfom48jgtwLiID0HuBrue9ektu9F1jv1SNL/iPTe2Lm4bdEIHQPEXy9KffXmEzXS7PsZxD95lQimD2abh59Uh7vkVfAjifq+wc8H/lhZlcQwdM7iP5iMnFy8yrgBe7+PTP7e6K9XEQEZyOJuvUGoo1/iDhW/ZnoK6529yty/S8ijifX5z7di2gjLyLqzvOIkcw7ifqxIPO9P1HHnpNlsoroizqJfmwsMTr4D8Qx8vVEPb4kl3mYPj4GZcAHbD2p/Vy8gyjYacRQ/yDioHAw0XCmEwXqROGXM/NnEDv7tcT9NJPcfXmu911Uv0Ysl1IPIBrNxvy7kgg+JhDB1RuJA+AriAqwkmiAH3f3OzPNzX7y/RzirGUk0Qj3ISpFJ3GQX5zruZU4QP6B6KwmNNtGL2V1dC5T8nQgceBZQFTk87328/ZW6O4n0mb2O6LBLu9pvsZl3P3UvnzfuL7elt3RfGxP+rqbr4/rfg4RLJxCdDQQB9kn7bfyE/O+PmKgm/nKiNQsIkC+hnjsxAH5/eO5/euIE6eZxIH3JJr87L88jqGnPDZJ/ygiuDqEaMufJjrWjxPB2Fji4LKMCPAfze9/S5wkfJm45H8A1a0J64m2P5U4cJ5HtLVZRDCLx6WQ7tJ2DxH4vIU4CD+TONieRO+PSvgd8Fx3Pz7351XEQXIr0SZXEiPKT+zPXGYzcZArBlP1cTMzz7N58iMo7iSCs5E5T7nsWkYFFxP156Is0w8QwcDEkmSivm0E7nL3v6494mEYEcQ8l+ib9if206HEqNwyIohZmOk8lDjIQvSXr/LqkRHriQPeVmJffAX4lecjcszsfnc/Pt/fSxw4N+X2tlDdkrCZuER5PBFMn0zs4xFZ5i8kTgRKme9Xy2e5tL2R6GNflnkbQ9SXN+T03xC3fhyR0y/MMj+MuPWjjJyVKynPpLpNwnKbTnWZdG3ul9VZTuuI4OkKYhR2JlU7LJdq9yNODjpz/r2zLOZnOa8hAvh7iePRI0QbPpfqEuS8XP8JxAniPcRJ4N/musltv5g4cRlMtPcSpL0907UX0dbq9W5wzkeu+27ismNpe5uoLp1vyfUfWCuXdcQo1/zMxyuIkd03Em3vGKI/ejUR0M3N5SDa5BuJY10XUf8gTsxHZ1kdSwyYHJGfr8ttjyROBq4hTtwOIPqfbfq0fFzKcGL/vpQYVR9OnPh+hTj+jyROQpr2h03t6KXIdvkjOoF/JTrXTWz7k+guYuhzCXHWsYSomPcQHXO5aXYNcSlgU65vLXH2MZY4Az2d6ifAZRh1OdteKjqWaMCLcyetr803nzizLcHjfKIS3k6MUq0hGuMiqiHwcu/LZqoGvjLT+M3c3jfz8yXEEO5WomJenZXoTmJo+eFM9/RMx9zM/yriEsXCzPO7qILVcl/EsMzTSuJs4W5ihOQbRGO9hejM30eMOqzI7aymuidsJjGaMDvzfg0xQvBHolNYRDXS8ghxpn821a84VxOd9YJc5maicd+b6V6S+ejMMniYGMGYkfO+nTh4nkgcJN5CnB0vJ0YW35KvpT6U0bkjqH419qecdjgxVF/uh1lO9eulcnlhWe7DKcTI1VjiMs1Mqkc9rMm8lHysy7K7mRgNWJvLXEc0+HlUj6pYSBy0v0ecEZabbus3/T5GnHkfm2VxJ9HJvjXzOZ/q3o03Ud1oW9K3jKgPb810dhJnlWW+KUSH9tp8fx3Vpb2ziE50I9ExlzQ/Umu3E4l2OyW3t5TY11/K/beMqCf/SRX0fZ+ok6UNbsn0zyX29RCiI3wst7uBOBhOyn32X1T9QrkMdwdxIldG39YSdXs9cYCdknk6iKizv6D6te3HiUuR03O/vZtoi57rKembSoyUfiCnr6W6xLMpl/8/RN0ptwAsJdrncqJf2T/T1UX1S83Sp5VL0vMzHZ/JdXya6kcxJ2aZdFA9wmc91Y3+y3J75YTyS0Tbfj4RZC8m6tPsTMNdRBv6Yqb5MeIk8SeZvl8Qz7ODOHFcSoxydxJBTunX7iROKN+S096cf1NrdaXcrF8uq87K7SwlTljPAh6qzb+B6pf0m7OcHiXaTDk+/CMRmJR9PDH38UaiL3k9Ecj9S5bZV6iugDxO9FNDMg+fJg7qm4l7xaZQ9d/lBP7Zma6j8/OanG8zUUfLSf4sqsuYTgwYrKP6BeuGLPvVRH/YmX+fIEb8u6jqw+ep2spb87WUcwdwSpbXkJxvAVHPNhIDGONzXc/O16dT3fYyiOiT1lD9SOyXmf7puX+6Mh9vz/L4NyIQf3qu4+eZnhm1dK0m+swZVD+AmJ9lvJloq+/ONI/PaYOIOraFKuh/ceZpUeax3F7xjExz2R/PIOr0cqI+bc3PL6S6x3QTVfBV2v6bqX4EUY6HK6geadOZZbmcOIaOy/SNy/yMp3Y7FzChT/HOrg64WhCwXU8VnNxABDF/IDqT9cSBooO4nDGX6CxLRSwd5yTi4LGVGKHaQDSmB4iD5BLiYPQg0WC3EJe9oArAbiEa+KJc535Zuabl92szjbNyvXOofm3aldtck9NWZKW4gzh720h0mrfkuv8p399K1SEtyXTdmpVodW5nfG57Q+Z5ZW7jbqqD74Jcttx8XC4F30MEskuJDnsm1a9Fb810Tcq/jUQnvzbzNjPL7rNZJguoHh/SQXUPoVMdNLbW0u5Ugeqa2nzl/aZc/1KqX5qWMijzLc5yXFnbbnndSnW5bBPVo15mEsH6HUTH3JHrmJx5eIzqMS8lKO+gujG/rLcccLuIQLfc91SC0Hm1tEymCuw3NZRJudRR8tyZ6VhDdX/d2tzexqyTxxL17kIiGJyR+2Rrrew7qH6N1ZVltYSow6VcynyLavMtz+mP5GsJtMcSndFWom6syjR+NZcr90luqO2neVS/kF1E9UzEWcQ9iEup7vX6JnEQGksVEF/PtvcIvpQ4CJeAZyvRjkteSl/wKNWjM+ZlOR6WZedUwW8JIp2oC7OJvmUu1a+fSz0odarsvxlUwdedRMDZSXWytozqF+WlfpZAbBFxCeqxnO/rVP3cJmL0ZhlV4L+E6tdsS6h+4faa3N4j+f5OqlswJlM9ZmYsEQTMJh8xQPV8sen5tzVfZ1A9WmUzUbc7iJGYu4hLozcTB+N1xMnuVKpfdm+harelr7mDuDWhs9av/wr4SL7/KXHAHE/U7bE5fR+ibqyiulm8BNiTqep6CSielmmZRQQXZV93ULXz0iZnU/1as7SracTJxP5Z9t/JMrqJOGl1InA6gurZnFOJuvJdql82biT6uYmZvkOIPnRTrndqpnVrLZ+zqH79/8tc9wP5t5XqIcDTieCm3Ju4jKqtrSVOfDtz/uG1/uKBXP47tXTuT9WWyjo2Uv26vSPLYywRSH+W6pfoF1D9ivmzuc0LiLZzf85zHnEcm0aMns3J728hRsY+m3kr33cC4zJtryFGybYQdW0a1bP2FtZOChdRPVqj1KONRJsofUcJlqdkmpfXyu0gon0+QvXL2O9T3f+8ieoe6FLfSr8wsbaNsu5bqZ5kMK1W/mP3lIDtodKY8rWMiu1FdEydVMHKnVQ/p99KBD4rievZG7PQS6fbQZyp/iGX/0NtG2uIhnV57pyrqR5P8AfirGwh1Y3PH6N6ntHCXP9Hau/H1dZd/0lymbaeOJOdSTTGiVlJNmdFmJDbmpnfjc3KcS7RyZUh/GnE8HMX0QjvAObmNkpZrcvtXU0VjP0h1/ul3MZG4gzKcx3XZrk9N/MzIf/KmXHpoKYRN7BOr82/kepRK48QZ6oPEp3nRqqz9EmZ3x9SnSGeTbX/SyfTkfk4lm1/0j2ztn/vzXV35DJbcp4SxJdAdkvOV/KxMKc9N8v791Q/kS+XkeYSjXEo1a+hnpv7oZPo9B6s7YctDfvhQaqb++sjFKXzfrCWlnJf1yaqh3t+kTgAlLyXM+wVWQZl9LSsx2vbXp+vj2felhH14blUAeMdOe3eWtpLQHQ7VeBR/hbntFInS1DRRbS7UVleDxGB6AaqYLDsj/VE2y2XtjbW0rqOaEtlRKMExjfn9uZRPS/pL3IbE/LvZqI+dVE9muG3RD29n7iloQRim4mD+FriEstiqgeZvpnqTHxIpnF2bn8+MVKwKtdzXub3YWJf19vIX1LVu3Lpr4yQPUR1u8aXqW72fnXu16Pz9Uaqx3CUE4A1RDC1rra/HiLq5BqiXW/M8vhSLZ9lH8+henzRPZmGP1OdgHQR9+KsIAKLcuJSRns7Mh31IHcVcaP33VTPJFtV6/ueQ1x6mkWcfJc2fxf5kNpav3Vc5nVu/q0k6nBXvpZR+MlZ/nvlsqOIA+jDVA/a3ZppeXmWx78Q9e97Oe8f8/1txCXJMiKzLvN1GzFSWkasyno7swxeQXWvbicRNJf2U04IS3l01fJZ2uuEfH16fVrm++lEGzyO6gRjLnEcK+1wE1U7KnX6LqJOl/rvwDNq5fvbXOY6qqtHZaT6if2R+2xSlv8Pct6TqfrsO4g++xTi+LOI6ikIq3N9s4k6/Svi0nU5iVtN9YzP52d67mLbE/+VRD+zMdMyngi4ZlL1QSXd43L6y4l6MY/qGZubczuLcxsrcpkVVCelpY5vpnoAbsnX/+R3f0vUi1OJfmFhLS3lZPmJ8t9TArY/E5d0biYi6DuoDuIzsyAnEpd3Tic62MOIM6KTiWvQpxMPYD2duFl7ITF8ezMxlLyUaKT3E9H/r4hgr1zOu7NWiculxx8TZ8Tfyc8P5DZvIM4qf5Y7aj5xuW0O1WXNctC9kxhhu7+2jVVUo0LLs0JOJf/rAHH55HSqiryCaBCW+flipvulWcGW5XYnEh3Gb4j7O35B1ZGsyPffzO0tIALFzlzHT/P7ckl3eaZpPtVDcpcDt2Yaj6DqNErHMZK4uX0sccD8apb1WuIg8cvM89uzTJcRneOficB0A3HJ+UGqp1J3EIHTpNp2H8n0zs90fY7Y33MzDSXN5XLDvIZpm6mekP7h/LyAuIzpOf2buf03U/3yqowofCPz8/ksr8eJ+85WUD2k9t+JIH8Dsd9Lh7QXVd2eSPXLo44sqxVEkFFOSDYSdeYWoiN/K9UDhJcRZ+ydOd9XMo2/yjL6DtXo5FyqUaaRRP36QK1cy+XaocDIJm20k7h/5a8zfW/K/fb53BfLcpvjMy/Tcn0XZT4/SdTdZcQBfANRn+7N8rmAaE+DiPo4PbfxRuKSxzFUdf83RB05hgjq78wyWkn1iIofEgenHxKXdBYRZ+6H1Mr/J8QJ2+nAi2snVm8i2s5ZuX/uIS75lZHJy3K5xbmvxzcsO5LqBvkribrUQXVLRhntHp9/V+f++Rrws1zXO4l69w/EaNl+DX1lGdl8IMvoGqpRmvpIcBnFvYQYHSu/6vtFbb+vzv3xeap/HzUz8/Ew0dceRgSIB+Q+/CXViOYBRD37LE0eHprre1WW/+ubfP8T4scKjdMPI04kX5l/ZwDHN5nvFcQIzHdyW3OofgFZyqMEWyuJvvsH5BPus/xKHicR9e904gcfN9W2M4246nJwbvMFwAn53euI/u74LI9PZnlcXFv+2Pprvi918Viq/v8IIqCZVNJVK+d/zvVeQNyK83byPyY0LPuWxvLNfB5MtOPhuT9+01CWJW/jiTr4zdp346mOFWW+QbVp72zc/8T9XRfV6vT3gefn58m5jhfX9kNJ/7yyjdq6TqOqR6UPOrbJfL+o7c9PEv3D94gg/CLi5PASom5dS/TT06lOAkp5PUB1da2kubSbt2VaPlov/z0lYHslEdCszsKZRfWg3EVE4zsw530RcE1t2ZcQ98Ts37DOU/P1LVSPKJjNtj+9XkF08J25M0dmhflmw/dTsxKUA8UkqkdL/D7T8F9Uv04rozplaLWcWZbRhkdKnojLuCOJ+5hOrqX/Rbn+nxEHiknEPR0HUj0SYRXRIT9KdTPyS4gD1SqiY/oUMZR/MvF/9iAa2LeIs9PlpeyofpJdzkLKZdiNVJdtX5TzPp84ayuXl1dk+azK9NyaZfUoEQz9gDg4L6P6afapuUy5r6Oc9X8st/H6nO+vG/b5KcSvpeZlmZ+X+/hCImg/j7hvagJx9v/Nhmk/rKX7PqLRfpLqDPAjuT/XEJ3/P1D9p4Abs3zX5LbvqeVjE1FX3lBL53nE5dcySvY3xD5/AXBFzvdFqn+/soUqAHucqJcH1ub7X6rRyym1cvsQ1ahnZ5bj2cRo5yepnvx/SuZtFVE/PkmM+owkAxfyvpiG9vTHHtrtqkzPhZnfP+Xr6eTjC3L+v899NoPqUvT83MdnA3v30k8cSNU2O6gezVDabmMfcArVowEW1ab/a5N5X0L8uvY2tn0cwseIjvl2Inj5PtXo7nJipOwaoj2MzmXX5bLH1urxD4gDZVn3pHz/YK53SmMZUAskm5T5euIAOpHqV9U/z31Ztrc/VfDx4ny/TX+Z5Vba/XlUj0HYZt/Vy42GgJ6GPnkXHkee2NeZz5MzvfX3p9Tmb1bP63W6vg8H08fHNmxnmp9UF9uhTMljRW/T+rmNJ9Xv2ncjW7idt/DkR8s0trVtjr/1OkL8CKt1+d5VO3UnVZyP1F8bpn2SiICvIw6sI2rzjO/LevP9lbme8T2tp75Md9OIIe1/6cs2avlomtZmeW+yvuuIA/026yMCtT7nqZvy7eu0q4jArGlaavOfTfW/MXssjybpv7C2nnlUT75/vIftdZvmZt837Lsey7ev+6GbvPdUln1dX7M09zVvH+mlfJ9UH2lSB/vaLrajHjVdppd2/KR63lhemfeX95DWso4nyry39t+X7XZXz/vaDnvJd3dpWU60ibK9WU3azXU9pXl79u327q+n+i/39TealMd1Tcqjx2PErs5ju5Tprtj/OyPvO9LWWrLdXb0Dn+JCnVt/bZg2iepMcQgxCvLp/PxgX9ab78uvQeb2tJ76Mn2Z1odtrOwprc3W07i+fP944/pK2fQ1T92Ub1+n9ZiW7SjzntLfUUv/xr6UZU9pbmGediTvrS7L7d6HvZTvk+ojTepgX9tFf9La21+TfPTYrrpJa70fKWXebVvZnu2ynX3LduS7u7SUy9IrqX45uE27yfe9llVf9u327q+d8ddNeXy6SXk0zXNfynwn5aNtynRn7/+dkfcdaWut+Bvwz2Ezs4n5dmht8n7la6rnuUzOz8e6+35m9rC7D6utZ3/i8sTDxL0+e9XWV9bduF6IX/NMpvpl3l5UNyDv35CmyQ3re1ptPfV1e+21WT4GEfegLW/YRt3Tast09JL+jvxuWa7PiEtP9Ty9lOo+KmrraZbW7Z3WLC1butlWY3mU+/Mal+loKAOneoZPb8v2luZW5mlH8t7qstyRfVjWPYWoJ+U+n/2pnq9UlnsZVd0v6m2qozZ9v26221O6mrbx+sZq/USzbdfb1TCqdtCYj9Ie6o4lLieXfD5M9+2/o+F9d3WwzNesb6m3w/r6ptTz3ZDf7vLdmJZO4paSlxL37ZxM3Ou3ifjhSX0fNvZB9bKqb6exz6tPg272187QTRkdS9X3zSLuKyvHhZOJWzQeBt7q7sf1YX3wFOVxZ2+vr/pQ9/q9/3dG3vu6jZ26H3Z1xN2CSLf8SmgpcT/QG4j7U87KaW/MeY4mzpIW5HK3A8c1rGtv4pc/W2rrPbq27vp635Dr7iRuaFxQW+YFxOMwyk+iT6ul4ejatC1N0ry1to0yrTNft8kH1b1u9byXdG2pbbcx/WV9jfOVNP+pSZ6WEfeWbaHntG7vtO7SsqlhW92VR70sS/rG5ff19ZX0ey/LNm5veTdpaEWediTvrS7LHdmHpXwXU9XF+q/Jjq79DclpxzVMr7eLxra7PWXebRvvpp+ot+d6Pupp7S4fCxrWczTRVk5l23x21/6bbbdZHeypb1nWZL4n9kM3+e2pzOtpqbf7ej9Yfjl4apPyKH1Qd9vpaVq3+2snHzvq6amXQfnFZf248MT7Pq7vKcvjzt5eP9PV0v2/M/Le123szP2wNwPfDcQZ3mhgrbv/2cyuJc6ObnH3P5nZbe7+GICZ3ZnLfYj4JdQT3L0L+JCZ/TfxC4793X2CmY0mbuyur/fPub4biWHzO6kuG0wA/sbM3pjrWQPU0zCa6qb0xjQ/WrZB9SDFG4mb7d/RkI+NRIc7vKyn5CX/ifga4kbojQ3pv5H4BdOi+nzu/v5M82NZNk/kiXgO1E+JG4s/2kNat3da07Q05K3b8qB6COUc4pdW59XS37i+n1L9gKG7ZUveyvaOIi6PPBV52pG8t7osd2QffjHL9x3uPqdWF39KPIH/MWoyLaVdlGmlDTxRP2vtYHvKvKc2XncDT27PI2v5KMvOIX6c0CwfJZ9P5MXM/o54/MKihnw+qf1TtcMntkuTOthT30KtHdbmu622H56U357KvCEtZb/e6fEvgko/+FPi128PuvuiJuUxrl5W9e006fNu66Zcd4VmZfR3VH3fF4l9+8RxoeEY0ev6auu9s+Wp3/nb66se616L9v/OyHtft7HT9sOAvyQqIiIisrvbq/dZRERERGRXUsAmIiIi0uYUsImIiIi0OQVsIiIiIm1OAZuIiIhIm/t/cRKUmRkVOGoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, f1_score, confusion_matrix\n",
    "from xgboost import XGBRegressor\n",
    "from copy import deepcopy\n",
    "from scipy.stats import pearsonr\n",
    "from utils import read_sentiment_scores, read_library_scores\n",
    "from math import sqrt\n",
    "get_ipython().run_line_magic(\"matplotlib\", \"inline\") # %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import statistics\n",
    "import datetime\n",
    "import random\n",
    "random.seed(9)\n",
    "\n",
    "labels = read_sentiment_scores(sentiment_dir, canonization_labels_dir, lang)\n",
    "library_scores = read_library_scores(sentiment_dir, canonization_labels_dir, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4594ed42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_name</th>\n",
       "      <th>y</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alexis_Willibald_Der-falsche-Woldemar_1842</td>\n",
       "      <td>0.025530</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alexis_Willibald_Ruhe-ist-die-erste-Buergerpfl...</td>\n",
       "      <td>0.023794</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alexis_Willibald_Cabanis_1830</td>\n",
       "      <td>0.023481</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alexis_Willibald_Schloss-Avalon_1826</td>\n",
       "      <td>0.027773</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alexis_Willibald_Walladmor_1824</td>\n",
       "      <td>0.046649</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Viebig_Clara_Das-Weiberdorf_1900</td>\n",
       "      <td>0.009018</td>\n",
       "      <td>not_classified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Weerth_Georg_Ritter-Schnapphahnski_1849</td>\n",
       "      <td>-0.001418</td>\n",
       "      <td>not_classified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Wienbarg_Ludolph_Aesthetische-Feldzuege_1834</td>\n",
       "      <td>-0.002994</td>\n",
       "      <td>not_classified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Willkomm_Ernst_Weisse-Sclaven_1845</td>\n",
       "      <td>-0.027169</td>\n",
       "      <td>not_classified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Zschokke_Johann_Das-Goldmacherdorf_1817</td>\n",
       "      <td>0.019384</td>\n",
       "      <td>not_classified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             book_name         y  \\\n",
       "0           Alexis_Willibald_Der-falsche-Woldemar_1842  0.025530   \n",
       "1    Alexis_Willibald_Ruhe-ist-die-erste-Buergerpfl...  0.023794   \n",
       "2                        Alexis_Willibald_Cabanis_1830  0.023481   \n",
       "3                 Alexis_Willibald_Schloss-Avalon_1826  0.027773   \n",
       "4                      Alexis_Willibald_Walladmor_1824  0.046649   \n",
       "..                                                 ...       ...   \n",
       "217                   Viebig_Clara_Das-Weiberdorf_1900  0.009018   \n",
       "218            Weerth_Georg_Ritter-Schnapphahnski_1849 -0.001418   \n",
       "219       Wienbarg_Ludolph_Aesthetische-Feldzuege_1834 -0.002994   \n",
       "220                 Willkomm_Ernst_Weisse-Sclaven_1845 -0.027169   \n",
       "221            Zschokke_Johann_Das-Goldmacherdorf_1817  0.019384   \n",
       "\n",
       "                  c  \n",
       "0          positive  \n",
       "1          positive  \n",
       "2          positive  \n",
       "3          positive  \n",
       "4          positive  \n",
       "..              ...  \n",
       "217  not_classified  \n",
       "218  not_classified  \n",
       "219  not_classified  \n",
       "220  not_classified  \n",
       "221  not_classified  \n",
       "\n",
       "[222 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels \n",
    "#len(pd.unique(labels[\"book_name\"])) #197\n",
    "\n",
    "# 254 labels, 197 different book_names -> 57 second/third... reviews\n",
    "# 36 book_names with more than 1 label, these 36 book_names have 93 labels\n",
    "# 93 = 36 first reviews + 57 second/third... reviews\n",
    "# 6 texts with opposing reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "933bfe04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels[\"y\"].plot.hist(grid=True, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b1785d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression(object):\n",
    "    def __init__(self, language, features, drop_columns_including, dimensionality_reduction, model_param, model, verbose):\n",
    "        assert isinstance(drop_columns_including, list)\n",
    "        for i in drop_columns_including:\n",
    "            assert isinstance(i, str)\n",
    "        assert (dimensionality_reduction in [\"k_best_f_reg_0_10\", \"k_best_mutual_info_0_10\", \"ss_pca_0_95\"]) or (dimensionality_reduction is None)\n",
    "        self._check_class_specific_assertions()\n",
    "        \n",
    "        self.language = language\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.labels = self._prepare_labels()\n",
    "        self.drop_columns_including = drop_columns_including\n",
    "        self.dimensionality_reduction = dimensionality_reduction\n",
    "        self.model_param = model_param\n",
    "        self.model = model\n",
    "        self.verbose = verbose\n",
    "        self.datetime = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "        if self.features == \"book\":\n",
    "            self.df = deepcopy(book_df)\n",
    "        elif self.features == \"chunk\":\n",
    "            self.df = deepcopy(chunk_df)\n",
    "        elif self.features == \"chunk_and_copied_book\":\n",
    "            self.df = deepcopy(chunk_and_copied_book_df)\n",
    "        elif self.features == \"book_and_averaged_chunk\":\n",
    "            self.df = deepcopy(book_and_averaged_chunk_df)\n",
    "\n",
    "        columns_before_drop = set(self.df.columns)\n",
    "        if self.drop_columns_including:\n",
    "            self.df = self.df[[column for column in self.df.columns if not self._drop_column(column)]].reset_index(drop=True)\n",
    "        columns_after_drop = set(self.df.columns)\n",
    "        if self.verbose:\n",
    "            print(f\"Dropped {len(columns_before_drop - columns_after_drop)} columns.\")\n",
    "            \n",
    "    def _check_class_specific_assertions(self):\n",
    "        assert model in [\"xgboost\", \"svr\", \"lasso\"]\n",
    "        assert features in [\"book\", \"chunk\", \"book_and_averaged_chunk\", \"chunk_and_copied_book\"]\n",
    "    \n",
    "    def _prepare_labels(self):\n",
    "        return self.labels.drop(columns=\"c\")\n",
    "\n",
    "    def _drop_column(self, column):\n",
    "        for string in self.drop_columns_including:\n",
    "            if string in column:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def _custom_pca(self, train_X):\n",
    "        for i in range(5, train_X.shape[1], int((train_X.shape[1] - 5) / 10)):\n",
    "            pca = PCA(n_components=i)\n",
    "            new_train_X = pca.fit_transform(train_X)\n",
    "            if pca.explained_variance_ratio_.sum() >= 0.95:\n",
    "                break\n",
    "        return new_train_X, pca\n",
    "\n",
    "    def _select_features(self, train_X, train_y, validation_X):\n",
    "        if self.dimensionality_reduction == \"ss_pca_0_95\":\n",
    "            ss = StandardScaler()\n",
    "            train_X = ss.fit_transform(train_X)\n",
    "            validation_X = ss.transform(validation_X)\n",
    "            train_X, pca = self._custom_pca(train_X)\n",
    "            validation_X = pca.transform(validation_X)\n",
    "        elif self.dimensionality_reduction == \"k_best_f_reg_0_10\":\n",
    "            k_best = SelectKBest(f_regression, k=np.minimum(int(0.10 * train_X.shape[0]), train_X.shape[1]))\n",
    "            train_X = k_best.fit_transform(train_X, train_y)\n",
    "            validation_X = k_best.transform(validation_X)\n",
    "        elif self.dimensionality_reduction == \"k_best_mutual_info_0_10\":\n",
    "            k_best = SelectKBest(mutual_info_regression, k=np.minimum(int(0.10 * train_X.shape[0]), train_X.shape[1]))\n",
    "            train_X = k_best.fit_transform(train_X, train_y)\n",
    "            validation_X = k_best.transform(validation_X)\n",
    "        elif self.dimensionality_reduction is None:\n",
    "            pass\n",
    "        return train_X, validation_X\n",
    "    \n",
    "    def _impute(self, train_X, validation_X):\n",
    "        imputer = KNNImputer()\n",
    "        train_X = imputer.fit_transform(train_X)\n",
    "        validation_X = imputer.transform(validation_X)\n",
    "        return train_X, validation_X\n",
    "    \n",
    "    def _get_model(self, model_param):\n",
    "        # if any of these performs better than others, we can try to tune the hyperparameters\n",
    "        # but I think for now it\"s more important to see which approach performs better\n",
    "        # chunk based or doc based\n",
    "        # use dimensionality reduction or not...\n",
    "        if self.model == \"xgboost\": #1,0.25,2\n",
    "            return XGBRegressor(n_estimators=1000, max_depth=model_param, learning_rate=0.01, colsample_bytree=0.33, min_child_weight=6) #max_depth=4\n",
    "        elif self.model == \"svr\":\n",
    "            return SVR(C=model_param)\n",
    "        elif self.model == \"lasso\":\n",
    "            return Lasso(alpha=model_param)\n",
    "        elif self.model == \"svc\":\n",
    "            return SVC(C=model_param)\n",
    "        \n",
    "    def _split_booknames(self, df, nr_splits):\n",
    "        \"\"\"\n",
    "        Distribute book names over splits.\n",
    "        All works of an author are in the same split.\n",
    "        \"\"\"\n",
    "        book_names = df[\"book_name\"].unique()\n",
    "        authors = []\n",
    "        booknames_authors_mapping = {}\n",
    "\n",
    "        #Get authors\n",
    "        for book_name in book_names:\n",
    "            author = \"_\".join(book_name.split(\"_\")[:2])\n",
    "            authors.append(author)\n",
    "            if author in booknames_authors_mapping:\n",
    "                booknames_authors_mapping[author].append(book_name)\n",
    "            else:\n",
    "                booknames_authors_mapping[author] = []\n",
    "                booknames_authors_mapping[author].append(book_name)\n",
    "        #Distribute authors over splits so that each split has approximately the same number of books\n",
    "        works_per_author = Counter(authors)\n",
    "        goal_sum = round(len(book_names)/nr_splits)\n",
    "        tolerance = 0.03\n",
    "        lower_threshold = goal_sum - round(tolerance*goal_sum)\n",
    "        upper_threshold = goal_sum + round(tolerance*goal_sum)\n",
    "        author_splits = []\n",
    "        popped_dict = {}\n",
    "\n",
    "        for i in range (0, nr_splits-1):\n",
    "            works_in_split = 0\n",
    "            split = []\n",
    "            curr_author_workcount = 0\n",
    "\n",
    "            # take values from popped dict first\n",
    "            if bool(popped_dict):  \n",
    "                popped = []\n",
    "                for curr_author, curr_author_workcount in popped_dict.items():\n",
    "                    # leave item in popped dict if value is too big\n",
    "                    if works_in_split + curr_author_workcount > upper_threshold:\n",
    "                        continue\n",
    "                    else:\n",
    "                        popped.append(curr_author)\n",
    "                        split.append(curr_author)\n",
    "                        works_in_split += curr_author_workcount\n",
    "                        if works_in_split >= lower_threshold:\n",
    "                            break\n",
    "                for current_author in popped:\n",
    "                    del popped_dict[current_author]\n",
    "            while works_in_split < upper_threshold:\n",
    "                if bool(works_per_author):\n",
    "                    curr_author = random.choice(list(works_per_author.keys()))\n",
    "                    curr_author_workcount = works_per_author.pop(curr_author)\n",
    "                    # Put values into separate dict if too big\n",
    "                    if works_in_split + curr_author_workcount > upper_threshold:\n",
    "                        popped_dict[curr_author] = curr_author_workcount\n",
    "                    else:\n",
    "                        split.append(curr_author)\n",
    "                        works_in_split += curr_author_workcount\n",
    "                        if works_in_split >= lower_threshold:\n",
    "                            break\n",
    "                else:\n",
    "                    #ignore upper threshold\n",
    "                    popped = []\n",
    "                    for curr_author, curr_author_workcount in popped_dict.items():\n",
    "                        popped.append(curr_author)\n",
    "                        split.append(curr_author)\n",
    "                        works_in_split += curr_author_workcount\n",
    "                        if works_in_split >= lower_threshold:\n",
    "                            break\n",
    "                    for current_author in popped:\n",
    "                        del popped_dict[current_author]\n",
    "\n",
    "            author_splits.append(split)\n",
    "        #Create last split directly from remaining dict\n",
    "        works_in_last_split = sum(works_per_author.values()) + sum(popped_dict.values())\n",
    "        split = list(works_per_author.keys()) + list(popped_dict.keys())\n",
    "        author_splits.append(split)\n",
    "\n",
    "        #Map author splits to book names\n",
    "        book_splits = []\n",
    "        for author_split in author_splits:\n",
    "            book_split = []\n",
    "            for author in author_split:\n",
    "                book_split.extend(booknames_authors_mapping[author])\n",
    "            book_splits.append(book_split)\n",
    "        return book_splits\n",
    "    \n",
    "    def _combine_df_labels(self, df):\n",
    "        #Average of sentiscores per book\n",
    "        agg_labels = self.labels.groupby(by=\"book_name\", as_index=False).mean()\n",
    "        df = df.merge(right=agg_labels, on=\"book_name\", how=\"inner\", validate=\"many_to_one\")\n",
    "        return df\n",
    "    \n",
    "    def run(self):\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "\n",
    "        train_mses = []\n",
    "        train_maes = []\n",
    "        train_r2s = []\n",
    "        train_corrs = []\n",
    "        \n",
    "        validation_mses = []\n",
    "        validation_maes = []\n",
    "        validation_r2s = []\n",
    "        validation_corrs = []\n",
    "        validation_corr_pvalues = []\n",
    "\n",
    "        df = self.df\n",
    "        df = self._combine_df_labels(df)\n",
    "        book_names_split = self._split_booknames(df, 5)\n",
    "        all_validation_books = []\n",
    "\n",
    "        for index, split in enumerate(book_names_split):\n",
    "            train_df = df[~df[\"book_name\"].isin(split)]\n",
    "            validation_df = df[df[\"book_name\"].isin(split)]\n",
    "            \n",
    "            train_X = train_df.drop(columns=[\"y\", \"book_name\"]).values\n",
    "            train_y = train_df[\"y\"].values.ravel()\n",
    "            validation_X = validation_df.drop(columns=[\"y\", \"book_name\"]).values\n",
    "            validation_y = validation_df[\"y\"].values.ravel()\n",
    "            train_X, validation_X = self._impute(train_X, validation_X)\n",
    "            #if self.verbose:\n",
    "            #    print(f\"train_X.shape before {self.dimensionality_reduction}: {train_X.shape}, validation_X.shape before {self.dimensionality_reduction}: {validation_X.shape}\")\n",
    "            train_X, validation_X = self._select_features(train_X, train_y, validation_X)\n",
    "            #if self.verbose:\n",
    "            #    print(f\"train_X.shape after {self.dimensionality_reduction}: {train_X.shape}, validation_X.shape after {self.dimensionality_reduction}: {validation_X.shape}\")\n",
    "            model = self._get_model(self.model_param)\n",
    "            model.fit(train_X, train_y)\n",
    "            \n",
    "            train_books = deepcopy(train_df[[\"book_name\", \"y\"]])\n",
    "            train_books[\"yhat\"] = model.predict(train_X)\n",
    "            validation_books = deepcopy(validation_df[[\"book_name\", \"y\"]])\n",
    "            validation_books[\"yhat\"] = model.predict(validation_X)\n",
    "            \n",
    "            train_books = train_books.groupby(\"book_name\").mean()\n",
    "            validation_books = validation_books.groupby(\"book_name\").mean()\n",
    "            all_validation_books.append(validation_books.reset_index())\n",
    "            \n",
    "            train_y = train_books[\"y\"].tolist()\n",
    "            train_yhat = train_books[\"yhat\"].tolist()\n",
    "            validation_y = validation_books[\"y\"].tolist()\n",
    "            validation_yhat = validation_books[\"yhat\"].tolist()\n",
    "            \n",
    "            all_labels.extend(validation_y)\n",
    "            all_predictions.extend(validation_yhat)\n",
    "            \n",
    "            train_mse = mean_squared_error(train_y, train_yhat)\n",
    "            train_mae = mean_absolute_error(train_y, train_yhat)\n",
    "            train_r2 = r2_score(train_y, train_yhat)\n",
    "            train_corr = pearsonr(train_y, train_yhat)[0]\n",
    "            \n",
    "            validation_mse = mean_squared_error(validation_y, validation_yhat)\n",
    "            validation_mae = mean_absolute_error(validation_y, validation_yhat)\n",
    "            validation_r2 = r2_score(validation_y, validation_yhat)\n",
    "            validation_corr = pearsonr(validation_y, validation_yhat)[0]\n",
    "            p_value = pearsonr(validation_y, validation_yhat)[1]\n",
    "            \n",
    "            train_mses.append(train_mse)\n",
    "            train_maes.append(train_mae)\n",
    "            train_r2s.append(train_r2)\n",
    "            train_corrs.append(train_corr)\n",
    "            \n",
    "            validation_mses.append(validation_mse)\n",
    "            validation_maes.append(validation_mae)\n",
    "            validation_r2s.append(validation_r2)\n",
    "            validation_corrs.append(validation_corr)\n",
    "            validation_corr_pvalues.append(p_value)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"Fold: {index+1}, TrainMSE: {np.round(train_mse, 3)}, TrainMAE: {np.round(train_mae, 3)}, ValMSE: {np.round(validation_mse, 3)}, ValMAE: {np.round(validation_mae, 3)}, ValR2: {np.round(validation_r2, 3)}, ValCorr: {np.round(validation_corr, 3)}\")\n",
    "        all_labels = np.array(all_labels)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        \n",
    "        # Save y and y_pred for examples\n",
    "        pd.concat(all_validation_books).to_csv(results_dir + \"/y-yhat-\" + self.language + \"-\" + self.datetime + \".csv\", index=False)\n",
    "        \n",
    "        mean_train_mse = np.mean(train_mses)\n",
    "        mean_train_rmse = np.mean([sqrt(x) for x in train_mses])\n",
    "        mean_train_mae = np.mean(train_maes)\n",
    "        mean_train_r2 = np.mean(train_r2s)\n",
    "        mean_train_corr = np.mean(train_corrs)\n",
    "        \n",
    "        mean_validation_mse = np.mean(validation_mses)\n",
    "        mean_validation_rmse = np.mean([sqrt(x) for x in validation_mses])\n",
    "        mean_validation_mae = np.mean(validation_maes)\n",
    "        mean_validation_r2 = np.mean(validation_r2s)\n",
    "        mean_validation_corr = np.mean(validation_corrs)\n",
    "        mean_p_value = self._get_pvalue(validation_corr_pvalues)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\"\"TrainMSE: {np.round(mean_train_mse, 3)}, TrainRMSE: {np.round(mean_train_rmse, 3)}, TrainMAE: {np.round(mean_train_mae, 3)}, TrainR2: {np.round(mean_train_r2, 3)}, TrainCorr: {np.round(mean_train_corr, 3)}, ValMSE: {np.round(mean_validation_mse, 3)}, ValRMSE: {np.round(mean_validation_rmse, 3)}, ValMAE: {np.round(mean_validation_mae, 3)}, ValR2: {np.round(mean_validation_r2, 3)}, ValCorr: {np.round(mean_validation_corr, 3)}, ValCorrPValue: {np.round(mean_p_value, 3)}\"\"\")\n",
    "            print(\"\\n---------------------------------------------------\\n\")\n",
    "            plt.figure(figsize=(4,4))\n",
    "            plt.xticks(fontsize=15)\n",
    "            plt.yticks(fontsize=15)\n",
    "            plt.xlim([0,1])\n",
    "            plt.ylim([0,1])\n",
    "\n",
    "            plt.scatter(all_labels, all_predictions, s=6)\n",
    "            plt.xlabel(\"Canonization Scores\", fontsize=20)\n",
    "            plt.ylabel(\"Predicted Scores\", fontsize=20)\n",
    "            plt.savefig(results_dir + lang + \"-\" + self.model + \"-\" + str(self.dimensionality_reduction) \n",
    "            + \"-\" + self.features + \"-\" + \"-\" + \"param\" + str(self.model_param) + \"-\" + self.datetime + \".png\", \n",
    "            dpi=400, bbox_inches=\"tight\")    \n",
    "    \n",
    "            plt.show();\n",
    "        return mean_train_mse, mean_train_rmse, mean_train_mae, mean_train_r2, mean_train_corr, mean_validation_mse, mean_validation_rmse, mean_validation_mae, mean_validation_r2, mean_validation_corr, mean_p_value, self.datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340d71a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Classification into reviewed/not reviewed\n",
    "'''\n",
    "\n",
    "class Classification(Regression):\n",
    "    def __init__(self, language, features, drop_columns_including, dimensionality_reduction, model_param, model, verbose):\n",
    "        super().__init__(language, features, drop_columns_including, dimensionality_reduction, model_param, model, verbose)\n",
    "\n",
    "    def _check_class_specific_assertions(self):\n",
    "        assert model in [\"svc\"]\n",
    "        assert features in [\"book\", \"chunk\", \"book_and_averaged_chunk\", \"chunk_and_copied_book\"]\n",
    "        \n",
    "    def _prepare_labels(self):\n",
    "        labels = self.labels.drop(columns=\"y\").rename(columns={\"c\":\"y\"})\n",
    "        labels = labels.replace(to_replace={\"positive\": 3, \"not_classified\": 2, \"negative\": 1})\n",
    "        labels = labels.drop_duplicates(subset=\"book_name\")\n",
    "        return labels\n",
    "        \n",
    "    def _combine_df_labels(self, df):\n",
    "        #Reviews zum englischen Korpus beginnnen mit 1759 und decken alles bis 1914 ab\n",
    "        agg_labels = self.labels[[\"book_name\"]].drop_duplicates()\n",
    "        agg_labels[\"y\"] = 1\n",
    "        df = df.merge(right=agg_labels, on=\"book_name\", how=\"left\", validate=\"many_to_one\")\n",
    "        df[\"y\"] = df[\"y\"].fillna(value=0)\n",
    "        #Select books written after 1759 (year of first review)\n",
    "        year = df[\"book_name\"].str.replace('-', '_').str.split('_').str[-1].astype('int64')\n",
    "        df = df.loc[year>=1759]\n",
    "        return df\n",
    "    \n",
    "    def _get_sample_weights(self, df):\n",
    "        # Weight \n",
    "        chunks_per_book = df[\"book_name\"].value_counts(sort=False).rename('chunks_per_book')\n",
    "        chunks_per_book = chunks_per_book.reset_index().rename(columns={\"index\":'book_name'})\n",
    "        chunks_per_book[\"chunks_per_book\"] = 1/chunks_per_book[\"chunks_per_book\"]\n",
    "        df = df.merge(right=chunks_per_book, how=\"left\", on=\"book_name\")\n",
    "        print(df)\n",
    "        sample_weights = df[\"chunks_per_book\"].tolist()\n",
    "        return sample_weights\n",
    "    \n",
    "    def _aggregate_chunk_predictions(self, df):\n",
    "        g = df.groupby(\"book_name\") \n",
    "        \n",
    "        # Majority vote\n",
    "        # If one value is more common, assign it to every chunk\n",
    "        # Therefore, accuracy is either 0 or 1\n",
    "        # If both values are equally likely, leave them unchanged, and accuracy is 0.5\n",
    "        def _get_mode_accuracy(group):\n",
    "            counts = group[\"yhat\"].value_counts()\n",
    "            if len(counts) == 1:\n",
    "                mode_acc = counts.index[0]\n",
    "            else:\n",
    "                mode_acc = 0.5\n",
    "            return mode_acc\n",
    "        mode_accs = g.apply(_get_mode_accuracy).rename(\"mode_acc\").reset_index() \n",
    "        mode_acc = mode_accs[\"mode_acc\"].mean()\n",
    "        \n",
    "        # Average accuracy within book\n",
    "        book_acc = g.apply(lambda group: accuracy_score(group[\"y\"], group[\"yhat\"])).mean()\n",
    "        #Accuracy when each chunk is treated as single document\n",
    "        chunk_acc = accuracy_score(df[\"y\"], df[\"yhat\"])#, sample_weight = self._get_sample_weights(df))\n",
    "        return {\"mode_acc\": mode_acc, \"book_acc\": book_acc, \"chunk_acc\": chunk_acc}\n",
    "        \n",
    "    def run(self):\n",
    "        train_accs = []\n",
    "        validation_accs = []\n",
    "\n",
    "        df = self.df\n",
    "        df = self._combine_df_labels(df)\n",
    "        book_names_split = self._split_booknames(df, 5)\n",
    "        all_validation_books = []\n",
    "\n",
    "        for index, split in enumerate(book_names_split):\n",
    "            train_df = df[~df[\"book_name\"].isin(split)]\n",
    "            validation_df = df[df[\"book_name\"].isin(split)]\n",
    "            \n",
    "            train_X = train_df.drop(columns=[\"y\", \"book_name\"]).values\n",
    "            train_y = train_df[\"y\"].values.ravel()\n",
    "            validation_X = validation_df.drop(columns=[\"y\", \"book_name\"]).values\n",
    "            validation_y = validation_df[\"y\"].values.ravel()\n",
    "            train_X, validation_X = self._impute(train_X, validation_X)\n",
    "            #if self.verbose:\n",
    "            #    print(f\"train_X.shape before {self.dimensionality_reduction}: {train_X.shape}, validation_X.shape before {self.dimensionality_reduction}: {validation_X.shape}\")\n",
    "            train_X, validation_X = self._select_features(train_X, train_y, validation_X)\n",
    "            #if self.verbose:\n",
    "            #    print(f\"train_X.shape after {self.dimensionality_reduction}: {train_X.shape}, validation_X.shape after {self.dimensionality_reduction}: {validation_X.shape}\")\n",
    "            model = self._get_model(self.model_param)\n",
    "            model.fit(train_X, train_y)\n",
    "            \n",
    "            train_books = deepcopy(train_df[[\"book_name\", \"y\"]])\n",
    "            train_books[\"yhat\"] = model.predict(train_X)\n",
    "            train_acc = self._aggregate_chunk_predictions(train_books)\n",
    "            validation_books = deepcopy(validation_df[[\"book_name\", \"y\"]])\n",
    "            validation_books[\"yhat\"] = model.predict(validation_X)\n",
    "            validation_acc = self._aggregate_chunk_predictions(validation_books)\n",
    "            \n",
    "            all_validation_books.append(validation_books)\n",
    "            \n",
    "            train_accs.append(train_acc)\n",
    "            validation_accs.append(validation_acc)\n",
    "            if self.verbose:\n",
    "                print(f\"Fold: {index+1}, TrainAcc: {np.round(train_acc, 3)}, ValAcc: {np.round(validation_acc, 3)}\")\n",
    "        \n",
    "        # Save y and y_pred for examples\n",
    "        all_validation_books = pd.concat(all_validation_books)\n",
    "        all_validation_books.to_csv(results_dir + \"/valiationbooks-class-\" + self.language + \"-\" + self.datetime + \".csv\", index=False)\n",
    "        \n",
    "        print(confusion_matrix(all_validation_books[\"y\"], all_validation_books[\"yhat\"]))\n",
    "        print(pd.crosstab(all_validation_books[\"y\"], all_validation_books[\"yhat\"], rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "                \n",
    "        train_accs = pd.DataFrame(train_accs)\n",
    "        validation_accs = pd.DataFrame(validation_accs)\n",
    "        \n",
    "        mean_train_mode_acc = train_accs[\"mode_acc\"].mean()\n",
    "        mean_train_book_acc = train_accs[\"book_acc\"].mean()\n",
    "        mean_train_chunk_acc = train_accs[\"chunk_acc\"].mean()\n",
    "        mean_validation_mode_acc = validation_accs[\"mode_acc\"].mean()\n",
    "        mean_validation_book_acc = validation_accs[\"book_acc\"].mean()\n",
    "        mean_validation_chunk_acc = validation_accs[\"chunk_acc\"].mean()\n",
    "        print(mean_train_mode_acc, mean_train_book_acc, mean_train_chunk_acc)\n",
    "        print(mean_validation_mode_acc, mean_validation_book_acc, mean_validation_chunk_acc)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\"\"TrainAcc: {np.round(mean_train_acc, 3)}, ValidationAcc: {np.round(mean_validation_acc, 3)}\"\"\")\n",
    "            print(\"\\n---------------------------------------------------\\n\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9de317b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Classification into in library/not in library\n",
    "'''\n",
    "\n",
    "class LibraryClassification(Classification):\n",
    "    def _prepare_labels(self):\n",
    "        return self.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0170865",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Classification into not reviewed/negative/not classified/positive\n",
    "'''\n",
    "\n",
    "class MulticlassClassification(Regression):\n",
    "    def __init__(self, language, features, drop_columns_including, dimensionality_reduction, model_param, model, verbose):\n",
    "        super().__init__(language, features, drop_columns_including, dimensionality_reduction, model_param, model, verbose)\n",
    "\n",
    "    def _check_class_specific_assertions(self):\n",
    "        assert model in [\"svc\"]\n",
    "        assert features in [\"book\", \"book_and_averaged_chunk\"]\n",
    "        \n",
    "    def _prepare_labels(self):\n",
    "        labels = self.labels.drop(columns=\"y\").rename(columns={\"c\":\"y\"})\n",
    "        labels = labels.replace(to_replace={\"positive\": 3, \"not_classified\": 2, \"negative\": 1})\n",
    "        \n",
    "        #Correct labels if book has opposed labels\n",
    "        single_review = labels.groupby(\"book_name\").filter(lambda x: len(x)==1) # 161 single review, 93 several\n",
    "        multiple_reviews = labels.groupby(\"book_name\").filter(lambda x: len(x)>1 and not(1 in x.values and 3 in x.values))\n",
    "        #opposed_reviews = labels.groupby(\"book_name\").filter(lambda x: len(x)>1 and (1 in x.values and 3 in x.values))\n",
    "              \n",
    "        def _correct_opposed_labels(group):\n",
    "            count = group[\"y\"].value_counts().reset_index().rename(columns={'index': 'y', \"y\": \"count\"})\n",
    "            #take label with the highest count, take more extreme label if counts are equal\n",
    "            if count.shape[0]>1:\n",
    "                if count.iloc[0,1] == count.iloc[1,1]:\n",
    "                    grouplabel = count[\"y\"].max()\n",
    "                else:\n",
    "                    grouplabel = count.iloc[0,0]\n",
    "                group[\"y\"] = grouplabel\n",
    "            return group\n",
    "        multiple_reviews = multiple_reviews.groupby(\"book_name\").apply(_correct_opposed_labels)\n",
    "        multiple_reviews = multiple_reviews.drop_duplicates(subset=\"book_name\")\n",
    "        labels = pd.concat([single_review, multiple_reviews])\n",
    "        return labels\n",
    "        \n",
    "    def _combine_df_labels(self, df):\n",
    "        #Reviews zum englischen Korpus beginnnen mit 1759 und decken alles bis 1914 ab\n",
    "        df = df.merge(right=self.labels, on=\"book_name\", how=\"left\", validate=\"many_to_one\")\n",
    "        df[\"y\"] = df[\"y\"].fillna(value=0)#(value=\"not_reviewed\")\n",
    "        #Select books written after 1759 (year of first review)\n",
    "        year = df[\"book_name\"].str.replace('-', '_').str.split('_').str[-1].astype('int64')\n",
    "        print(year)\n",
    "        df = df.loc[year>=1759]\n",
    "        return df\n",
    "    \n",
    "    def _get_sample_weights(self, df):\n",
    "        # Weight \n",
    "        chunks_per_book = df[\"book_name\"].value_counts(sort=False).rename('chunks_per_book')\n",
    "        chunks_per_book = chunks_per_book.reset_index().rename(columns={\"index\":'book_name'})\n",
    "        chunks_per_book[\"chunks_per_book\"] = 1/chunks_per_book[\"chunks_per_book\"]\n",
    "        df = df.merge(right=chunks_per_book, how=\"left\", on=\"book_name\")\n",
    "        sample_weights = df[\"chunks_per_book\"].tolist()\n",
    "        return sample_weights\n",
    "    \n",
    "    def _evaluate_predictions(self, df):\n",
    "        score = f1_score(df[\"y\"], df[\"yhat\"], average='macro')\n",
    "        return score\n",
    "        \n",
    "    def run(self):\n",
    "        train_f1s = []\n",
    "        validation_f1s = []\n",
    "\n",
    "        df = self.df\n",
    "        df = self._combine_df_labels(df)\n",
    "        book_names_split = self._split_booknames(df, 10)\n",
    "        all_validation_books = []\n",
    "\n",
    "        for index, split in enumerate(book_names_split):\n",
    "            train_df = df[~df[\"book_name\"].isin(split)]\n",
    "            validation_df = df[df[\"book_name\"].isin(split)]\n",
    "            \n",
    "            train_X = train_df.drop(columns=[\"y\", \"book_name\"]).values\n",
    "            train_y = train_df[\"y\"].values.ravel()\n",
    "            validation_X = validation_df.drop(columns=[\"y\", \"book_name\"]).values\n",
    "            validation_y = validation_df[\"y\"].values.ravel()\n",
    "            train_X, validation_X = self._impute(train_X, validation_X)\n",
    "            #if self.verbose:\n",
    "            #    print(f\"train_X.shape before {self.dimensionality_reduction}: {train_X.shape}, validation_X.shape before {self.dimensionality_reduction}: {validation_X.shape}\")\n",
    "            train_X, validation_X = self._select_features(train_X, train_y, validation_X)\n",
    "            #if self.verbose:\n",
    "            #    print(f\"train_X.shape after {self.dimensionality_reduction}: {train_X.shape}, validation_X.shape after {self.dimensionality_reduction}: {validation_X.shape}\")\n",
    "            model = SVC(C=self.model_param, class_weight='balanced')\n",
    "            model.fit(train_X, train_y)\n",
    "            \n",
    "            train_books = deepcopy(train_df[[\"book_name\", \"y\"]])\n",
    "            train_books[\"yhat\"] = model.predict(train_X)\n",
    "            train_f1 = self._evaluate_predictions(train_books)\n",
    "            validation_books = deepcopy(validation_df[[\"book_name\", \"y\"]])\n",
    "            validation_books[\"yhat\"] = model.predict(validation_X)\n",
    "            validation_f1 = self._evaluate_predictions(validation_books)\n",
    "            all_validation_books.append(validation_books)\n",
    "            \n",
    "            train_f1s.append(train_f1)\n",
    "            validation_f1s.append(validation_f1)\n",
    "            if self.verbose:\n",
    "                print(f\"Fold: {index+1}, TrainF1: {np.round(train_f1, 3)}, ValF1: {np.round(validation_f1, 3)}\")\n",
    "        \n",
    "        # Save y and y_pred for examples\n",
    "        all_validation_books = pd.concat(all_validation_books)\n",
    "        all_validation_books.to_csv(results_dir + \"/valiationbooks-class-\" + self.language + \"-\" + self.datetime + \".csv\", index=False)\n",
    "        \n",
    "        print(confusion_matrix(all_validation_books[\"y\"], all_validation_books[\"yhat\"]))\n",
    "        print(pd.crosstab(all_validation_books[\"y\"], all_validation_books[\"yhat\"], rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "        mean_train_f1 = statistics.mean(train_f1s)\n",
    "        mean_validation_f1 = statistics.mean(validation_f1s)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\"\"TrainF1: {np.round(mean_train_f1, 3)}, ValidationF1: {np.round(mean_validation_f1, 3)}\"\"\")\n",
    "            print(\"\\n---------------------------------------------------\\n\")\n",
    "        return mean_train_f1, mean_validation_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56c1f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop some columns by default before running cv\n",
    "def drop_default_columns(df, drop_default_columns_including):\n",
    "    def _drop_column(column):\n",
    "        for string in drop_default_columns_including:\n",
    "            if string in column:\n",
    "                return True\n",
    "    df = df[[column for column in df.columns if not _drop_column(column)]].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "### Cross-validation\n",
    "\n",
    "# Feature split\n",
    "complexity_features = []\n",
    "\n",
    "\n",
    "# Superfluous featues\n",
    "drop_default_columns_including = [\"average_sentence_embedding\", \"100_most_common_\", \"doc2vec_chunk_embedding\"]\n",
    "\n",
    "# All parameters\n",
    "models = [\"svr\", \"lasso\", \"xgboost\", \"svc\"]\n",
    "model_params = {\"svr\": [1], \"lasso\": [1, 4], \"xgboost\": [1, 4], \"svc\": [0.1, 1, 10, 100, 1000, 10000]} #\n",
    "dimensionality_reduction = [\"ss_pca_0_95\", 'k_best_f_reg_0_10', 'k_best_mutual_info_0_10', None]\n",
    "features = [\"book\", \"chunk\", \"book_and_averaged_chunk\", \"chunk_and_copied_book\"]\n",
    "\n",
    "# Which parameters to use\n",
    "full_cv_params = {\"model\": models, \"dimensionality_reduction\": dimensionality_reduction, \"features\": features}\n",
    "testing_params = {\"model\": models[3], \"dimensionality_reduction\": dimensionality_reduction[3], \n",
    "                  \"features\": features[2]}\n",
    "multiclass_params = {\"model\": models[3], \"dimensionality_reduction\": dimensionality_reduction, \n",
    "                  \"features\": [\"book\", \"book_and_averaged_chunk\"] }\n",
    "# Old results from chr2021 paper\n",
    "eng_params = {\"model\": models[0], \"dimensionality_reduction\": dimensionality_reduction[0], \n",
    "                  \"features\": features[2], }, # svr, pca, book_and_average_chunk\n",
    "ger_params = {\"model\": models[0], \"dimensionality_reduction\": dimensionality_reduction[0], \n",
    "                  \"features\": features[1]}, # svr, pca, chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3a11a8",
   "metadata": {},
   "source": [
    "book_df = pd.read_csv(f\"{extracted_features_dir}{lang}/book_df.csv\")\n",
    "book_and_averaged_chunk_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/book_and_averaged_chunk_df.csv\")\n",
    "chunk_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/chunk_df.csv\")\n",
    "chunk_and_copied_book_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/chunk_and_copied_book_df.csv\")\n",
    "book_df = drop_default_columns(book_df, drop_default_columns_including)\n",
    "book_and_averaged_chunk_df = drop_default_columns(book_and_averaged_chunk_df, drop_default_columns_including)\n",
    "chunk_df = drop_default_columns(chunk_df, drop_default_columns_including)\n",
    "chunk_and_copied_book_df = drop_default_columns(chunk_and_copied_book_df, drop_default_columns_including)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff09a045",
   "metadata": {},
   "source": [
    "print(len(book_df.columns), len(book_and_averaged_chunk_df.columns),len(chunk_df.columns),len(chunk_and_copied_book_df.columns),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c542ff4",
   "metadata": {},
   "source": [
    "len(list(book_and_averaged_chunk_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46b3cb2",
   "metadata": {},
   "source": [
    "for i in list(book_and_averaged_chunk_df.columns):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ace3b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Run Classification\n",
    "# '''\n",
    "# results = []\n",
    "# param_dict = \"multiclass\" #\"full_cv\", \"language_specific\"\n",
    "# for lang in [\"eng\"]: #, \"ger\"]:    \n",
    "#     if param_dict == \"testing\":\n",
    "#         param_dir = testing_params\n",
    "#     elif param_dict == \"multiclass\":\n",
    "#         param_dir = multiclass_params\n",
    "#     elif param_dict == \"full_cv\":\n",
    "#         param_dir = full_cv_params\n",
    "#     elif param_dict == \"language_specific\":\n",
    "#         if lang == \"eng\":\n",
    "#             param_dir = eng_params\n",
    "#         else: \n",
    "#             param_dir = ger_params\n",
    "    \n",
    "#     #Eng: 606 books, 14146 chunks, 13170 chunks of books published after 1759\n",
    "#     book_df = pd.read_csv(f\"{extracted_features_dir}{lang}/book_df.csv\")\n",
    "#     book_and_averaged_chunk_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/book_and_averaged_chunk_df.csv\")\n",
    "#     chunk_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/chunk_df.csv\")\n",
    "#     chunk_and_copied_book_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/chunk_and_copied_book_df.csv\")\n",
    "    \n",
    "#     book_df = drop_default_columns(book_df, drop_default_columns_including)\n",
    "#     book_and_averaged_chunk_df = drop_default_columns(book_and_averaged_chunk_df, drop_default_columns_including)\n",
    "#     chunk_df = drop_default_columns(chunk_df, drop_default_columns_including)\n",
    "#     chunk_and_copied_book_df = drop_default_columns(chunk_and_copied_book_df, drop_default_columns_including)\n",
    "    \n",
    "#     for model in [] + [param_dir['model']]:\n",
    "#         model_param = model_params[model]\n",
    "#         for model_param in model_param:\n",
    "#             for dimensionality_reduction in param_dir[\"dimensionality_reduction\"]:\n",
    "#                 for features in param_dir[\"features\"]:\n",
    "#                     for drop_columns_including in [[]]:\n",
    "#                         #try:\n",
    "#                         print(lang, model, features, drop_columns_including, dimensionality_reduction, 'param=', model_param)\n",
    "#                         experiment = MulticlassClassification(\n",
    "#                             language=lang,\n",
    "#                             features=features,\n",
    "#                             drop_columns_including=drop_columns_including,\n",
    "#                             dimensionality_reduction=dimensionality_reduction,\n",
    "#                             model_param=model_param,\n",
    "#                             model=model,\n",
    "#                             verbose=True\n",
    "#                         )\n",
    "#                         mean_train_f1, mean_validation_f1 = experiment.run()\n",
    "#                         results.append((lang, model, features, drop_columns_including, dimensionality_reduction, model_param, mean_train_f1, mean_validation_f1))\n",
    "#                         ########################################\n",
    "#                         #Library\n",
    "# #                             experiment = LibraryClassification(\n",
    "# #                                 language=lang,\n",
    "# #                                 features=features,\n",
    "# #                                 drop_columns_including=drop_columns_including,\n",
    "# #                                 dimensionality_reduction=dimensionality_reduction,\n",
    "# #                                 model_param=model_param,\n",
    "# #                                 model=model,\n",
    "# #                                 verbose=False\n",
    "# #                             )\n",
    "#                         #################################################\n",
    "\n",
    "#                         #except Exception as e:\n",
    "# #                             print(f\"Error in {lang}, {model}, {features}, {drop_columns_including}, {dimensionality_reduction}\")\n",
    "# #                             print(e)\n",
    "# results_df = pd.DataFrame(results, columns=[\"lang\", \"model\", \"features\", \"drop_columns_including\", \n",
    "# \"dimensionality_reduction\", \"model_param\", \"mean_train_f1\", \"mean_validation_f1\"])\n",
    "# results_df.to_csv(results_dir + lang + '_' + param_dict + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e4e21fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ger svc book [] ss_pca_0_95 param= 0.1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.336, ValF1: 0.223\n",
      "Fold: 2, TrainF1: 0.359, ValF1: 0.139\n",
      "Fold: 3, TrainF1: 0.381, ValF1: 0.182\n",
      "Fold: 4, TrainF1: 0.391, ValF1: 0.156\n",
      "Fold: 5, TrainF1: 0.258, ValF1: 0.096\n",
      "Fold: 6, TrainF1: 0.294, ValF1: 0.153\n",
      "Fold: 7, TrainF1: 0.414, ValF1: 0.304\n",
      "Fold: 8, TrainF1: 0.384, ValF1: 0.068\n",
      "Fold: 9, TrainF1: 0.333, ValF1: 0.133\n",
      "Fold: 10, TrainF1: 0.326, ValF1: 0.145\n",
      "[[154  63  88  51]\n",
      " [  5   0   4   1]\n",
      " [ 38   4  20  24]\n",
      " [ 32   6  28  11]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        154   63   88   51  356\n",
      "1.0          5    0    4    1   10\n",
      "2.0         38    4   20   24   86\n",
      "3.0         32    6   28   11   77\n",
      "All        229   73  140   87  529\n",
      "TrainF1: 0.348, ValidationF1: 0.16\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] ss_pca_0_95 param= 0.1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.365, ValF1: 0.245\n",
      "Fold: 2, TrainF1: 0.393, ValF1: 0.205\n",
      "Fold: 3, TrainF1: 0.42, ValF1: 0.316\n",
      "Fold: 4, TrainF1: 0.365, ValF1: 0.215\n",
      "Fold: 5, TrainF1: 0.347, ValF1: 0.098\n",
      "Fold: 6, TrainF1: 0.344, ValF1: 0.321\n",
      "Fold: 7, TrainF1: 0.397, ValF1: 0.207\n",
      "Fold: 8, TrainF1: 0.377, ValF1: 0.265\n",
      "Fold: 9, TrainF1: 0.446, ValF1: 0.171\n",
      "Fold: 10, TrainF1: 0.334, ValF1: 0.16\n",
      "[[170  39  94  53]\n",
      " [  5   0   3   2]\n",
      " [ 38   4  31  13]\n",
      " [ 29   3  30  15]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        170   39   94   53  356\n",
      "1.0          5    0    3    2   10\n",
      "2.0         38    4   31   13   86\n",
      "3.0         29    3   30   15   77\n",
      "All        242   46  158   83  529\n",
      "TrainF1: 0.379, ValidationF1: 0.22\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_f_reg_0_10 param= 0.1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.177, ValF1: 0.173\n",
      "Fold: 2, TrainF1: 0.126, ValF1: 0.195\n",
      "Fold: 3, TrainF1: 0.126, ValF1: 0.121\n",
      "Fold: 4, TrainF1: 0.066, ValF1: 0.062\n",
      "Fold: 5, TrainF1: 0.15, ValF1: 0.108\n",
      "Fold: 6, TrainF1: 0.202, ValF1: 0.152\n",
      "Fold: 7, TrainF1: 0.081, ValF1: 0.068\n",
      "Fold: 8, TrainF1: 0.113, ValF1: 0.173\n",
      "Fold: 9, TrainF1: 0.135, ValF1: 0.098\n",
      "Fold: 10, TrainF1: 0.215, ValF1: 0.153\n",
      "[[ 55  60  95 146]\n",
      " [  2   0   1   7]\n",
      " [  7  10  23  46]\n",
      " [  4  12  15  46]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         55   60   95  146  356\n",
      "1.0          2    0    1    7   10\n",
      "2.0          7   10   23   46   86\n",
      "3.0          4   12   15   46   77\n",
      "All         68   82  134  245  529\n",
      "TrainF1: 0.139, ValidationF1: 0.13\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_f_reg_0_10 param= 0.1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.065, ValF1: 0.067\n",
      "Fold: 2, TrainF1: 0.085, ValF1: 0.128\n",
      "Fold: 3, TrainF1: 0.141, ValF1: 0.136\n",
      "Fold: 4, TrainF1: 0.217, ValF1: 0.202\n",
      "Fold: 5, TrainF1: 0.01, ValF1: 0.0\n",
      "Fold: 6, TrainF1: 0.065, ValF1: 0.067\n",
      "Fold: 7, TrainF1: 0.081, ValF1: 0.069\n",
      "Fold: 8, TrainF1: 0.25, ValF1: 0.215\n",
      "Fold: 9, TrainF1: 0.036, ValF1: 0.01\n",
      "Fold: 10, TrainF1: 0.091, ValF1: 0.049\n",
      "[[ 86  94  76 100]\n",
      " [  3   1   4   2]\n",
      " [  9  25  21  31]\n",
      " [ 15  29  16  17]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         86   94   76  100  356\n",
      "1.0          3    1    4    2   10\n",
      "2.0          9   25   21   31   86\n",
      "3.0         15   29   16   17   77\n",
      "All        113  149  117  150  529\n",
      "TrainF1: 0.104, ValidationF1: 0.094\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_mutual_info_0_10 param= 0.1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.009, ValF1: 0.01\n",
      "Fold: 2, TrainF1: 0.104, ValF1: 0.091\n",
      "Fold: 3, TrainF1: 0.082, ValF1: 0.061\n",
      "Fold: 4, TrainF1: 0.088, ValF1: 0.056\n",
      "Fold: 5, TrainF1: 0.091, ValF1: 0.076\n",
      "Fold: 6, TrainF1: 0.11, ValF1: 0.079\n",
      "Fold: 7, TrainF1: 0.202, ValF1: 0.103\n",
      "Fold: 8, TrainF1: 0.152, ValF1: 0.14\n",
      "Fold: 9, TrainF1: 0.068, ValF1: 0.116\n",
      "Fold: 10, TrainF1: 0.068, ValF1: 0.03\n",
      "[[ 11  86 153 106]\n",
      " [  0   2   7   1]\n",
      " [  2  15  42  27]\n",
      " [  2  21  37  17]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         11   86  153  106  356\n",
      "1.0          0    2    7    1   10\n",
      "2.0          2   15   42   27   86\n",
      "3.0          2   21   37   17   77\n",
      "All         15  124  239  151  529\n",
      "TrainF1: 0.097, ValidationF1: 0.076\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_mutual_info_0_10 param= 0.1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.248, ValF1: 0.164\n",
      "Fold: 2, TrainF1: 0.009, ValF1: 0.01\n",
      "Fold: 3, TrainF1: 0.084, ValF1: 0.082\n",
      "Fold: 4, TrainF1: 0.224, ValF1: 0.213\n",
      "Fold: 5, TrainF1: 0.237, ValF1: 0.213\n",
      "Fold: 6, TrainF1: 0.055, ValF1: 0.035\n",
      "Fold: 7, TrainF1: 0.217, ValF1: 0.189\n",
      "Fold: 8, TrainF1: 0.069, ValF1: 0.068\n",
      "Fold: 9, TrainF1: 0.219, ValF1: 0.232\n",
      "Fold: 10, TrainF1: 0.171, ValF1: 0.21\n",
      "[[168  98  46  44]\n",
      " [  3   3   2   2]\n",
      " [ 36  22  13  15]\n",
      " [ 33  27   4  13]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        168   98   46   44  356\n",
      "1.0          3    3    2    2   10\n",
      "2.0         36   22   13   15   86\n",
      "3.0         33   27    4   13   77\n",
      "All        240  150   65   74  529\n",
      "TrainF1: 0.153, ValidationF1: 0.142\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] None param= 0.1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.083, ValF1: 0.061\n",
      "Fold: 2, TrainF1: 0.028, ValF1: 0.01\n",
      "Fold: 3, TrainF1: 0.168, ValF1: 0.148\n",
      "Fold: 4, TrainF1: 0.291, ValF1: 0.246\n",
      "Fold: 5, TrainF1: 0.204, ValF1: 0.233\n",
      "Fold: 6, TrainF1: 0.01, ValF1: 0.0\n",
      "Fold: 7, TrainF1: 0.09, ValF1: 0.075\n",
      "Fold: 8, TrainF1: 0.25, ValF1: 0.222\n",
      "Fold: 9, TrainF1: 0.009, ValF1: 0.01\n",
      "Fold: 10, TrainF1: 0.073, ValF1: 0.062\n",
      "[[100 137 102  17]\n",
      " [  1   2   4   3]\n",
      " [ 32  23  24   7]\n",
      " [ 17  29  27   4]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        100  137  102   17  356\n",
      "1.0          1    2    4    3   10\n",
      "2.0         32   23   24    7   86\n",
      "3.0         17   29   27    4   77\n",
      "All        150  191  157   31  529\n",
      "TrainF1: 0.121, ValidationF1: 0.107\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] None param= 0.1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.082, ValF1: 0.075\n",
      "Fold: 2, TrainF1: 0.136, ValF1: 0.111\n",
      "Fold: 3, TrainF1: 0.013, ValF1: 0.019\n",
      "Fold: 4, TrainF1: 0.096, ValF1: 0.098\n",
      "Fold: 5, TrainF1: 0.229, ValF1: 0.162\n",
      "Fold: 6, TrainF1: 0.01, ValF1: 0.0\n",
      "Fold: 7, TrainF1: 0.083, ValF1: 0.085\n",
      "Fold: 8, TrainF1: 0.105, ValF1: 0.077\n",
      "Fold: 9, TrainF1: 0.191, ValF1: 0.152\n",
      "Fold: 10, TrainF1: 0.064, ValF1: 0.065\n",
      "[[ 27 102 176  51]\n",
      " [  2   2   4   2]\n",
      " [  8  27  46   5]\n",
      " [  9  23  36   9]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         27  102  176   51  356\n",
      "1.0          2    2    4    2   10\n",
      "2.0          8   27   46    5   86\n",
      "3.0          9   23   36    9   77\n",
      "All         46  154  262   67  529\n",
      "TrainF1: 0.101, ValidationF1: 0.084\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] ss_pca_0_95 param= 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.741, ValF1: 0.445\n",
      "Fold: 2, TrainF1: 0.725, ValF1: 0.375\n",
      "Fold: 3, TrainF1: 0.737, ValF1: 0.177\n",
      "Fold: 4, TrainF1: 0.74, ValF1: 0.258\n",
      "Fold: 5, TrainF1: 0.711, ValF1: 0.281\n",
      "Fold: 6, TrainF1: 0.721, ValF1: 0.23\n",
      "Fold: 7, TrainF1: 0.735, ValF1: 0.206\n",
      "Fold: 8, TrainF1: 0.716, ValF1: 0.23\n",
      "Fold: 9, TrainF1: 0.751, ValF1: 0.494\n",
      "Fold: 10, TrainF1: 0.761, ValF1: 0.226\n",
      "[[219   0  50  87]\n",
      " [  8   0   0   2]\n",
      " [ 43   0  16  27]\n",
      " [ 43   0  13  21]]\n",
      "Predicted  0.0  2.0  3.0  All\n",
      "True                         \n",
      "0.0        219   50   87  356\n",
      "1.0          8    0    2   10\n",
      "2.0         43   16   27   86\n",
      "3.0         43   13   21   77\n",
      "All        313   79  137  529\n",
      "TrainF1: 0.734, ValidationF1: 0.292\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] ss_pca_0_95 param= 1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.713, ValF1: 0.356\n",
      "Fold: 2, TrainF1: 0.744, ValF1: 0.316\n",
      "Fold: 3, TrainF1: 0.723, ValF1: 0.297\n",
      "Fold: 4, TrainF1: 0.706, ValF1: 0.353\n",
      "Fold: 5, TrainF1: 0.723, ValF1: 0.256\n",
      "Fold: 6, TrainF1: 0.732, ValF1: 0.18\n",
      "Fold: 7, TrainF1: 0.723, ValF1: 0.192\n",
      "Fold: 8, TrainF1: 0.748, ValF1: 0.218\n",
      "Fold: 9, TrainF1: 0.713, ValF1: 0.287\n",
      "Fold: 10, TrainF1: 0.725, ValF1: 0.238\n",
      "[[217   2  55  82]\n",
      " [  8   0   0   2]\n",
      " [ 44   1  14  27]\n",
      " [ 41   0  14  22]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        217    2   55   82  356\n",
      "1.0          8    0    0    2   10\n",
      "2.0         44    1   14   27   86\n",
      "3.0         41    0   14   22   77\n",
      "All        310    3   83  133  529\n",
      "TrainF1: 0.725, ValidationF1: 0.269\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_f_reg_0_10 param= 1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.225, ValF1: 0.202\n",
      "Fold: 2, TrainF1: 0.264, ValF1: 0.175\n",
      "Fold: 3, TrainF1: 0.225, ValF1: 0.113\n",
      "Fold: 4, TrainF1: 0.248, ValF1: 0.237\n",
      "Fold: 5, TrainF1: 0.251, ValF1: 0.191\n",
      "Fold: 6, TrainF1: 0.224, ValF1: 0.151\n",
      "Fold: 7, TrainF1: 0.228, ValF1: 0.248\n",
      "Fold: 8, TrainF1: 0.22, ValF1: 0.138\n",
      "Fold: 9, TrainF1: 0.218, ValF1: 0.198\n",
      "Fold: 10, TrainF1: 0.251, ValF1: 0.193\n",
      "[[ 63  51  97 145]\n",
      " [  1   0   4   5]\n",
      " [ 12  11  21  42]\n",
      " [  9   4  16  48]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         63   51   97  145  356\n",
      "1.0          1    0    4    5   10\n",
      "2.0         12   11   21   42   86\n",
      "3.0          9    4   16   48   77\n",
      "All         85   66  138  240  529\n",
      "TrainF1: 0.235, ValidationF1: 0.184\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_f_reg_0_10 param= 1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.185, ValF1: 0.2\n",
      "Fold: 2, TrainF1: 0.214, ValF1: 0.221\n",
      "Fold: 3, TrainF1: 0.186, ValF1: 0.189\n",
      "Fold: 4, TrainF1: 0.174, ValF1: 0.137\n",
      "Fold: 5, TrainF1: 0.211, ValF1: 0.034\n",
      "Fold: 6, TrainF1: 0.227, ValF1: 0.3\n",
      "Fold: 7, TrainF1: 0.217, ValF1: 0.173\n",
      "Fold: 8, TrainF1: 0.191, ValF1: 0.335\n",
      "Fold: 9, TrainF1: 0.18, ValF1: 0.143\n",
      "Fold: 10, TrainF1: 0.199, ValF1: 0.076\n",
      "[[ 42  31 142 141]\n",
      " [  1   2   3   4]\n",
      " [  7  15  38  26]\n",
      " [  4   9  34  30]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         42   31  142  141  356\n",
      "1.0          1    2    3    4   10\n",
      "2.0          7   15   38   26   86\n",
      "3.0          4    9   34   30   77\n",
      "All         54   57  217  201  529\n",
      "TrainF1: 0.198, ValidationF1: 0.181\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_mutual_info_0_10 param= 1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.252, ValF1: 0.124\n",
      "Fold: 2, TrainF1: 0.139, ValF1: 0.14\n",
      "Fold: 3, TrainF1: 0.258, ValF1: 0.184\n",
      "Fold: 4, TrainF1: 0.233, ValF1: 0.18\n",
      "Fold: 5, TrainF1: 0.193, ValF1: 0.151\n",
      "Fold: 6, TrainF1: 0.255, ValF1: 0.238\n",
      "Fold: 7, TrainF1: 0.278, ValF1: 0.205\n",
      "Fold: 8, TrainF1: 0.235, ValF1: 0.202\n",
      "Fold: 9, TrainF1: 0.222, ValF1: 0.226\n",
      "Fold: 10, TrainF1: 0.27, ValF1: 0.141\n",
      "[[ 78  67  74 137]\n",
      " [  2   2   3   3]\n",
      " [ 16  25   5  40]\n",
      " [ 10   6  12  49]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         78   67   74  137  356\n",
      "1.0          2    2    3    3   10\n",
      "2.0         16   25    5   40   86\n",
      "3.0         10    6   12   49   77\n",
      "All        106  100   94  229  529\n",
      "TrainF1: 0.234, ValidationF1: 0.179\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_mutual_info_0_10 param= 1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.235, ValF1: 0.23\n",
      "Fold: 2, TrainF1: 0.228, ValF1: 0.122\n",
      "Fold: 3, TrainF1: 0.206, ValF1: 0.199\n",
      "Fold: 4, TrainF1: 0.269, ValF1: 0.337\n",
      "Fold: 5, TrainF1: 0.228, ValF1: 0.113\n",
      "Fold: 6, TrainF1: 0.152, ValF1: 0.166\n",
      "Fold: 7, TrainF1: 0.15, ValF1: 0.167\n",
      "Fold: 8, TrainF1: 0.218, ValF1: 0.253\n",
      "Fold: 9, TrainF1: 0.216, ValF1: 0.258\n",
      "Fold: 10, TrainF1: 0.13, ValF1: 0.084\n",
      "[[ 75  55 101 125]\n",
      " [  3   1   3   3]\n",
      " [  9  11  35  31]\n",
      " [ 12   8  24  33]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         75   55  101  125  356\n",
      "1.0          3    1    3    3   10\n",
      "2.0          9   11   35   31   86\n",
      "3.0         12    8   24   33   77\n",
      "All         99   75  163  192  529\n",
      "TrainF1: 0.203, ValidationF1: 0.193\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] None param= 1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.246, ValF1: 0.227\n",
      "Fold: 2, TrainF1: 0.23, ValF1: 0.282\n",
      "Fold: 3, TrainF1: 0.23, ValF1: 0.278\n",
      "Fold: 4, TrainF1: 0.23, ValF1: 0.235\n",
      "Fold: 5, TrainF1: 0.251, ValF1: 0.179\n",
      "Fold: 6, TrainF1: 0.24, ValF1: 0.25\n",
      "Fold: 7, TrainF1: 0.243, ValF1: 0.157\n",
      "Fold: 8, TrainF1: 0.176, ValF1: 0.176\n",
      "Fold: 9, TrainF1: 0.255, ValF1: 0.108\n",
      "Fold: 10, TrainF1: 0.246, ValF1: 0.165\n",
      "[[ 69  55  99 133]\n",
      " [  1   1   4   4]\n",
      " [  9  14  24  39]\n",
      " [  6   7  18  46]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         69   55   99  133  356\n",
      "1.0          1    1    4    4   10\n",
      "2.0          9   14   24   39   86\n",
      "3.0          6    7   18   46   77\n",
      "All         85   77  145  222  529\n",
      "TrainF1: 0.235, ValidationF1: 0.206\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] None param= 1\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.202, ValF1: 0.129\n",
      "Fold: 2, TrainF1: 0.15, ValF1: 0.193\n",
      "Fold: 3, TrainF1: 0.162, ValF1: 0.175\n",
      "Fold: 4, TrainF1: 0.19, ValF1: 0.134\n",
      "Fold: 5, TrainF1: 0.215, ValF1: 0.216\n",
      "Fold: 6, TrainF1: 0.176, ValF1: 0.137\n",
      "Fold: 7, TrainF1: 0.154, ValF1: 0.167\n",
      "Fold: 8, TrainF1: 0.204, ValF1: 0.11\n",
      "Fold: 9, TrainF1: 0.192, ValF1: 0.267\n",
      "Fold: 10, TrainF1: 0.17, ValF1: 0.102\n",
      "[[ 30  28 163 135]\n",
      " [  1   0   6   3]\n",
      " [  5   4  50  27]\n",
      " [  8   3  37  29]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         30   28  163  135  356\n",
      "1.0          1    0    6    3   10\n",
      "2.0          5    4   50   27   86\n",
      "3.0          8    3   37   29   77\n",
      "All         44   35  256  194  529\n",
      "TrainF1: 0.182, ValidationF1: 0.163\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] ss_pca_0_95 param= 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.96, ValF1: 0.268\n",
      "Fold: 2, TrainF1: 0.956, ValF1: 0.335\n",
      "Fold: 3, TrainF1: 0.957, ValF1: 0.358\n",
      "Fold: 4, TrainF1: 0.96, ValF1: 0.195\n",
      "Fold: 5, TrainF1: 0.961, ValF1: 0.243\n",
      "Fold: 6, TrainF1: 0.962, ValF1: 0.245\n",
      "Fold: 7, TrainF1: 0.967, ValF1: 0.273\n",
      "Fold: 8, TrainF1: 0.959, ValF1: 0.356\n",
      "Fold: 9, TrainF1: 0.957, ValF1: 0.164\n",
      "Fold: 10, TrainF1: 0.954, ValF1: 0.302\n",
      "[[284   1  33  38]\n",
      " [ 10   0   0   0]\n",
      " [ 61   0  12  13]\n",
      " [ 53   0  14  10]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        284    1   33   38  356\n",
      "1.0         10    0    0    0   10\n",
      "2.0         61    0   12   13   86\n",
      "3.0         53    0   14   10   77\n",
      "All        408    1   59   61  529\n",
      "TrainF1: 0.959, ValidationF1: 0.274\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] ss_pca_0_95 param= 10\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.96, ValF1: 0.203\n",
      "Fold: 2, TrainF1: 0.961, ValF1: 0.398\n",
      "Fold: 3, TrainF1: 0.967, ValF1: 0.231\n",
      "Fold: 4, TrainF1: 0.957, ValF1: 0.261\n",
      "Fold: 5, TrainF1: 0.962, ValF1: 0.253\n",
      "Fold: 6, TrainF1: 0.96, ValF1: 0.278\n",
      "Fold: 7, TrainF1: 0.961, ValF1: 0.242\n",
      "Fold: 8, TrainF1: 0.961, ValF1: 0.393\n",
      "Fold: 9, TrainF1: 0.97, ValF1: 0.261\n",
      "Fold: 10, TrainF1: 0.971, ValF1: 0.388\n",
      "[[290   0  32  34]\n",
      " [  9   0   1   0]\n",
      " [ 66   1  11   8]\n",
      " [ 54   0  10  13]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        290    0   32   34  356\n",
      "1.0          9    0    1    0   10\n",
      "2.0         66    1   11    8   86\n",
      "3.0         54    0   10   13   77\n",
      "All        419    1   54   55  529\n",
      "TrainF1: 0.963, ValidationF1: 0.291\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_f_reg_0_10 param= 10\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.296, ValF1: 0.137\n",
      "Fold: 2, TrainF1: 0.272, ValF1: 0.212\n",
      "Fold: 3, TrainF1: 0.268, ValF1: 0.262\n",
      "Fold: 4, TrainF1: 0.299, ValF1: 0.26\n",
      "Fold: 5, TrainF1: 0.233, ValF1: 0.109\n",
      "Fold: 6, TrainF1: 0.28, ValF1: 0.246\n",
      "Fold: 7, TrainF1: 0.29, ValF1: 0.201\n",
      "Fold: 8, TrainF1: 0.243, ValF1: 0.271\n",
      "Fold: 9, TrainF1: 0.267, ValF1: 0.208\n",
      "Fold: 10, TrainF1: 0.282, ValF1: 0.227\n",
      "[[108  64  45 139]\n",
      " [  2   1   2   5]\n",
      " [ 19  15  10  42]\n",
      " [ 11  12   6  48]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        108   64   45  139  356\n",
      "1.0          2    1    2    5   10\n",
      "2.0         19   15   10   42   86\n",
      "3.0         11   12    6   48   77\n",
      "All        140   92   63  234  529\n",
      "TrainF1: 0.273, ValidationF1: 0.213\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_f_reg_0_10 param= 10\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.201, ValF1: 0.172\n",
      "Fold: 2, TrainF1: 0.245, ValF1: 0.216\n",
      "Fold: 3, TrainF1: 0.259, ValF1: 0.116\n",
      "Fold: 4, TrainF1: 0.224, ValF1: 0.119\n",
      "Fold: 5, TrainF1: 0.223, ValF1: 0.044\n",
      "Fold: 6, TrainF1: 0.23, ValF1: 0.143\n",
      "Fold: 7, TrainF1: 0.192, ValF1: 0.316\n",
      "Fold: 8, TrainF1: 0.165, ValF1: 0.111\n",
      "Fold: 9, TrainF1: 0.221, ValF1: 0.23\n",
      "Fold: 10, TrainF1: 0.218, ValF1: 0.164\n",
      "[[ 54  65 113 124]\n",
      " [  2   1   6   1]\n",
      " [  7  18  37  24]\n",
      " [ 12  10  25  30]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         54   65  113  124  356\n",
      "1.0          2    1    6    1   10\n",
      "2.0          7   18   37   24   86\n",
      "3.0         12   10   25   30   77\n",
      "All         75   94  181  179  529\n",
      "TrainF1: 0.218, ValidationF1: 0.163\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_mutual_info_0_10 param= 10\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.244, ValF1: 0.25\n",
      "Fold: 2, TrainF1: 0.263, ValF1: 0.28\n",
      "Fold: 3, TrainF1: 0.293, ValF1: 0.149\n",
      "Fold: 4, TrainF1: 0.228, ValF1: 0.353\n",
      "Fold: 5, TrainF1: 0.264, ValF1: 0.215\n",
      "Fold: 6, TrainF1: 0.293, ValF1: 0.119\n",
      "Fold: 7, TrainF1: 0.272, ValF1: 0.278\n",
      "Fold: 8, TrainF1: 0.274, ValF1: 0.117\n",
      "Fold: 9, TrainF1: 0.284, ValF1: 0.183\n",
      "Fold: 10, TrainF1: 0.287, ValF1: 0.236\n",
      "[[ 94  68  46 148]\n",
      " [  3   0   2   5]\n",
      " [ 16  11  16  43]\n",
      " [  9   8  10  50]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         94   68   46  148  356\n",
      "1.0          3    0    2    5   10\n",
      "2.0         16   11   16   43   86\n",
      "3.0          9    8   10   50   77\n",
      "All        122   87   74  246  529\n",
      "TrainF1: 0.27, ValidationF1: 0.218\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_mutual_info_0_10 param= 10\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.223, ValF1: 0.083\n",
      "Fold: 2, TrainF1: 0.186, ValF1: 0.147\n",
      "Fold: 3, TrainF1: 0.214, ValF1: 0.07\n",
      "Fold: 4, TrainF1: 0.206, ValF1: 0.277\n",
      "Fold: 5, TrainF1: 0.218, ValF1: 0.222\n",
      "Fold: 6, TrainF1: 0.277, ValF1: 0.22\n",
      "Fold: 7, TrainF1: 0.227, ValF1: 0.201\n",
      "Fold: 8, TrainF1: 0.224, ValF1: 0.173\n",
      "Fold: 9, TrainF1: 0.228, ValF1: 0.15\n",
      "Fold: 10, TrainF1: 0.243, ValF1: 0.155\n",
      "[[ 84  98  40 134]\n",
      " [  3   2   2   3]\n",
      " [ 16  25   8  37]\n",
      " [  9  19  11  38]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         84   98   40  134  356\n",
      "1.0          3    2    2    3   10\n",
      "2.0         16   25    8   37   86\n",
      "3.0          9   19   11   38   77\n",
      "All        112  144   61  212  529\n",
      "TrainF1: 0.225, ValidationF1: 0.17\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] None param= 10\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.242, ValF1: 0.314\n",
      "Fold: 2, TrainF1: 0.28, ValF1: 0.133\n",
      "Fold: 3, TrainF1: 0.267, ValF1: 0.163\n",
      "Fold: 4, TrainF1: 0.246, ValF1: 0.182\n",
      "Fold: 5, TrainF1: 0.223, ValF1: 0.265\n",
      "Fold: 6, TrainF1: 0.259, ValF1: 0.229\n",
      "Fold: 7, TrainF1: 0.271, ValF1: 0.252\n",
      "Fold: 8, TrainF1: 0.283, ValF1: 0.165\n",
      "Fold: 9, TrainF1: 0.281, ValF1: 0.189\n",
      "Fold: 10, TrainF1: 0.297, ValF1: 0.195\n",
      "[[ 93 100  37 126]\n",
      " [  2   2   3   3]\n",
      " [ 21  21   9  35]\n",
      " [ 12  11   8  46]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         93  100   37  126  356\n",
      "1.0          2    2    3    3   10\n",
      "2.0         21   21    9   35   86\n",
      "3.0         12   11    8   46   77\n",
      "All        128  134   57  210  529\n",
      "TrainF1: 0.265, ValidationF1: 0.209\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] None param= 10\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.209, ValF1: 0.248\n",
      "Fold: 2, TrainF1: 0.208, ValF1: 0.094\n",
      "Fold: 3, TrainF1: 0.176, ValF1: 0.041\n",
      "Fold: 4, TrainF1: 0.226, ValF1: 0.128\n",
      "Fold: 5, TrainF1: 0.202, ValF1: 0.172\n",
      "Fold: 6, TrainF1: 0.196, ValF1: 0.138\n",
      "Fold: 7, TrainF1: 0.224, ValF1: 0.121\n",
      "Fold: 8, TrainF1: 0.186, ValF1: 0.252\n",
      "Fold: 9, TrainF1: 0.235, ValF1: 0.149\n",
      "Fold: 10, TrainF1: 0.215, ValF1: 0.168\n",
      "[[ 31  43 162 120]\n",
      " [  1   1   6   2]\n",
      " [  5   5  52  24]\n",
      " [  8   4  40  25]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         31   43  162  120  356\n",
      "1.0          1    1    6    2   10\n",
      "2.0          5    5   52   24   86\n",
      "3.0          8    4   40   25   77\n",
      "All         45   53  260  171  529\n",
      "TrainF1: 0.208, ValidationF1: 0.151\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] ss_pca_0_95 param= 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 1.0, ValF1: 0.38\n",
      "Fold: 2, TrainF1: 1.0, ValF1: 0.228\n",
      "Fold: 3, TrainF1: 1.0, ValF1: 0.321\n",
      "Fold: 4, TrainF1: 1.0, ValF1: 0.235\n",
      "Fold: 5, TrainF1: 1.0, ValF1: 0.347\n",
      "Fold: 6, TrainF1: 1.0, ValF1: 0.446\n",
      "Fold: 7, TrainF1: 1.0, ValF1: 0.226\n",
      "Fold: 8, TrainF1: 1.0, ValF1: 0.288\n",
      "Fold: 9, TrainF1: 1.0, ValF1: 0.272\n",
      "Fold: 10, TrainF1: 1.0, ValF1: 0.254\n",
      "[[297   0  31  28]\n",
      " [ 10   0   0   0]\n",
      " [ 59   0  17  10]\n",
      " [ 59   0  13   5]]\n",
      "Predicted  0.0  2.0  3.0  All\n",
      "True                         \n",
      "0.0        297   31   28  356\n",
      "1.0         10    0    0   10\n",
      "2.0         59   17   10   86\n",
      "3.0         59   13    5   77\n",
      "All        425   61   43  529\n",
      "TrainF1: 1.0, ValidationF1: 0.3\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] ss_pca_0_95 param= 100\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 1.0, ValF1: 0.278\n",
      "Fold: 2, TrainF1: 1.0, ValF1: 0.264\n",
      "Fold: 3, TrainF1: 1.0, ValF1: 0.319\n",
      "Fold: 4, TrainF1: 1.0, ValF1: 0.29\n",
      "Fold: 5, TrainF1: 1.0, ValF1: 0.205\n",
      "Fold: 6, TrainF1: 1.0, ValF1: 0.407\n",
      "Fold: 7, TrainF1: 1.0, ValF1: 0.306\n",
      "Fold: 8, TrainF1: 1.0, ValF1: 0.392\n",
      "Fold: 9, TrainF1: 1.0, ValF1: 0.208\n",
      "Fold: 10, TrainF1: 1.0, ValF1: 0.263\n",
      "[[295   1  36  24]\n",
      " [ 10   0   0   0]\n",
      " [ 62   0  17   7]\n",
      " [ 57   0  12   8]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        295    1   36   24  356\n",
      "1.0         10    0    0    0   10\n",
      "2.0         62    0   17    7   86\n",
      "3.0         57    0   12    8   77\n",
      "All        424    1   65   39  529\n",
      "TrainF1: 1.0, ValidationF1: 0.293\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_f_reg_0_10 param= 100\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.308, ValF1: 0.27\n",
      "Fold: 2, TrainF1: 0.299, ValF1: 0.264\n",
      "Fold: 3, TrainF1: 0.311, ValF1: 0.237\n",
      "Fold: 4, TrainF1: 0.276, ValF1: 0.196\n",
      "Fold: 5, TrainF1: 0.325, ValF1: 0.155\n",
      "Fold: 6, TrainF1: 0.317, ValF1: 0.199\n",
      "Fold: 7, TrainF1: 0.291, ValF1: 0.12\n",
      "Fold: 8, TrainF1: 0.309, ValF1: 0.306\n",
      "Fold: 9, TrainF1: 0.338, ValF1: 0.139\n",
      "Fold: 10, TrainF1: 0.295, ValF1: 0.26\n",
      "[[104  73  64 115]\n",
      " [  2   1   4   3]\n",
      " [ 15  17  16  38]\n",
      " [ 14  17   7  39]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        104   73   64  115  356\n",
      "1.0          2    1    4    3   10\n",
      "2.0         15   17   16   38   86\n",
      "3.0         14   17    7   39   77\n",
      "All        135  108   91  195  529\n",
      "TrainF1: 0.307, ValidationF1: 0.215\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_f_reg_0_10 param= 100\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.223, ValF1: 0.221\n",
      "Fold: 2, TrainF1: 0.223, ValF1: 0.22\n",
      "Fold: 3, TrainF1: 0.212, ValF1: 0.144\n",
      "Fold: 4, TrainF1: 0.211, ValF1: 0.12\n",
      "Fold: 5, TrainF1: 0.253, ValF1: 0.169\n",
      "Fold: 6, TrainF1: 0.241, ValF1: 0.211\n",
      "Fold: 7, TrainF1: 0.278, ValF1: 0.187\n",
      "Fold: 8, TrainF1: 0.233, ValF1: 0.127\n",
      "Fold: 9, TrainF1: 0.309, ValF1: 0.148\n",
      "Fold: 10, TrainF1: 0.25, ValF1: 0.229\n",
      "[[ 60  38 143 115]\n",
      " [  2   0   5   3]\n",
      " [  8   6  42  30]\n",
      " [ 12   6  37  22]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         60   38  143  115  356\n",
      "1.0          2    0    5    3   10\n",
      "2.0          8    6   42   30   86\n",
      "3.0         12    6   37   22   77\n",
      "All         82   50  227  170  529\n",
      "TrainF1: 0.243, ValidationF1: 0.178\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_mutual_info_0_10 param= 100\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.312, ValF1: 0.217\n",
      "Fold: 2, TrainF1: 0.323, ValF1: 0.24\n",
      "Fold: 3, TrainF1: 0.271, ValF1: 0.267\n",
      "Fold: 4, TrainF1: 0.31, ValF1: 0.338\n",
      "Fold: 5, TrainF1: 0.296, ValF1: 0.283\n",
      "Fold: 6, TrainF1: 0.3, ValF1: 0.143\n",
      "Fold: 7, TrainF1: 0.321, ValF1: 0.17\n",
      "Fold: 8, TrainF1: 0.314, ValF1: 0.178\n",
      "Fold: 9, TrainF1: 0.293, ValF1: 0.143\n",
      "Fold: 10, TrainF1: 0.317, ValF1: 0.165\n",
      "[[109  55  73 119]\n",
      " [  2   1   4   3]\n",
      " [ 17   9  20  40]\n",
      " [ 14  10  14  39]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        109   55   73  119  356\n",
      "1.0          2    1    4    3   10\n",
      "2.0         17    9   20   40   86\n",
      "3.0         14   10   14   39   77\n",
      "All        142   75  111  201  529\n",
      "TrainF1: 0.306, ValidationF1: 0.214\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_mutual_info_0_10 param= 100\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.281, ValF1: 0.321\n",
      "Fold: 2, TrainF1: 0.216, ValF1: 0.145\n",
      "Fold: 3, TrainF1: 0.348, ValF1: 0.227\n",
      "Fold: 4, TrainF1: 0.255, ValF1: 0.116\n",
      "Fold: 5, TrainF1: 0.22, ValF1: 0.15\n",
      "Fold: 6, TrainF1: 0.242, ValF1: 0.232\n",
      "Fold: 7, TrainF1: 0.28, ValF1: 0.182\n",
      "Fold: 8, TrainF1: 0.294, ValF1: 0.081\n",
      "Fold: 9, TrainF1: 0.261, ValF1: 0.137\n",
      "Fold: 10, TrainF1: 0.22, ValF1: 0.243\n",
      "[[ 83  59  96 118]\n",
      " [  1   1   4   4]\n",
      " [ 10  21  26  29]\n",
      " [ 11   8  24  34]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         83   59   96  118  356\n",
      "1.0          1    1    4    4   10\n",
      "2.0         10   21   26   29   86\n",
      "3.0         11    8   24   34   77\n",
      "All        105   89  150  185  529\n",
      "TrainF1: 0.262, ValidationF1: 0.183\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] None param= 100\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.302, ValF1: 0.26\n",
      "Fold: 2, TrainF1: 0.305, ValF1: 0.158\n",
      "Fold: 3, TrainF1: 0.313, ValF1: 0.243\n",
      "Fold: 4, TrainF1: 0.308, ValF1: 0.272\n",
      "Fold: 5, TrainF1: 0.331, ValF1: 0.281\n",
      "Fold: 6, TrainF1: 0.298, ValF1: 0.282\n",
      "Fold: 7, TrainF1: 0.315, ValF1: 0.268\n",
      "Fold: 8, TrainF1: 0.313, ValF1: 0.175\n",
      "Fold: 9, TrainF1: 0.313, ValF1: 0.215\n",
      "Fold: 10, TrainF1: 0.293, ValF1: 0.27\n",
      "[[114  58  66 118]\n",
      " [  2   1   4   3]\n",
      " [ 18  15  19  34]\n",
      " [ 15  13   7  42]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        114   58   66  118  356\n",
      "1.0          2    1    4    3   10\n",
      "2.0         18   15   19   34   86\n",
      "3.0         15   13    7   42   77\n",
      "All        149   87   96  197  529\n",
      "TrainF1: 0.309, ValidationF1: 0.243\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] None param= 100\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.244, ValF1: 0.224\n",
      "Fold: 2, TrainF1: 0.239, ValF1: 0.243\n",
      "Fold: 3, TrainF1: 0.229, ValF1: 0.141\n",
      "Fold: 4, TrainF1: 0.229, ValF1: 0.298\n",
      "Fold: 5, TrainF1: 0.221, ValF1: 0.173\n",
      "Fold: 6, TrainF1: 0.243, ValF1: 0.194\n",
      "Fold: 7, TrainF1: 0.26, ValF1: 0.07\n",
      "Fold: 8, TrainF1: 0.197, ValF1: 0.142\n",
      "Fold: 9, TrainF1: 0.255, ValF1: 0.156\n",
      "Fold: 10, TrainF1: 0.156, ValF1: 0.139\n",
      "[[ 73  54 149  80]\n",
      " [  2   1   6   1]\n",
      " [  9  13  47  17]\n",
      " [ 14   7  40  16]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         73   54  149   80  356\n",
      "1.0          2    1    6    1   10\n",
      "2.0          9   13   47   17   86\n",
      "3.0         14    7   40   16   77\n",
      "All         98   75  242  114  529\n",
      "TrainF1: 0.227, ValidationF1: 0.178\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] ss_pca_0_95 param= 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 1.0, ValF1: 0.37\n",
      "Fold: 2, TrainF1: 1.0, ValF1: 0.253\n",
      "Fold: 3, TrainF1: 1.0, ValF1: 0.291\n",
      "Fold: 4, TrainF1: 1.0, ValF1: 0.327\n",
      "Fold: 5, TrainF1: 1.0, ValF1: 0.184\n",
      "Fold: 6, TrainF1: 1.0, ValF1: 0.328\n",
      "Fold: 7, TrainF1: 1.0, ValF1: 0.253\n",
      "Fold: 8, TrainF1: 1.0, ValF1: 0.202\n",
      "Fold: 9, TrainF1: 1.0, ValF1: 0.199\n",
      "Fold: 10, TrainF1: 1.0, ValF1: 0.336\n",
      "[[305   0  30  21]\n",
      " [ 10   0   0   0]\n",
      " [ 60   0  12  14]\n",
      " [ 59   0  11   7]]\n",
      "Predicted  0.0  2.0  3.0  All\n",
      "True                         \n",
      "0.0        305   30   21  356\n",
      "1.0         10    0    0   10\n",
      "2.0         60   12   14   86\n",
      "3.0         59   11    7   77\n",
      "All        434   53   42  529\n",
      "TrainF1: 1.0, ValidationF1: 0.274\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] ss_pca_0_95 param= 1000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 1.0, ValF1: 0.272\n",
      "Fold: 2, TrainF1: 1.0, ValF1: 0.183\n",
      "Fold: 3, TrainF1: 1.0, ValF1: 0.32\n",
      "Fold: 4, TrainF1: 1.0, ValF1: 0.38\n",
      "Fold: 5, TrainF1: 1.0, ValF1: 0.324\n",
      "Fold: 6, TrainF1: 1.0, ValF1: 0.48\n",
      "Fold: 7, TrainF1: 1.0, ValF1: 0.384\n",
      "Fold: 8, TrainF1: 1.0, ValF1: 0.2\n",
      "Fold: 9, TrainF1: 1.0, ValF1: 0.247\n",
      "Fold: 10, TrainF1: 1.0, ValF1: 0.328\n",
      "[[298   0  34  24]\n",
      " [  9   0   1   0]\n",
      " [ 66   0  16   4]\n",
      " [ 58   0  10   9]]\n",
      "Predicted  0.0  2.0  3.0  All\n",
      "True                         \n",
      "0.0        298   34   24  356\n",
      "1.0          9    1    0   10\n",
      "2.0         66   16    4   86\n",
      "3.0         58   10    9   77\n",
      "All        431   61   37  529\n",
      "TrainF1: 1.0, ValidationF1: 0.312\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_f_reg_0_10 param= 1000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.37, ValF1: 0.341\n",
      "Fold: 2, TrainF1: 0.378, ValF1: 0.296\n",
      "Fold: 3, TrainF1: 0.364, ValF1: 0.157\n",
      "Fold: 4, TrainF1: 0.383, ValF1: 0.264\n",
      "Fold: 5, TrainF1: 0.324, ValF1: 0.297\n",
      "Fold: 6, TrainF1: 0.408, ValF1: 0.269\n",
      "Fold: 7, TrainF1: 0.403, ValF1: 0.201\n",
      "Fold: 8, TrainF1: 0.404, ValF1: 0.232\n",
      "Fold: 9, TrainF1: 0.439, ValF1: 0.199\n",
      "Fold: 10, TrainF1: 0.392, ValF1: 0.129\n",
      "[[131  61  64 100]\n",
      " [  4   0   3   3]\n",
      " [ 28   7  19  32]\n",
      " [ 19   8  16  34]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        131   61   64  100  356\n",
      "1.0          4    0    3    3   10\n",
      "2.0         28    7   19   32   86\n",
      "3.0         19    8   16   34   77\n",
      "All        182   76  102  169  529\n",
      "TrainF1: 0.386, ValidationF1: 0.239\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_f_reg_0_10 param= 1000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.329, ValF1: 0.151\n",
      "Fold: 2, TrainF1: 0.246, ValF1: 0.264\n",
      "Fold: 3, TrainF1: 0.353, ValF1: 0.305\n",
      "Fold: 4, TrainF1: 0.254, ValF1: 0.248\n",
      "Fold: 5, TrainF1: 0.25, ValF1: 0.095\n",
      "Fold: 6, TrainF1: 0.238, ValF1: 0.26\n",
      "Fold: 7, TrainF1: 0.333, ValF1: 0.204\n",
      "Fold: 8, TrainF1: 0.311, ValF1: 0.267\n",
      "Fold: 9, TrainF1: 0.27, ValF1: 0.146\n",
      "Fold: 10, TrainF1: 0.257, ValF1: 0.241\n",
      "[[104  34 137  81]\n",
      " [  3   0   4   3]\n",
      " [ 17   7  36  26]\n",
      " [ 14   9  25  29]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        104   34  137   81  356\n",
      "1.0          3    0    4    3   10\n",
      "2.0         17    7   36   26   86\n",
      "3.0         14    9   25   29   77\n",
      "All        138   50  202  139  529\n",
      "TrainF1: 0.284, ValidationF1: 0.218\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_mutual_info_0_10 param= 1000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.349, ValF1: 0.36\n",
      "Fold: 2, TrainF1: 0.386, ValF1: 0.191\n",
      "Fold: 3, TrainF1: 0.376, ValF1: 0.152\n",
      "Fold: 4, TrainF1: 0.369, ValF1: 0.308\n",
      "Fold: 5, TrainF1: 0.37, ValF1: 0.205\n",
      "Fold: 6, TrainF1: 0.419, ValF1: 0.163\n",
      "Fold: 7, TrainF1: 0.354, ValF1: 0.205\n",
      "Fold: 8, TrainF1: 0.354, ValF1: 0.281\n",
      "Fold: 9, TrainF1: 0.387, ValF1: 0.114\n",
      "Fold: 10, TrainF1: 0.388, ValF1: 0.288\n",
      "[[125  65  68  98]\n",
      " [  2   1   4   3]\n",
      " [ 21  10  18  37]\n",
      " [ 16  14  14  33]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        125   65   68   98  356\n",
      "1.0          2    1    4    3   10\n",
      "2.0         21   10   18   37   86\n",
      "3.0         16   14   14   33   77\n",
      "All        164   90  104  171  529\n",
      "TrainF1: 0.375, ValidationF1: 0.227\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_mutual_info_0_10 param= 1000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.253, ValF1: 0.152\n",
      "Fold: 2, TrainF1: 0.355, ValF1: 0.162\n",
      "Fold: 3, TrainF1: 0.361, ValF1: 0.187\n",
      "Fold: 4, TrainF1: 0.311, ValF1: 0.178\n",
      "Fold: 5, TrainF1: 0.255, ValF1: 0.266\n",
      "Fold: 6, TrainF1: 0.225, ValF1: 0.203\n",
      "Fold: 7, TrainF1: 0.241, ValF1: 0.149\n",
      "Fold: 8, TrainF1: 0.242, ValF1: 0.168\n",
      "Fold: 9, TrainF1: 0.288, ValF1: 0.346\n",
      "Fold: 10, TrainF1: 0.342, ValF1: 0.134\n",
      "[[ 94  46 128  88]\n",
      " [  3   1   4   2]\n",
      " [  9  18  34  25]\n",
      " [ 18   9  31  19]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         94   46  128   88  356\n",
      "1.0          3    1    4    2   10\n",
      "2.0          9   18   34   25   86\n",
      "3.0         18    9   31   19   77\n",
      "All        124   74  197  134  529\n",
      "TrainF1: 0.287, ValidationF1: 0.195\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] None param= 1000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.408, ValF1: 0.222\n",
      "Fold: 2, TrainF1: 0.415, ValF1: 0.158\n",
      "Fold: 3, TrainF1: 0.36, ValF1: 0.292\n",
      "Fold: 4, TrainF1: 0.374, ValF1: 0.221\n",
      "Fold: 5, TrainF1: 0.396, ValF1: 0.182\n",
      "Fold: 6, TrainF1: 0.393, ValF1: 0.133\n",
      "Fold: 7, TrainF1: 0.385, ValF1: 0.258\n",
      "Fold: 8, TrainF1: 0.358, ValF1: 0.159\n",
      "Fold: 9, TrainF1: 0.364, ValF1: 0.329\n",
      "Fold: 10, TrainF1: 0.388, ValF1: 0.187\n",
      "[[119  56  80 101]\n",
      " [  4   1   2   3]\n",
      " [ 24   7  18  37]\n",
      " [ 25   8  10  34]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        119   56   80  101  356\n",
      "1.0          4    1    2    3   10\n",
      "2.0         24    7   18   37   86\n",
      "3.0         25    8   10   34   77\n",
      "All        172   72  110  175  529\n",
      "TrainF1: 0.384, ValidationF1: 0.214\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] None param= 1000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.246, ValF1: 0.13\n",
      "Fold: 2, TrainF1: 0.248, ValF1: 0.22\n",
      "Fold: 3, TrainF1: 0.234, ValF1: 0.138\n",
      "Fold: 4, TrainF1: 0.209, ValF1: 0.134\n",
      "Fold: 5, TrainF1: 0.23, ValF1: 0.203\n",
      "Fold: 6, TrainF1: 0.214, ValF1: 0.187\n",
      "Fold: 7, TrainF1: 0.242, ValF1: 0.149\n",
      "Fold: 8, TrainF1: 0.24, ValF1: 0.227\n",
      "Fold: 9, TrainF1: 0.26, ValF1: 0.163\n",
      "Fold: 10, TrainF1: 0.256, ValF1: 0.216\n",
      "[[ 74  38 155  89]\n",
      " [  3   1   5   1]\n",
      " [  8  10  48  20]\n",
      " [ 15   4  42  16]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         74   38  155   89  356\n",
      "1.0          3    1    5    1   10\n",
      "2.0          8   10   48   20   86\n",
      "3.0         15    4   42   16   77\n",
      "All        100   53  250  126  529\n",
      "TrainF1: 0.238, ValidationF1: 0.177\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] ss_pca_0_95 param= 10000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, TrainF1: 1.0, ValF1: 0.193\n",
      "Fold: 2, TrainF1: 1.0, ValF1: 0.244\n",
      "Fold: 3, TrainF1: 1.0, ValF1: 0.279\n",
      "Fold: 4, TrainF1: 1.0, ValF1: 0.245\n",
      "Fold: 5, TrainF1: 1.0, ValF1: 0.27\n",
      "Fold: 6, TrainF1: 1.0, ValF1: 0.488\n",
      "Fold: 7, TrainF1: 1.0, ValF1: 0.198\n",
      "Fold: 8, TrainF1: 1.0, ValF1: 0.276\n",
      "Fold: 9, TrainF1: 1.0, ValF1: 0.164\n",
      "Fold: 10, TrainF1: 1.0, ValF1: 0.255\n",
      "[[297   0  28  31]\n",
      " [ 10   0   0   0]\n",
      " [ 58   0  15  13]\n",
      " [ 59   0  14   4]]\n",
      "Predicted  0.0  2.0  3.0  All\n",
      "True                         \n",
      "0.0        297   28   31  356\n",
      "1.0         10    0    0   10\n",
      "2.0         58   15   13   86\n",
      "3.0         59   14    4   77\n",
      "All        424   57   48  529\n",
      "TrainF1: 1.0, ValidationF1: 0.261\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] ss_pca_0_95 param= 10000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 1.0, ValF1: 0.425\n",
      "Fold: 2, TrainF1: 1.0, ValF1: 0.225\n",
      "Fold: 3, TrainF1: 1.0, ValF1: 0.218\n",
      "Fold: 4, TrainF1: 1.0, ValF1: 0.263\n",
      "Fold: 5, TrainF1: 1.0, ValF1: 0.248\n",
      "Fold: 6, TrainF1: 1.0, ValF1: 0.252\n",
      "Fold: 7, TrainF1: 1.0, ValF1: 0.29\n",
      "Fold: 8, TrainF1: 1.0, ValF1: 0.34\n",
      "Fold: 9, TrainF1: 1.0, ValF1: 0.272\n",
      "Fold: 10, TrainF1: 1.0, ValF1: 0.247\n",
      "[[299   1  27  29]\n",
      " [  9   0   1   0]\n",
      " [ 63   1  12  10]\n",
      " [ 59   0  11   7]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        299    1   27   29  356\n",
      "1.0          9    0    1    0   10\n",
      "2.0         63    1   12   10   86\n",
      "3.0         59    0   11    7   77\n",
      "All        430    2   51   46  529\n",
      "TrainF1: 1.0, ValidationF1: 0.278\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_f_reg_0_10 param= 10000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.538, ValF1: 0.443\n",
      "Fold: 2, TrainF1: 0.597, ValF1: 0.263\n",
      "Fold: 3, TrainF1: 0.549, ValF1: 0.297\n",
      "Fold: 4, TrainF1: 0.539, ValF1: 0.177\n",
      "Fold: 5, TrainF1: 0.547, ValF1: 0.22\n",
      "Fold: 6, TrainF1: 0.483, ValF1: 0.234\n",
      "Fold: 7, TrainF1: 0.571, ValF1: 0.21\n",
      "Fold: 8, TrainF1: 0.448, ValF1: 0.165\n",
      "Fold: 9, TrainF1: 0.524, ValF1: 0.216\n",
      "Fold: 10, TrainF1: 0.515, ValF1: 0.32\n",
      "[[154  33  79  90]\n",
      " [  4   1   3   2]\n",
      " [ 32   6  23  25]\n",
      " [ 28   2  17  30]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        154   33   79   90  356\n",
      "1.0          4    1    3    2   10\n",
      "2.0         32    6   23   25   86\n",
      "3.0         28    2   17   30   77\n",
      "All        218   42  122  147  529\n",
      "TrainF1: 0.531, ValidationF1: 0.255\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_f_reg_0_10 param= 10000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.24, ValF1: 0.136\n",
      "Fold: 2, TrainF1: 0.389, ValF1: 0.218\n",
      "Fold: 3, TrainF1: 0.251, ValF1: 0.168\n",
      "Fold: 4, TrainF1: 0.217, ValF1: 0.22\n",
      "Fold: 5, TrainF1: 0.269, ValF1: 0.133\n",
      "Fold: 6, TrainF1: 0.192, ValF1: 0.122\n",
      "Fold: 7, TrainF1: 0.245, ValF1: 0.211\n",
      "Fold: 8, TrainF1: 0.422, ValF1: 0.203\n",
      "Fold: 9, TrainF1: 0.228, ValF1: 0.164\n",
      "Fold: 10, TrainF1: 0.408, ValF1: 0.205\n",
      "[[ 89  64 115  88]\n",
      " [  5   1   3   1]\n",
      " [ 10  10  34  32]\n",
      " [ 14  10  29  24]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         89   64  115   88  356\n",
      "1.0          5    1    3    1   10\n",
      "2.0         10   10   34   32   86\n",
      "3.0         14   10   29   24   77\n",
      "All        118   85  181  145  529\n",
      "TrainF1: 0.286, ValidationF1: 0.178\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] k_best_mutual_info_0_10 param= 10000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.459, ValF1: 0.201\n",
      "Fold: 2, TrainF1: 0.477, ValF1: 0.264\n",
      "Fold: 3, TrainF1: 0.502, ValF1: 0.23\n",
      "Fold: 4, TrainF1: 0.478, ValF1: 0.222\n",
      "Fold: 5, TrainF1: 0.518, ValF1: 0.238\n",
      "Fold: 6, TrainF1: 0.453, ValF1: 0.325\n",
      "Fold: 7, TrainF1: 0.504, ValF1: 0.239\n",
      "Fold: 8, TrainF1: 0.507, ValF1: 0.238\n",
      "Fold: 9, TrainF1: 0.473, ValF1: 0.18\n",
      "Fold: 10, TrainF1: 0.517, ValF1: 0.22\n",
      "[[141  35  82  98]\n",
      " [  4   1   3   2]\n",
      " [ 25   6  23  32]\n",
      " [ 24   5  19  29]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        141   35   82   98  356\n",
      "1.0          4    1    3    2   10\n",
      "2.0         25    6   23   32   86\n",
      "3.0         24    5   19   29   77\n",
      "All        194   47  127  161  529\n",
      "TrainF1: 0.489, ValidationF1: 0.236\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] k_best_mutual_info_0_10 param= 10000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.428, ValF1: 0.2\n",
      "Fold: 2, TrainF1: 0.308, ValF1: 0.263\n",
      "Fold: 3, TrainF1: 0.333, ValF1: 0.185\n",
      "Fold: 4, TrainF1: 0.217, ValF1: 0.101\n",
      "Fold: 5, TrainF1: 0.199, ValF1: 0.124\n",
      "Fold: 6, TrainF1: 0.369, ValF1: 0.178\n",
      "Fold: 7, TrainF1: 0.435, ValF1: 0.352\n",
      "Fold: 8, TrainF1: 0.217, ValF1: 0.163\n",
      "Fold: 9, TrainF1: 0.359, ValF1: 0.128\n",
      "Fold: 10, TrainF1: 0.393, ValF1: 0.338\n",
      "[[116  49  73 118]\n",
      " [  1   2   3   4]\n",
      " [ 26   8  20  32]\n",
      " [ 16  12  20  29]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        116   49   73  118  356\n",
      "1.0          1    2    3    4   10\n",
      "2.0         26    8   20   32   86\n",
      "3.0         16   12   20   29   77\n",
      "All        159   71  116  183  529\n",
      "TrainF1: 0.326, ValidationF1: 0.203\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book [] None param= 10000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.563, ValF1: 0.317\n",
      "Fold: 2, TrainF1: 0.517, ValF1: 0.183\n",
      "Fold: 3, TrainF1: 0.526, ValF1: 0.224\n",
      "Fold: 4, TrainF1: 0.52, ValF1: 0.296\n",
      "Fold: 5, TrainF1: 0.532, ValF1: 0.228\n",
      "Fold: 6, TrainF1: 0.535, ValF1: 0.367\n",
      "Fold: 7, TrainF1: 0.505, ValF1: 0.172\n",
      "Fold: 8, TrainF1: 0.525, ValF1: 0.198\n",
      "Fold: 9, TrainF1: 0.488, ValF1: 0.201\n",
      "Fold: 10, TrainF1: 0.524, ValF1: 0.228\n",
      "[[154  25  74 103]\n",
      " [  6   0   4   0]\n",
      " [ 34   5  21  26]\n",
      " [ 29   2  17  29]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0        154   25   74  103  356\n",
      "1.0          6    0    4    0   10\n",
      "2.0         34    5   21   26   86\n",
      "3.0         29    2   17   29   77\n",
      "All        223   32  116  158  529\n",
      "TrainF1: 0.524, ValidationF1: 0.241\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "ger svc book_and_averaged_chunk [] None param= 10000\n",
      "Dropped 0 columns.\n",
      "0      1865\n",
      "1      1865\n",
      "2      1889\n",
      "3      1866\n",
      "4      1918\n",
      "       ... \n",
      "542    1913\n",
      "543    1895\n",
      "544    1835\n",
      "545    1760\n",
      "546    1882\n",
      "Name: book_name, Length: 547, dtype: int64\n",
      "Fold: 1, TrainF1: 0.219, ValF1: 0.159\n",
      "Fold: 2, TrainF1: 0.267, ValF1: 0.134\n",
      "Fold: 3, TrainF1: 0.256, ValF1: 0.178\n",
      "Fold: 4, TrainF1: 0.218, ValF1: 0.151\n",
      "Fold: 5, TrainF1: 0.232, ValF1: 0.083\n",
      "Fold: 6, TrainF1: 0.202, ValF1: 0.194\n",
      "Fold: 7, TrainF1: 0.253, ValF1: 0.135\n",
      "Fold: 8, TrainF1: 0.241, ValF1: 0.118\n",
      "Fold: 9, TrainF1: 0.186, ValF1: 0.175\n",
      "Fold: 10, TrainF1: 0.171, ValF1: 0.192\n",
      "[[ 62  70 151  73]\n",
      " [  3   1   5   1]\n",
      " [  8  16  50  12]\n",
      " [ 14  19  37   7]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         62   70  151   73  356\n",
      "1.0          3    1    5    1   10\n",
      "2.0          8   16   50   12   86\n",
      "3.0         14   19   37    7   77\n",
      "All         87  106  243   93  529\n",
      "TrainF1: 0.224, ValidationF1: 0.152\n",
      "\n",
      "---------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Run Multiclass Classification\n",
    "'''\n",
    "results = []\n",
    "param_dict = \"multiclass\" #\"full_cv\", \"language_specific\"\n",
    "for lang in [\"ger\"]: #, \"ger\"]:    \n",
    "    if param_dict == \"testing\":\n",
    "        param_dir = testing_params\n",
    "    elif param_dict == \"multiclass\":\n",
    "        param_dir = multiclass_params\n",
    "    elif param_dict == \"full_cv\":\n",
    "        param_dir = full_cv_params\n",
    "    elif param_dict == \"language_specific\":\n",
    "        if lang == \"eng\":\n",
    "            param_dir = eng_params\n",
    "        else: \n",
    "            param_dir = ger_params\n",
    "    \n",
    "    #Eng: 606 books, 14146 chunks, 13170 chunks of books published after 1759\n",
    "    book_df = pd.read_csv(f\"{extracted_features_dir}{lang}/book_df.csv\")\n",
    "    book_and_averaged_chunk_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/book_and_averaged_chunk_df.csv\")\n",
    "    #chunk_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/chunk_df.csv\")\n",
    "    #chunk_and_copied_book_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/chunk_and_copied_book_df.csv\")\n",
    "    \n",
    "    book_df = drop_default_columns(book_df, drop_default_columns_including)\n",
    "    book_and_averaged_chunk_df = drop_default_columns(book_and_averaged_chunk_df, drop_default_columns_including)\n",
    "    #chunk_df = drop_default_columns(chunk_df, drop_default_columns_including)\n",
    "    #chunk_and_copied_book_df = drop_default_columns(chunk_and_copied_book_df, drop_default_columns_including)\n",
    "    \n",
    "    for model in [] + [param_dir['model']]:\n",
    "        model_param = model_params[model]\n",
    "        for model_param in model_param:\n",
    "            for dimensionality_reduction in param_dir[\"dimensionality_reduction\"]:\n",
    "                for features in param_dir[\"features\"]:\n",
    "                    for drop_columns_including in [[]]:\n",
    "                        #try:\n",
    "                        print(lang, model, features, drop_columns_including, dimensionality_reduction, 'param=', model_param)\n",
    "                        experiment = MulticlassClassification(\n",
    "                            language=lang,\n",
    "                            features=features,\n",
    "                            drop_columns_including=drop_columns_including,\n",
    "                            dimensionality_reduction=dimensionality_reduction,\n",
    "                            model_param=model_param,\n",
    "                            model=model,\n",
    "                            verbose=True\n",
    "                        )\n",
    "                        mean_train_f1, mean_validation_f1 = experiment.run()\n",
    "                        results.append((lang, model, features, drop_columns_including, dimensionality_reduction, model_param, mean_train_f1, mean_validation_f1))\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=[\"lang\", \"model\", \"features\", \"drop_columns_including\", \n",
    "\"dimensionality_reduction\", \"model_param\", \"mean_train_f1\", \"mean_validation_f1\"])\n",
    "results_df.to_csv(results_dir + lang + '_' + param_dict + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1720f4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 378 texts without reviews, 197 different books with reviews, 6 of which have opposing reviews and are left out.\n",
    "# 378 + 197 - 6 = 569 texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "162f01d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Run Regression\n",
    "# '''\n",
    "# results = []\n",
    "# param_dict = \"testing\" #\"full_cv\", \"language_specific\"\n",
    "# for lang in [\"eng\"]: #, \"ger\"]:    \n",
    "#     if param_dict == \"testing\":\n",
    "#         param_dir = testing_params\n",
    "#     elif param_dict == \"multiclass\":\n",
    "#         param_dir = multiclass_params\n",
    "#     elif param_dict == \"full_cv\":\n",
    "#         param_dir = full_cv_params\n",
    "#     elif param_dict == \"language_specific\":\n",
    "#         if lang == \"eng\":\n",
    "#             param_dir = eng_params\n",
    "#         else: \n",
    "#             param_dir = ger_params\n",
    "    \n",
    "#     #Eng: 606 books, 14146 chunks, 13170 chunks of books published after 1759\n",
    "#     #book_df = pd.read_csv(f\"{extracted_features_dir}{lang}/book_df.csv\")\n",
    "#     book_and_averaged_chunk_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/book_and_averaged_chunk_df.csv\")\n",
    "#     #chunk_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/chunk_df.csv\")\n",
    "#     #chunk_and_copied_book_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/chunk_and_copied_book_df.csv\")\n",
    "    \n",
    "#     #book_df = drop_default_columns(book_df, drop_default_columns_including)\n",
    "#     book_and_averaged_chunk_df = drop_default_columns(book_and_averaged_chunk_df, drop_default_columns_including)\n",
    "#     #chunk_df = drop_default_columns(chunk_df, drop_default_columns_including)\n",
    "#     #chunk_and_copied_book_df = drop_default_columns(chunk_and_copied_book_df, drop_default_columns_including)\n",
    "    \n",
    "#     for model in [] + [param_dir['model']]:\n",
    "#         model_param = model_params[model]\n",
    "#         for model_param in model_param:\n",
    "#             for dimensionality_reduction in [param_dir[\"dimensionality_reduction\"]]:\n",
    "#                 for features in [param_dir[\"features\"]]:\n",
    "#                     for drop_columns_including in [[]]:\n",
    "#                                                         #try:\n",
    "#                         experiment = Regression(\n",
    "#                             language=lang,\n",
    "#                             features=features,\n",
    "#                             drop_columns_including=drop_columns_including,\n",
    "#                             dimensionality_reduction=dimensionality_reduction,\n",
    "#                             model_param=model_param,\n",
    "#                             model=model,\n",
    "#                             verbose=True\n",
    "#                         )\n",
    "#                         print(lang, model, features, drop_columns_including, dimensionality_reduction, 'param=', model_param)\n",
    "#                         mean_train_mse, mean_train_rmse, mean_train_mae, mean_train_r2, mean_train_corr, mean_validation_mse, mean_validation_rmse, mean_validation_mae, mean_validation_r2, mean_validation_corr, mean_p_value, datetime = experiment.run()\n",
    "#                         results.append((lang, model, features, drop_columns_including, dimensionality_reduction, model_param, mean_train_mse, mean_train_rmse, mean_train_mae, mean_train_r2, mean_train_corr, mean_validation_mse, mean_validation_rmse, mean_validation_mae, mean_validation_r2, mean_validation_corr, mean_p_value))\n",
    "#                         #except Exception as e:\n",
    "# #                             print(f\"Error in {lang}, {model}, {features}, {drop_columns_including}, {dimensionality_reduction}\")\n",
    "# #                             print(e)\n",
    "# results_df = pd.DataFrame(results, columns=[\"lang\", \"model\", \"features\", \"drop_columns_including\", \n",
    "# \"dimensionality_reduction\", \"model_param\", \"mean_train_mse\", \"mean_train_rmse\", \n",
    "# \"mean_train_mae\", \"mean_train_r2\", \"mean_train_corr\", \"mean_validation_mse\", \"mean_validation_rmse\",\n",
    "# \"mean_validation_mae\", \"mean_validation_r2\", \"mean_validation_corr\", \"mean_p_value\"])\n",
    "# results_df.to_csv(results_dir + lang + '_' + regression_' + param_dict + datetime + \".csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
