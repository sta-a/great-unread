{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15df4db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsentiment file names for eng/ger\\nMerge labels and features depending on how labels are aggregated if there are multiple scores for a work.\\ndrop_column reset index???\\nchunk based features?\\ncomplexity features\\ntake out doc2vec_chunk_embedding from default drop columns\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "sentiment file names for eng/ger\n",
    "Merge labels and features depending on how labels are aggregated if there are multiple scores for a work.\n",
    "drop_column reset index???\n",
    "chunk based features?\n",
    "complexity features\n",
    "take out doc2vec_chunk_embedding from default drop columns\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c12bfc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../src/\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "extracted_features_dir = \"../data/extracted_features/\"\n",
    "results_dir = \"../data/results/\"\n",
    "sentiment_dir = \"../data/evaluationscore/\"\n",
    "canonization_labels_dir = \"/home/annina/scripts/great_unread_nlp/data/labels/\"\n",
    "lang = \"eng\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2696499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, f1_score, confusion_matrix\n",
    "from xgboost import XGBRegressor\n",
    "from copy import deepcopy\n",
    "from scipy.stats import pearsonr\n",
    "from utils import read_sentiment_scores, read_library_scores\n",
    "from math import sqrt\n",
    "get_ipython().run_line_magic(\"matplotlib\", \"inline\") # %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import random\n",
    "random.seed(9)\n",
    "\n",
    "labels = read_sentiment_scores(sentiment_dir, canonization_labels_dir, lang)\n",
    "library_scores = read_library_scores(sentiment_dir, canonization_labels_dir, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4594ed42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_name</th>\n",
       "      <th>y</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anonymous_Anonymous_The-Adventures-of-Anthony-...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austen_Jane_Pride-and-Prejudice_1813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austen_Jane_Sense-and-Sensibility_1811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barrie_J-M_Auld-Licht-Idylls_1888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barrie_J-M_Sentimental-Tommy_1896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Wells_H-G_Ann-Veronica_1909</td>\n",
       "      <td>-0.019978</td>\n",
       "      <td>not_classified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Wells_H-G_The-First-Men-in-the-Moon_1901</td>\n",
       "      <td>-0.040821</td>\n",
       "      <td>not_classified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Wells_H-G_The-Island-of-Dr-Moreau_1896</td>\n",
       "      <td>-0.044745</td>\n",
       "      <td>not_classified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Wilde_Oscar_The-Picture-of-Dorian-Gray_1890</td>\n",
       "      <td>0.007171</td>\n",
       "      <td>not_classified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Wollstonecraft_Mary_Mary_1788</td>\n",
       "      <td>-0.002009</td>\n",
       "      <td>not_classified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             book_name         y  \\\n",
       "0    Anonymous_Anonymous_The-Adventures-of-Anthony-...  0.000000   \n",
       "1                 Austen_Jane_Pride-and-Prejudice_1813  0.000000   \n",
       "2               Austen_Jane_Sense-and-Sensibility_1811  0.000000   \n",
       "3                    Barrie_J-M_Auld-Licht-Idylls_1888  0.000000   \n",
       "4                    Barrie_J-M_Sentimental-Tommy_1896  0.000000   \n",
       "..                                                 ...       ...   \n",
       "249                        Wells_H-G_Ann-Veronica_1909 -0.019978   \n",
       "250           Wells_H-G_The-First-Men-in-the-Moon_1901 -0.040821   \n",
       "251             Wells_H-G_The-Island-of-Dr-Moreau_1896 -0.044745   \n",
       "252        Wilde_Oscar_The-Picture-of-Dorian-Gray_1890  0.007171   \n",
       "253                      Wollstonecraft_Mary_Mary_1788 -0.002009   \n",
       "\n",
       "                  c  \n",
       "0          positive  \n",
       "1          positive  \n",
       "2          positive  \n",
       "3          positive  \n",
       "4          positive  \n",
       "..              ...  \n",
       "249  not_classified  \n",
       "250  not_classified  \n",
       "251  not_classified  \n",
       "252  not_classified  \n",
       "253  not_classified  \n",
       "\n",
       "[254 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels \n",
    "#len(pd.unique(labels[\"book_name\"])) #197\n",
    "\n",
    "# 254 labels, 197 different book_names -> 57 second/third... reviews\n",
    "# 36 book_names with more than 1 label, these 36 book_names have 93 labels\n",
    "# 93 = 36 first reviews + 57 second/third... reviews\n",
    "# 6 texts with opposing reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "933bfe04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels[\"y\"].plot.hist(grid=True, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b1785d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression(object):\n",
    "    def __init__(self, language, features, drop_columns_including, dimensionality_reduction, model_param, model, verbose):\n",
    "        assert features in [\"book\", \"chunk\", \"book_and_averaged_chunk\", \"chunk_and_copied_book\"]\n",
    "        assert isinstance(drop_columns_including, list)\n",
    "        for i in drop_columns_including:\n",
    "            assert isinstance(i, str)\n",
    "        assert (dimensionality_reduction in [\"k_best_f_reg_0_10\", \"k_best_mutual_info_0_10\", \"ss_pca_0_95\"]) or (dimensionality_reduction is None)\n",
    "        self._check_class_specific_assertions()\n",
    "        \n",
    "        self.language = language\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.labels = self._prepare_labels()\n",
    "        self.drop_columns_including = drop_columns_including\n",
    "        self.dimensionality_reduction = dimensionality_reduction\n",
    "        self.model_param = model_param\n",
    "        self.model = model\n",
    "        self.verbose = verbose\n",
    "        self.datetime = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "        if self.features == \"book\":\n",
    "            self.df = deepcopy(book_df)\n",
    "        elif self.features == \"chunk\":\n",
    "            self.df = deepcopy(chunk_df)\n",
    "        elif self.features == \"chunk_and_copied_book\":\n",
    "            self.df = deepcopy(chunk_and_copied_book_df)\n",
    "        elif self.features == \"book_and_averaged_chunk\":\n",
    "            self.df = deepcopy(book_and_averaged_chunk_df)\n",
    "\n",
    "        columns_before_drop = set(self.df.columns)\n",
    "        if self.drop_columns_including:\n",
    "            self.df = self.df[[column for column in self.df.columns if not self._drop_column(column)]].reset_index(drop=True)\n",
    "        columns_after_drop = set(self.df.columns)\n",
    "        if self.verbose:\n",
    "            print(f\"Dropped {len(columns_before_drop - columns_after_drop)} columns.\")\n",
    "            \n",
    "    def _check_class_specific_assertions(self):\n",
    "        assert model in [\"xgboost\", \"svr\", \"lasso\"]\n",
    "    \n",
    "    def _prepare_labels(self):\n",
    "        return self.labels.drop(columns=\"c\")\n",
    "\n",
    "    def _drop_column(self, column):\n",
    "        for string in self.drop_columns_including:\n",
    "            if string in column:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def _custom_pca(self, train_X):\n",
    "        for i in range(5, train_X.shape[1], int((train_X.shape[1] - 5) / 10)):\n",
    "            pca = PCA(n_components=i)\n",
    "            new_train_X = pca.fit_transform(train_X)\n",
    "            if pca.explained_variance_ratio_.sum() >= 0.95:\n",
    "                break\n",
    "        return new_train_X, pca\n",
    "\n",
    "    def _select_features(self, train_X, train_y, validation_X):\n",
    "        if self.dimensionality_reduction == \"ss_pca_0_95\":\n",
    "            ss = StandardScaler()\n",
    "            train_X = ss.fit_transform(train_X)\n",
    "            validation_X = ss.transform(validation_X)\n",
    "            train_X, pca = self._custom_pca(train_X)\n",
    "            validation_X = pca.transform(validation_X)\n",
    "        elif self.dimensionality_reduction == \"k_best_f_reg_0_10\":\n",
    "            k_best = SelectKBest(f_regression, k=np.minimum(int(0.10 * train_X.shape[0]), train_X.shape[1]))\n",
    "            train_X = k_best.fit_transform(train_X, train_y)\n",
    "            validation_X = k_best.transform(validation_X)\n",
    "        elif self.dimensionality_reduction == \"k_best_mutual_info_0_10\":\n",
    "            k_best = SelectKBest(mutual_info_regression, k=np.minimum(int(0.10 * train_X.shape[0]), train_X.shape[1]))\n",
    "            train_X = k_best.fit_transform(train_X, train_y)\n",
    "            validation_X = k_best.transform(validation_X)\n",
    "        elif self.dimensionality_reduction is None:\n",
    "            pass\n",
    "        return train_X, validation_X\n",
    "    \n",
    "    def _impute(self, train_X, validation_X):\n",
    "        imputer = KNNImputer()\n",
    "        train_X = imputer.fit_transform(train_X)\n",
    "        validation_X = imputer.transform(validation_X)\n",
    "        return train_X, validation_X\n",
    "    \n",
    "    def _get_model(self, model_param):\n",
    "        # if any of these performs better than others, we can try to tune the hyperparameters\n",
    "        # but I think for now it\"s more important to see which approach performs better\n",
    "        # chunk based or doc based\n",
    "        # use dimensionality reduction or not...\n",
    "        if self.model == \"xgboost\": #1,0.25,2\n",
    "            return XGBRegressor(n_estimators=1000, max_depth=model_param, learning_rate=0.01, colsample_bytree=0.33, min_child_weight=6) #max_depth=4\n",
    "        elif self.model == \"svr\":\n",
    "            return SVR(C=model_param)\n",
    "        elif self.model == \"lasso\":\n",
    "            return Lasso(alpha=model_param)\n",
    "        elif self.model == \"svc\":\n",
    "            return SVC(C=model_param)\n",
    "        \n",
    "    def _split_booknames(self, df, nr_splits):\n",
    "        \"\"\"\n",
    "        Distribute book names over splits.\n",
    "        All works of an author are in the same split.\n",
    "        \"\"\"\n",
    "        book_names = df[\"book_name\"].unique()\n",
    "        authors = []\n",
    "        booknames_authors_mapping = {}\n",
    "\n",
    "        #Get authors\n",
    "        for book_name in book_names:\n",
    "            author = \"_\".join(book_name.split(\"_\")[:2])\n",
    "            authors.append(author)\n",
    "            if author in booknames_authors_mapping:\n",
    "                booknames_authors_mapping[author].append(book_name)\n",
    "            else:\n",
    "                booknames_authors_mapping[author] = []\n",
    "                booknames_authors_mapping[author].append(book_name)\n",
    "        #Distribute authors over splits so that each split has approximately the same number of books\n",
    "        works_per_author = Counter(authors)\n",
    "        goal_sum = round(len(book_names)/nr_splits)\n",
    "        tolerance = 0.03\n",
    "        lower_threshold = goal_sum - round(tolerance*goal_sum)\n",
    "        upper_threshold = goal_sum + round(tolerance*goal_sum)\n",
    "        author_splits = []\n",
    "        popped_dict = {}\n",
    "\n",
    "        for i in range (0, nr_splits-1):\n",
    "            works_in_split = 0\n",
    "            split = []\n",
    "            curr_author_workcount = 0\n",
    "\n",
    "            # take values from popped dict first\n",
    "            if bool(popped_dict):  \n",
    "                popped = []\n",
    "                for curr_author, curr_author_workcount in popped_dict.items():\n",
    "                    # leave item in popped dict if value is too big\n",
    "                    if works_in_split + curr_author_workcount > upper_threshold:\n",
    "                        continue\n",
    "                    else:\n",
    "                        popped.append(curr_author)\n",
    "                        split.append(curr_author)\n",
    "                        works_in_split += curr_author_workcount\n",
    "                        if works_in_split >= lower_threshold:\n",
    "                            break\n",
    "                for current_author in popped:\n",
    "                    del popped_dict[current_author]\n",
    "            while works_in_split < upper_threshold:\n",
    "                if bool(works_per_author):\n",
    "                    curr_author = random.choice(list(works_per_author.keys()))\n",
    "                    curr_author_workcount = works_per_author.pop(curr_author)\n",
    "                    # Put values into separate dict if too big\n",
    "                    if works_in_split + curr_author_workcount > upper_threshold:\n",
    "                        popped_dict[curr_author] = curr_author_workcount\n",
    "                    else:\n",
    "                        split.append(curr_author)\n",
    "                        works_in_split += curr_author_workcount\n",
    "                        if works_in_split >= lower_threshold:\n",
    "                            break\n",
    "                else:\n",
    "                    #ignore upper threshold\n",
    "                    popped = []\n",
    "                    for curr_author, curr_author_workcount in popped_dict.items():\n",
    "                        popped.append(curr_author)\n",
    "                        split.append(curr_author)\n",
    "                        works_in_split += curr_author_workcount\n",
    "                        if works_in_split >= lower_threshold:\n",
    "                            break\n",
    "                    for current_author in popped:\n",
    "                        del popped_dict[current_author]\n",
    "\n",
    "            author_splits.append(split)\n",
    "        #Create last split directly from remaining dict\n",
    "        works_in_last_split = sum(works_per_author.values()) + sum(popped_dict.values())\n",
    "        split = list(works_per_author.keys()) + list(popped_dict.keys())\n",
    "        author_splits.append(split)\n",
    "\n",
    "        #Map author splits to book names\n",
    "        book_splits = []\n",
    "        for author_split in author_splits:\n",
    "            book_split = []\n",
    "            for author in author_split:\n",
    "                book_split.extend(booknames_authors_mapping[author])\n",
    "            book_splits.append(book_split)\n",
    "        return book_splits\n",
    "    \n",
    "    def _combine_df_labels(self, df):\n",
    "        #Average of sentiscores per book\n",
    "        agg_labels = self.labels.groupby(by=\"book_name\", as_index=False).mean()\n",
    "        df = df.merge(right=agg_labels, on=\"book_name\", how=\"inner\", validate=\"many_to_one\")\n",
    "        return df\n",
    "    \n",
    "    def run(self):\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "\n",
    "        train_mses = []\n",
    "        train_maes = []\n",
    "        train_r2s = []\n",
    "        train_corrs = []\n",
    "        \n",
    "        validation_mses = []\n",
    "        validation_maes = []\n",
    "        validation_r2s = []\n",
    "        validation_corrs = []\n",
    "        validation_corr_pvalues = []\n",
    "\n",
    "        df = self.df\n",
    "        df = self._combine_df_labels(df)\n",
    "        book_names_split = self._split_booknames(df, 5)\n",
    "        all_validation_books = []\n",
    "\n",
    "        for index, split in enumerate(book_names_split):\n",
    "            train_df = df[~df[\"book_name\"].isin(split)]\n",
    "            validation_df = df[df[\"book_name\"].isin(split)]\n",
    "            \n",
    "            train_X = train_df.drop(columns=[\"y\", \"book_name\"]).values\n",
    "            train_y = train_df[\"y\"].values.ravel()\n",
    "            validation_X = validation_df.drop(columns=[\"y\", \"book_name\"]).values\n",
    "            validation_y = validation_df[\"y\"].values.ravel()\n",
    "            train_X, validation_X = self._impute(train_X, validation_X)\n",
    "            #if self.verbose:\n",
    "            #    print(f\"train_X.shape before {self.dimensionality_reduction}: {train_X.shape}, validation_X.shape before {self.dimensionality_reduction}: {validation_X.shape}\")\n",
    "            train_X, validation_X = self._select_features(train_X, train_y, validation_X)\n",
    "            #if self.verbose:\n",
    "            #    print(f\"train_X.shape after {self.dimensionality_reduction}: {train_X.shape}, validation_X.shape after {self.dimensionality_reduction}: {validation_X.shape}\")\n",
    "            model = self._get_model(self.model_param)\n",
    "            model.fit(train_X, train_y)\n",
    "            \n",
    "            train_books = deepcopy(train_df[[\"book_name\", \"y\"]])\n",
    "            train_books[\"yhat\"] = model.predict(train_X)\n",
    "            validation_books = deepcopy(validation_df[[\"book_name\", \"y\"]])\n",
    "            validation_books[\"yhat\"] = model.predict(validation_X)\n",
    "            \n",
    "            train_books = train_books.groupby(\"book_name\").mean()\n",
    "            validation_books = validation_books.groupby(\"book_name\").mean()\n",
    "            all_validation_books.append(validation_books.reset_index())\n",
    "            \n",
    "            train_y = train_books[\"y\"].tolist()\n",
    "            train_yhat = train_books[\"yhat\"].tolist()\n",
    "            validation_y = validation_books[\"y\"].tolist()\n",
    "            validation_yhat = validation_books[\"yhat\"].tolist()\n",
    "            \n",
    "            all_labels.extend(validation_y)\n",
    "            all_predictions.extend(validation_yhat)\n",
    "            \n",
    "            train_mse = mean_squared_error(train_y, train_yhat)\n",
    "            train_mae = mean_absolute_error(train_y, train_yhat)\n",
    "            train_r2 = r2_score(train_y, train_yhat)\n",
    "            train_corr = pearsonr(train_y, train_yhat)[0]\n",
    "            \n",
    "            validation_mse = mean_squared_error(validation_y, validation_yhat)\n",
    "            validation_mae = mean_absolute_error(validation_y, validation_yhat)\n",
    "            validation_r2 = r2_score(validation_y, validation_yhat)\n",
    "            validation_corr = pearsonr(validation_y, validation_yhat)[0]\n",
    "            p_value = pearsonr(validation_y, validation_yhat)[1]\n",
    "            \n",
    "            train_mses.append(train_mse)\n",
    "            train_maes.append(train_mae)\n",
    "            train_r2s.append(train_r2)\n",
    "            train_corrs.append(train_corr)\n",
    "            \n",
    "            validation_mses.append(validation_mse)\n",
    "            validation_maes.append(validation_mae)\n",
    "            validation_r2s.append(validation_r2)\n",
    "            validation_corrs.append(validation_corr)\n",
    "            validation_corr_pvalues.append(p_value)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"Fold: {index+1}, TrainMSE: {np.round(train_mse, 3)}, TrainMAE: {np.round(train_mae, 3)}, ValMSE: {np.round(validation_mse, 3)}, ValMAE: {np.round(validation_mae, 3)}, ValR2: {np.round(validation_r2, 3)}, ValCorr: {np.round(validation_corr, 3)}\")\n",
    "        all_labels = np.array(all_labels)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        \n",
    "        # Save y and y_pred for examples\n",
    "        pd.concat(all_validation_books).to_csv(results_dir + \"/y-yhat-\" + self.language + \"-\" + self.datetime + \".csv\", index=False)\n",
    "        \n",
    "        mean_train_mse = np.mean(train_mses)\n",
    "        mean_train_rmse = np.mean([sqrt(x) for x in train_mses])\n",
    "        mean_train_mae = np.mean(train_maes)\n",
    "        mean_train_r2 = np.mean(train_r2s)\n",
    "        mean_train_corr = np.mean(train_corrs)\n",
    "        \n",
    "        mean_validation_mse = np.mean(validation_mses)\n",
    "        mean_validation_rmse = np.mean([sqrt(x) for x in validation_mses])\n",
    "        mean_validation_mae = np.mean(validation_maes)\n",
    "        mean_validation_r2 = np.mean(validation_r2s)\n",
    "        mean_validation_corr = np.mean(validation_corrs)\n",
    "        mean_p_value = self._get_pvalue(validation_corr_pvalues)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\"\"TrainMSE: {np.round(mean_train_mse, 3)}, TrainRMSE: {np.round(mean_train_rmse, 3)}, TrainMAE: {np.round(mean_train_mae, 3)}, TrainR2: {np.round(mean_train_r2, 3)}, TrainCorr: {np.round(mean_train_corr, 3)}, ValMSE: {np.round(mean_validation_mse, 3)}, ValRMSE: {np.round(mean_validation_rmse, 3)}, ValMAE: {np.round(mean_validation_mae, 3)}, ValR2: {np.round(mean_validation_r2, 3)}, ValCorr: {np.round(mean_validation_corr, 3)}, ValCorrPValue: {np.round(mean_p_value, 3)}\"\"\")\n",
    "            print(\"\\n---------------------------------------------------\\n\")\n",
    "            plt.figure(figsize=(4,4))\n",
    "            plt.xticks(fontsize=15)\n",
    "            plt.yticks(fontsize=15)\n",
    "            plt.xlim([0,1])\n",
    "            plt.ylim([0,1])\n",
    "\n",
    "            plt.scatter(all_labels, all_predictions, s=6)\n",
    "            plt.xlabel(\"Canonization Scores\", fontsize=20)\n",
    "            plt.ylabel(\"Predicted Scores\", fontsize=20)\n",
    "            plt.savefig(results_dir + lang + \"-\" + self.model + \"-\" + str(self.dimensionality_reduction) \n",
    "            + \"-\" + self.features + \"-\" + \"-\" + \"param\" + str(self.model_param) + \"-\" + self.datetime + \".png\", \n",
    "            dpi=400, bbox_inches=\"tight\")    \n",
    "    \n",
    "            plt.show();\n",
    "        return mean_train_mse, mean_train_rmse, mean_train_mae, mean_train_r2, mean_train_corr, mean_validation_mse, mean_validation_rmse, mean_validation_mae, mean_validation_r2, mean_validation_corr, mean_p_value, self.datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340d71a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Classification into reviewed/not reviewed\n",
    "'''\n",
    "\n",
    "class Classification(Regression):\n",
    "    def __init__(self, language, features, drop_columns_including, dimensionality_reduction, model_param, model, verbose):\n",
    "        super().__init__(language, features, drop_columns_including, dimensionality_reduction, model_param, model, verbose)\n",
    "\n",
    "    def _check_class_specific_assertions(self):\n",
    "        assert model in [\"svc\"]\n",
    "        \n",
    "    def _prepare_labels(self):\n",
    "        labels = self.labels.drop(columns=\"y\").rename(columns={\"c\":\"y\"})\n",
    "        labels = labels.replace(to_replace={\"positive\": 3, \"not_classified\": 2, \"negative\": 1})\n",
    "        labels = labels.drop_duplicates(subset=\"book_name\")\n",
    "        return labels\n",
    "        \n",
    "    def _combine_df_labels(self, df):\n",
    "        #Reviews zum englischen Korpus beginnnen mit 1759 und decken alles bis 1914 ab\n",
    "        agg_labels = self.labels[[\"book_name\"]].drop_duplicates()\n",
    "        agg_labels[\"y\"] = 1\n",
    "        df = df.merge(right=agg_labels, on=\"book_name\", how=\"left\", validate=\"many_to_one\")\n",
    "        df[\"y\"] = df[\"y\"].fillna(value=0)\n",
    "        #Select books written after 1759 (year of first review)\n",
    "        year = df[\"book_name\"].str.split('_').str[-1].astype('int64')\n",
    "        df = df.loc[year>=1759]\n",
    "        return df\n",
    "    \n",
    "    def _get_sample_weights(self, df):\n",
    "        # Weight \n",
    "        chunks_per_book = df[\"book_name\"].value_counts(sort=False).rename('chunks_per_book')\n",
    "        chunks_per_book = chunks_per_book.reset_index().rename(columns={\"index\":'book_name'})\n",
    "        chunks_per_book[\"chunks_per_book\"] = 1/chunks_per_book[\"chunks_per_book\"]\n",
    "        df = df.merge(right=chunks_per_book, how=\"left\", on=\"book_name\")\n",
    "        print(df)\n",
    "        sample_weights = df[\"chunks_per_book\"].tolist()\n",
    "        return sample_weights\n",
    "    \n",
    "    def _aggregate_chunk_predictions(self, df):\n",
    "        g = df.groupby(\"book_name\") \n",
    "        \n",
    "        # Majority vote\n",
    "        # If one value is more common, assign it to every chunk\n",
    "        # Therefore, accuracy is either 0 or 1\n",
    "        # If both values are equally likely, leave them unchanged, and accuracy is 0.5\n",
    "        def _get_mode_accuracy(group):\n",
    "            counts = group[\"yhat\"].value_counts()\n",
    "            if len(counts) == 1:\n",
    "                mode_acc = counts.index[0]\n",
    "            else:\n",
    "                mode_acc = 0.5\n",
    "            return mode_acc\n",
    "        mode_accs = g.apply(_get_mode_accuracy).rename(\"mode_acc\").reset_index() \n",
    "        mode_acc = mode_accs[\"mode_acc\"].mean()\n",
    "        \n",
    "        # Average accuracy within book\n",
    "        book_acc = g.apply(lambda group: accuracy_score(group[\"y\"], group[\"yhat\"])).mean()\n",
    "        #Accuracy when each chunk is treated as single document\n",
    "        chunk_acc = accuracy_score(df[\"y\"], df[\"yhat\"])#, sample_weight = self._get_sample_weights(df))\n",
    "        return {\"mode_acc\": mode_acc, \"book_acc\": book_acc, \"chunk_acc\": chunk_acc}\n",
    "        \n",
    "    def run(self):\n",
    "        train_accs = []\n",
    "        validation_accs = []\n",
    "\n",
    "        df = self.df\n",
    "        df = self._combine_df_labels(df)\n",
    "        book_names_split = self._split_booknames(df, 5)\n",
    "        all_validation_books = []\n",
    "\n",
    "        for index, split in enumerate(book_names_split):\n",
    "            train_df = df[~df[\"book_name\"].isin(split)]\n",
    "            validation_df = df[df[\"book_name\"].isin(split)]\n",
    "            \n",
    "            train_X = train_df.drop(columns=[\"y\", \"book_name\"]).values\n",
    "            train_y = train_df[\"y\"].values.ravel()\n",
    "            validation_X = validation_df.drop(columns=[\"y\", \"book_name\"]).values\n",
    "            validation_y = validation_df[\"y\"].values.ravel()\n",
    "            train_X, validation_X = self._impute(train_X, validation_X)\n",
    "            #if self.verbose:\n",
    "            #    print(f\"train_X.shape before {self.dimensionality_reduction}: {train_X.shape}, validation_X.shape before {self.dimensionality_reduction}: {validation_X.shape}\")\n",
    "            train_X, validation_X = self._select_features(train_X, train_y, validation_X)\n",
    "            #if self.verbose:\n",
    "            #    print(f\"train_X.shape after {self.dimensionality_reduction}: {train_X.shape}, validation_X.shape after {self.dimensionality_reduction}: {validation_X.shape}\")\n",
    "            model = self._get_model(self.model_param)\n",
    "            model.fit(train_X, train_y)\n",
    "            \n",
    "            train_books = deepcopy(train_df[[\"book_name\", \"y\"]])\n",
    "            train_books[\"yhat\"] = model.predict(train_X)\n",
    "            train_acc = self._aggregate_chunk_predictions(train_books)\n",
    "            validation_books = deepcopy(validation_df[[\"book_name\", \"y\"]])\n",
    "            validation_books[\"yhat\"] = model.predict(validation_X)\n",
    "            validation_acc = self._aggregate_chunk_predictions(validation_books)\n",
    "            \n",
    "            all_validation_books.append(validation_books)\n",
    "            \n",
    "            train_accs.append(train_acc)\n",
    "            validation_accs.append(validation_acc)\n",
    "            if self.verbose:\n",
    "                print(f\"Fold: {index+1}, TrainAcc: {np.round(train_acc, 3)}, ValAcc: {np.round(validation_acc, 3)}\")\n",
    "        \n",
    "        # Save y and y_pred for examples\n",
    "        all_validation_books = pd.concat(all_validation_books)\n",
    "        all_validation_books.to_csv(results_dir + \"/valiationbooks-class-\" + self.language + \"-\" + self.datetime + \".csv\", index=False)\n",
    "        \n",
    "        print(confusion_matrix(all_validation_books[\"y\"], all_validation_books[\"yhat\"]))\n",
    "        print(pd.crosstab(all_validation_books[\"y\"], all_validation_books[\"yhat\"], rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "                \n",
    "        train_accs = pd.DataFrame(train_accs)\n",
    "        validation_accs = pd.DataFrame(validation_accs)\n",
    "        \n",
    "        mean_train_mode_acc = train_accs[\"mode_acc\"].mean()\n",
    "        mean_train_book_acc = train_accs[\"book_acc\"].mean()\n",
    "        mean_train_chunk_acc = train_accs[\"chunk_acc\"].mean()\n",
    "        mean_validation_mode_acc = validation_accs[\"mode_acc\"].mean()\n",
    "        mean_validation_book_acc = validation_accs[\"book_acc\"].mean()\n",
    "        mean_validation_chunk_acc = validation_accs[\"chunk_acc\"].mean()\n",
    "        print(mean_train_mode_acc, mean_train_book_acc, mean_train_chunk_acc)\n",
    "        print(mean_validation_mode_acc, mean_validation_book_acc, mean_validation_chunk_acc)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\"\"TrainAcc: {np.round(mean_train_acc, 3)}, ValidationAcc: {np.round(mean_validation_acc, 3)}\"\"\")\n",
    "            print(\"\\n---------------------------------------------------\\n\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9de317b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Classification into in library/not in library\n",
    "'''\n",
    "\n",
    "class LibraryClassification(Classification):\n",
    "    def _prepare_labels(self):\n",
    "        return self.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0170865",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Classification into not reviewed/negative/not classified/positive\n",
    "'''\n",
    "\n",
    "class MulticlassClassification(Regression):\n",
    "    def __init__(self, language, features, drop_columns_including, dimensionality_reduction, model_param, model, verbose):\n",
    "        super().__init__(language, features, drop_columns_including, dimensionality_reduction, model_param, model, verbose)\n",
    "\n",
    "    def _check_class_specific_assertions(self):\n",
    "        assert model in [\"svc\"]\n",
    "        \n",
    "    def _prepare_labels(self):\n",
    "        labels = self.labels.drop(columns=\"y\").rename(columns={\"c\":\"y\"})\n",
    "        labels = labels.replace(to_replace={\"positive\": 3, \"not_classified\": 2, \"negative\": 1})\n",
    "        \n",
    "        #Correct labels if book has opposed labels\n",
    "        single_review = labels.groupby(\"book_name\").filter(lambda x: len(x)==1) # 161 single review, 93 several\n",
    "        multiple_reviews = labels.groupby(\"book_name\").filter(lambda x: len(x)>1 and not(1 in x.values and 3 in x.values))\n",
    "        #opposed_reviews = labels.groupby(\"book_name\").filter(lambda x: len(x)>1 and (1 in x.values and 3 in x.values))\n",
    "              \n",
    "        def _correct_opposed_labels(group):\n",
    "            count = group[\"y\"].value_counts().reset_index().rename(columns={'index': 'y', \"y\": \"count\"})\n",
    "            #take label with the highest count, take more extreme label if counts are equal\n",
    "            if count.shape[0]>1:\n",
    "                if count.iloc[0,1] == count.iloc[1,1]:\n",
    "                    grouplabel = count[\"y\"].max()\n",
    "                else:\n",
    "                    grouplabel = count.iloc[0,0]\n",
    "                group[\"y\"] = grouplabel\n",
    "            return group\n",
    "        multiple_reviews = multiple_reviews.groupby(\"book_name\").apply(_correct_opposed_labels)\n",
    "        multiple_reviews = multiple_reviews.drop_duplicates(subset=\"book_name\")\n",
    "        labels = pd.concat([single_review, multiple_reviews])\n",
    "        return labels\n",
    "        \n",
    "    def _combine_df_labels(self, df):\n",
    "        #Reviews zum englischen Korpus beginnnen mit 1759 und decken alles bis 1914 ab\n",
    "        df = df.merge(right=self.labels, on=\"book_name\", how=\"left\", validate=\"many_to_one\")\n",
    "        print('labels value count', df[\"y\"].value_counts())\n",
    "        df[\"y\"] = df[\"y\"].fillna(value=0)#(value=\"not_reviewed\")\n",
    "        print('labels value count', df[\"y\"].value_counts())\n",
    "        #Select books written after 1759 (year of first review)\n",
    "        year = df[\"book_name\"].str.split('_').str[-1].astype('int64')\n",
    "        df = df.loc[year>=1759]\n",
    "        print('labels value count', df[\"y\"].value_counts())\n",
    "        return df\n",
    "    \n",
    "    def _get_sample_weights(self, df):\n",
    "        # Weight \n",
    "        chunks_per_book = df[\"book_name\"].value_counts(sort=False).rename('chunks_per_book')\n",
    "        chunks_per_book = chunks_per_book.reset_index().rename(columns={\"index\":'book_name'})\n",
    "        chunks_per_book[\"chunks_per_book\"] = 1/chunks_per_book[\"chunks_per_book\"]\n",
    "        df = df.merge(right=chunks_per_book, how=\"left\", on=\"book_name\")\n",
    "        sample_weights = df[\"chunks_per_book\"].tolist()\n",
    "        return sample_weights\n",
    "    \n",
    "    def _aggregate_chunk_predictions(self, df):\n",
    "        g = df.groupby(\"book_name\") \n",
    "        \n",
    "        # If one value is more common, assign it to every chunk\n",
    "        # Therefore, accuracy is either 0 or 1\n",
    "        # If both values are equally likely, leave them unchanged, and accuracy is 0.5\n",
    "        def _get_mode_accuracy(group):\n",
    "            counts = group[\"yhat\"].value_counts()\n",
    "            if len(counts) == 1:\n",
    "                mode_acc = counts.index[0]\n",
    "            else:\n",
    "                mode_acc = 0.5\n",
    "            return mode_acc\n",
    "        mode_accs = g.apply(_get_mode_accuracy).rename(\"mode_acc\").reset_index() \n",
    "        mode_acc = mode_accs[\"mode_acc\"].mean()\n",
    "        \n",
    "        # Average accuracy within book\n",
    "        book_acc = g.apply(lambda group: f1_score(group[\"y\"], group[\"yhat\"], average='macro')).mean()\n",
    "        # Accuracy when each chunk is treated as single document\n",
    "        # Chunk accuracy with sample weights returns book accuracy\n",
    "        # Chunk accuracy is the only choice for bookl-level features\n",
    "        chunk_acc = f1_score(df[\"y\"], df[\"yhat\"], average='macro')#, sample_weight = self._get_sample_weights(df))\n",
    "        return {\"mode_acc\": mode_acc, \"book_acc\": book_acc, \"chunk_acc\": chunk_acc}\n",
    "        \n",
    "    def run(self):\n",
    "        train_accs = []\n",
    "        validation_accs = []\n",
    "\n",
    "        df = self.df\n",
    "        df = self._combine_df_labels(df)\n",
    "        book_names_split = self._split_booknames(df, 5)\n",
    "        all_validation_books = []\n",
    "\n",
    "        for index, split in enumerate(book_names_split):\n",
    "            train_df = df[~df[\"book_name\"].isin(split)]\n",
    "            validation_df = df[df[\"book_name\"].isin(split)]\n",
    "            \n",
    "            train_X = train_df.drop(columns=[\"y\", \"book_name\"]).values\n",
    "            train_y = train_df[\"y\"].values.ravel()\n",
    "            validation_X = validation_df.drop(columns=[\"y\", \"book_name\"]).values\n",
    "            validation_y = validation_df[\"y\"].values.ravel()\n",
    "            train_X, validation_X = self._impute(train_X, validation_X)\n",
    "            #if self.verbose:\n",
    "            #    print(f\"train_X.shape before {self.dimensionality_reduction}: {train_X.shape}, validation_X.shape before {self.dimensionality_reduction}: {validation_X.shape}\")\n",
    "            train_X, validation_X = self._select_features(train_X, train_y, validation_X)\n",
    "            #if self.verbose:\n",
    "            #    print(f\"train_X.shape after {self.dimensionality_reduction}: {train_X.shape}, validation_X.shape after {self.dimensionality_reduction}: {validation_X.shape}\")\n",
    "            model = SVC(C=self.model_param, class_weight='balanced')\n",
    "            model.fit(train_X, train_y)\n",
    "            \n",
    "            train_books = deepcopy(train_df[[\"book_name\", \"y\"]])\n",
    "            train_books[\"yhat\"] = model.predict(train_X)\n",
    "            train_acc = self._aggregate_chunk_predictions(train_books)\n",
    "            validation_books = deepcopy(validation_df[[\"book_name\", \"y\"]])\n",
    "            validation_books[\"yhat\"] = model.predict(validation_X)\n",
    "            validation_acc = self._aggregate_chunk_predictions(validation_books)\n",
    "            all_validation_books.append(validation_books)\n",
    "            \n",
    "            train_accs.append(train_acc)\n",
    "            validation_accs.append(validation_acc)\n",
    "            if self.verbose:\n",
    "                print(f\"Fold: {index+1}, TrainAcc: {np.round(train_acc, 3)}, ValAcc: {np.round(validation_acc, 3)}\")\n",
    "        \n",
    "        # Save y and y_pred for examples\n",
    "        all_validation_books = pd.concat(all_validation_books)\n",
    "        all_validation_books.to_csv(results_dir + \"/valiationbooks-class-\" + self.language + \"-\" + self.datetime + \".csv\", index=False)\n",
    "        \n",
    "        print(confusion_matrix(all_validation_books[\"y\"], all_validation_books[\"yhat\"]))\n",
    "        print(pd.crosstab(all_validation_books[\"y\"], all_validation_books[\"yhat\"], rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "        \n",
    "        \n",
    "        train_accs = pd.DataFrame(train_accs)\n",
    "        validation_accs = pd.DataFrame(validation_accs)\n",
    "        \n",
    "        mean_train_mode_acc = train_accs[\"mode_acc\"].mean()\n",
    "        mean_train_book_acc = train_accs[\"book_acc\"].mean()\n",
    "        mean_train_chunk_acc = train_accs[\"chunk_acc\"].mean()\n",
    "        mean_validation_mode_acc = validation_accs[\"mode_acc\"].mean()\n",
    "        mean_validation_book_acc = validation_accs[\"book_acc\"].mean()\n",
    "        mean_validation_chunk_acc = validation_accs[\"chunk_acc\"].mean()\n",
    "        print(mean_train_chunk_acc)\n",
    "        print(mean_validation_chunk_acc)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\"\"TrainAcc: {np.round(mean_train_acc, 3)}, ValidationAcc: {np.round(mean_validation_acc, 3)}\"\"\")\n",
    "            print(\"\\n---------------------------------------------------\\n\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56c1f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop some columns by default before running cv\n",
    "def drop_default_columns(df, drop_default_columns_including):\n",
    "    def _drop_column(column):\n",
    "        for string in drop_default_columns_including:\n",
    "            if string in column:\n",
    "                return True\n",
    "    df = df[[column for column in df.columns if not _drop_column(column)]].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "### Cross-validation\n",
    "\n",
    "# Feature split\n",
    "complexity_features = []\n",
    "\n",
    "\n",
    "# Superfluous featues\n",
    "drop_default_columns_including = [\"average_sentence_embedding\", \"100_most_common_\", \"doc2vec_chunk_embedding\"]\n",
    "\n",
    "# All parameters\n",
    "models = [\"svr\", \"lasso\", \"xgboost\", \"svc\"]\n",
    "model_params = {\"svr\": [1], \"lasso\": [1, 4], \"xgboost\": [1, 4], \"svc\": [1]}\n",
    "dimensionality_reduction = [\"ss_pca_0_95\", 'k_best_f_reg_0_10', 'k_best_mutual_info_0_10', None]\n",
    "features = [\"book\", \"chunk\", \"book_and_averaged_chunk\", \"chunk_and_copied_book\"]\n",
    "\n",
    "# Which parameters to use\n",
    "full_cv_params = {\"model\": models, \"dimensionality_reduction\": dimensionality_reduction, \"features\": features}\n",
    "testing_params = {\"model\": models[3], \"dimensionality_reduction\": dimensionality_reduction[3], \n",
    "                  \"features\": features[2]}\n",
    "# Old results from chr2021 paper\n",
    "eng_params = {\"model\": models[0], \"dimensionality_reduction\": dimensionality_reduction[0], \n",
    "                  \"features\": features[2], }, # svr, pca, book_and_average_chunk\n",
    "ger_params = {\"model\": models[0], \"dimensionality_reduction\": dimensionality_reduction[0], \n",
    "                  \"features\": features[1]}, # svr, pca, chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3a11a8",
   "metadata": {},
   "source": [
    "book_df = pd.read_csv(f\"{extracted_features_dir}{lang}/book_df.csv\")\n",
    "book_and_averaged_chunk_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/book_and_averaged_chunk_df.csv\")\n",
    "chunk_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/chunk_df.csv\")\n",
    "chunk_and_copied_book_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/chunk_and_copied_book_df.csv\")\n",
    "book_df = drop_default_columns(book_df, drop_default_columns_including)\n",
    "book_and_averaged_chunk_df = drop_default_columns(book_and_averaged_chunk_df, drop_default_columns_including)\n",
    "chunk_df = drop_default_columns(chunk_df, drop_default_columns_including)\n",
    "chunk_and_copied_book_df = drop_default_columns(chunk_and_copied_book_df, drop_default_columns_including)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff09a045",
   "metadata": {},
   "source": [
    "print(len(book_df.columns), len(book_and_averaged_chunk_df.columns),len(chunk_df.columns),len(chunk_and_copied_book_df.columns),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c542ff4",
   "metadata": {},
   "source": [
    "len(list(book_and_averaged_chunk_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46b3cb2",
   "metadata": {},
   "source": [
    "for i in list(book_and_averaged_chunk_df.columns):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e4e21fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng svc book_and_averaged_chunk [] None param= 1\n",
      "labels value count 3.0    113\n",
      "2.0     63\n",
      "1.0     15\n",
      "Name: y, dtype: int64\n",
      "labels value count 0.0    415\n",
      "3.0    113\n",
      "2.0     63\n",
      "1.0     15\n",
      "Name: y, dtype: int64\n",
      "labels value count 0.0    378\n",
      "3.0    113\n",
      "2.0     63\n",
      "1.0     15\n",
      "Name: y, dtype: int64\n",
      "[[ 64 110 145  59]\n",
      " [  2   2  10   1]\n",
      " [  5  14  33  11]\n",
      " [  7  34  57  15]]\n",
      "Predicted  0.0  1.0  2.0  3.0  All\n",
      "True                              \n",
      "0.0         64  110  145   59  378\n",
      "1.0          2    2   10    1   15\n",
      "2.0          5   14   33   11   63\n",
      "3.0          7   34   57   15  113\n",
      "All         78  160  245   86  569\n",
      "0.16720797799473958\n",
      "0.14239139906010884\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "param_dict = \"testing\" #\"full_cv\", \"language_specific\"\n",
    "for lang in [\"eng\"]: #, \"ger\"]:    \n",
    "    if param_dict==\"testing\":\n",
    "        param_dir = testing_params\n",
    "    elif param_dict==\"full_cv\":\n",
    "        param_dir = full_cv_params\n",
    "    elif param_dict==\"language_specific\":\n",
    "        if lang==\"eng\":\n",
    "            param_dir = eng_params\n",
    "        else: \n",
    "            param_dir = ger_params\n",
    "    \n",
    "    #Eng: 606 books, 14146 chunks, 13170 chunks of books published after 1759\n",
    "    #book_df = pd.read_csv(f\"{extracted_features_dir}{lang}/book_df.csv\")\n",
    "    book_and_averaged_chunk_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/book_and_averaged_chunk_df.csv\")\n",
    "    #chunk_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/chunk_df.csv\")\n",
    "    chunk_and_copied_book_df = pd.read_csv(f\"{extracted_features_dir}/{lang}/chunk_and_copied_book_df.csv\")\n",
    "    \n",
    "    #book_df = drop_default_columns(book_df, drop_default_columns_including)\n",
    "    book_and_averaged_chunk_df = drop_default_columns(book_and_averaged_chunk_df, drop_default_columns_including)\n",
    "    #chunk_df = drop_default_columns(chunk_df, drop_default_columns_including)\n",
    "    chunk_and_copied_book_df = drop_default_columns(chunk_and_copied_book_df, drop_default_columns_including)\n",
    "    \n",
    "    for model in [] + [param_dir['model']]:\n",
    "        model_param = model_params[model]\n",
    "        for model_param in model_param:\n",
    "            for dimensionality_reduction in [param_dir[\"dimensionality_reduction\"]]:\n",
    "                for features in [param_dir[\"features\"]]:\n",
    "                    for drop_columns_including in [[]]:\n",
    "                        if model == \"svc\":\n",
    "                            experiment = MulticlassClassification(\n",
    "                                language=lang,\n",
    "                                features=features,\n",
    "                                drop_columns_including=drop_columns_including,\n",
    "                                dimensionality_reduction=dimensionality_reduction,\n",
    "                                model_param=model_param,\n",
    "                                model=model,\n",
    "                                verbose=False\n",
    "                            )\n",
    "                            print(lang, model, features, drop_columns_including, dimensionality_reduction, 'param=', model_param)\n",
    "                            classification_results = experiment.run()\n",
    "                            #results.append((lang, model, features, drop_columns_including, dimensionality_reduction, model_param, mean_train_acc, mean_validation_acc))\n",
    "                            \n",
    "                            ########################################\n",
    "                            #Library\n",
    "#                             experiment = LibraryClassification(\n",
    "#                                 language=lang,\n",
    "#                                 features=features,\n",
    "#                                 drop_columns_including=drop_columns_including,\n",
    "#                                 dimensionality_reduction=dimensionality_reduction,\n",
    "#                                 model_param=model_param,\n",
    "#                                 model=model,\n",
    "#                                 verbose=False\n",
    "#                             )\n",
    "                            #################################################\n",
    "                            \n",
    "                        else:\n",
    "                            #try:\n",
    "                            experiment = Regression(\n",
    "                                language=lang,\n",
    "                                features=features,\n",
    "                                drop_columns_including=drop_columns_including,\n",
    "                                dimensionality_reduction=dimensionality_reduction,\n",
    "                                model_param=model_param,\n",
    "                                model=model,\n",
    "                                verbose=True\n",
    "                            )\n",
    "                            print(lang, model, features, drop_columns_including, dimensionality_reduction, 'param=', model_param)\n",
    "                            mean_train_mse, mean_train_rmse, mean_train_mae, mean_train_r2, mean_train_corr, mean_validation_mse, mean_validation_rmse, mean_validation_mae, mean_validation_r2, mean_validation_corr, mean_p_value, datetime = experiment.run()\n",
    "                            results.append((lang, model, features, drop_columns_including, dimensionality_reduction, model_param, mean_train_mse, mean_train_rmse, mean_train_mae, mean_train_r2, mean_train_corr, mean_validation_mse, mean_validation_rmse, mean_validation_mae, mean_validation_r2, mean_validation_corr, mean_p_value))\n",
    "\n",
    "                            #except Exception as e:\n",
    "    #                             print(f\"Error in {lang}, {model}, {features}, {drop_columns_including}, {dimensionality_reduction}\")\n",
    "    #                             print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2103539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = pd.DataFrame(results, columns=[\"lang\", \"model\", \"features\", \"drop_columns_including\", \n",
    "#             \"dimensionality_reduction\", \"model_param\", \"mean_train_mse\", \"mean_train_rmse\", \n",
    "#             \"mean_train_mae\", \"mean_train_r2\", \"mean_train_corr\", \"mean_validation_mse\", \"mean_validation_rmse\",\n",
    "#             \"mean_validation_mae\", \"mean_validation_r2\", \"mean_validation_corr\", \"mean_p_value\"])\n",
    "# results_df.to_csv(results_dir + param_dict + datetime + \".csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
