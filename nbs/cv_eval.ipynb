{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b64b32c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (cv.py, line 649)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/annina/anaconda3/envs/nlp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3441\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-f2b425a7994e>\"\u001b[0;36m, line \u001b[0;32m30\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from cv import Regression, TwoclassClassification, LibraryClassification, MulticlassClassification\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"../src/cv.py\"\u001b[0;36m, line \u001b[0;32m649\u001b[0m\n\u001b[0;31m    all_validation_books.to_csv(f\"{results_dir}valiationbooks-{self.params_to_use}.csv\", index=False)\u001b[0m\n\u001b[0m                                                                                                             ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "lang = \"eng\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../src/\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "random.seed(2)\n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "from scipy.stats import pearsonr\n",
    "from math import sqrt\n",
    "import heapq\n",
    "import statistics\n",
    "get_ipython().run_line_magic(\"matplotlib\", \"inline\") # %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from utils import read_sentiment_scores, read_library_scores\n",
    "from cv import Regression, TwoclassClassification, LibraryClassification, MulticlassClassification\n",
    "\n",
    "features_dir = f\"../data/features-3/{lang}/\" ##############################\n",
    "results_dir = f\"../data/results_sentiment/classification_library/{lang}/\" ##############3############33\n",
    "sentiment_labels_dir = \"../data/labels_sentiment/\"\n",
    "canonization_labels_dir = \"../data/labels_canon/\"\n",
    "\n",
    "labels = read_sentiment_scores(sentiment_labels_dir, canonization_labels_dir, lang)\n",
    "library_scores = read_library_scores(sentiment_labels_dir, canonization_labels_dir, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2338fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48ece3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Labels statistics\n",
    "print(len(pd.unique(labels[\"book_name\"]))) #197\n",
    "# 254 labels, 197 different book_names -> 57 second/third... reviews\n",
    "# 36 book_names with more than 1 label, these 36 book_names have 93 labels\n",
    "# 93 = 36 first reviews + 57 second/third... reviews\n",
    "# 6 texts have opposing reviews (13 reviews are opposing)\n",
    "# 191 texts after aggregating (without opposing reviews)\n",
    "\n",
    "labels[\"y\"].plot.hist(grid=True, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94a35df",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Fehler\n",
    "Brooke_Frances_Emily_Montague_1769\n",
    "Lennox_Charlotte_The-Female_Quixote_1752\n",
    "Stoker_Bram-Dracula_1897\n",
    "\n",
    "Nicolai_Friedrich_Sebaldus-Nothanker-1773\n",
    "Jung-Stilling_Heinrich-Stillings-Jugend_1777\n",
    "Sacher-Masoch_Venus-im-Pelz_1869\n",
    "Hunold_Christian_Friedrich_Die-liebenswuerdige-Adalie_1681\n",
    "\n",
    "Hoffmansthal_Hugo ['Hoffmansthal_Hugo_Andreas-oder-die-Vereinigten_1907', 'Hoffmansthal_Hugo_Das-Maerchen-der-672-Nacht_1895'] \n",
    "Hoffmansthal_Hugo-von ['Hoffmansthal_Hugo-von_Ein-Brief_1902', 'Hoffmansthal_Hugo-von_Reitergeschichte_1899'] \n",
    "\n",
    "\n",
    "Anonymous anonymous\n",
    "\n",
    "df = df.loc[df[\"book_name\"] != \"Defoe_Daniel_Roxana_1724\"]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe2b3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parameter combinations\n",
    "'''\n",
    "langs = [\"eng\", \"ger\"]\n",
    "langs = [\"eng\"] ################################################3\n",
    "models = [\"svr\", \"lasso\", \"xgboost\", \"svc\"]\n",
    "model_params = {\"svr\": [1], \"lasso\": [1, 4], \"xgboost\": [None], \"svc\": [0.1, 1, 10, 100, 1000, 10000]} \n",
    "dimensionality_reduction = [\"ss_pca_0_95\", 'k_best_f_reg_0_10', 'k_best_mutual_info_0_10', [None]]\n",
    "features = [\"book\", \"chunk\", \"book_and_averaged_chunk\", \"chunk_and_copied_book\"]\n",
    "\n",
    "regression_dict = {\"model\": [\"xgboost\"], \n",
    "                     \"dimensionality_reduction\": dimensionality_reduction[-1], \n",
    "                     \"features\": [features[0]]}\n",
    "library_dict = {\"model\": [\"svc\", \"xgboost\"], \n",
    "                  \"dimensionality_reduction\": dimensionality_reduction[-1], \n",
    "                  \"features\": [\"book\", \"book_and_averaged_chunk\"]}\n",
    "twoclass_dict = {\"model\": [\"svc\", \"xgboost\"], \n",
    "                   \"dimensionality_reduction\": dimensionality_reduction[-1], \n",
    "                   \"features\": [\"book\", \"book_and_averaged_chunk\"]}\n",
    "multiclass_dict = {\"model\": [\"svc\", \"xgboost\"], \n",
    "                     \"dimensionality_reduction\": dimensionality_reduction[-1],\n",
    "                     \"features\": [\"book\", \"book_and_averaged_chunk\"]}\n",
    "testing_dict = {\"model\": models[3], \n",
    "                  \"dimensionality_reduction\": dimensionality_reduction[-1], \n",
    "                  \"features\": [\"book\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b617a236",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Run Cross-Validation\n",
    "'''\n",
    "results = []\n",
    "target = \"regression\" \n",
    "if target == \"regression\":\n",
    "    param_dict = regression_dict\n",
    "elif target = \"library\":\n",
    "    param_dict = library_dict\n",
    "elif target == \"twoclass\":\n",
    "    param_dict = twoclass_dict\n",
    "elif target == \"multiclass\":\n",
    "    param_dict = multiclass_dict\n",
    "elif target == \"testing\":\n",
    "    param_dict = testing_dict\n",
    "\n",
    "book_df = pd.read_csv(f\"{features_dir}book_df.csv\")\n",
    "book_and_averaged_chunk_df = pd.read_csv(f\"{features_dir}book_and_averaged_chunk_df.csv\")\n",
    "chunk_df = pd.read_csv(f\"{features_dir}chunk_df.csv\")\n",
    "chunk_and_copied_book_df = pd.read_csv(f\"{features_dir}chunk_and_copied_book_df.csv\")\n",
    "\n",
    "#Remove duplicate text\n",
    "book_df = book_df.loc[book_df[\"book_name\"] != \"Defoe_Daniel_Roxana_1724\"] ########################################\n",
    "book_and_averaged_chunk_df = book_and_averaged_chunk_df.loc[book_and_averaged_chunk_df[\"book_name\"] != \"Defoe_Daniel_Roxana_1724\"]\n",
    "chunk_df = chunk_df.loc[chunk_df[\"book_name\"] != \"Defoe_Daniel_Roxana_1724\"]\n",
    "chunk_and_copied_book_df = chunk_and_copied_book_df.loc[chunk_and_copied_book_df[\"book_name\"] != \"Defoe_Daniel_Roxana_1724\"]\n",
    "\n",
    "\n",
    "for lang in langs:\n",
    "    drop_columns_list = [\n",
    "        [\"average_sentence_embedding\", \"100_most_common_\", \"doc2vec_chunk_embedding\"],\n",
    "        [\"average_sentence_embedding\", \"100_most_common_\", \"doc2vec_chunk_embedding\", \"pos\"],\n",
    "        ]\n",
    "    if lang == \"eng\":\n",
    "        drop_columns_list.extend([\n",
    "            [\"average_sentence_embedding\", \"100_most_common_\", \"doc2vec_chunk_embedding\", \"->\"], \n",
    "            [\"average_sentence_embedding\", \"100_most_common_\", \"doc2vec_chunk_embedding\", \"->\", \"pos\"]\n",
    "        ])\n",
    "        \n",
    "    for model in [] + param_dict['model']:\n",
    "        model_param = model_params[model]\n",
    "        for model_param in model_param:\n",
    "            for dimensionality_reduction in param_dict[\"dimensionality_reduction\"]:\n",
    "                for features in param_dict[\"features\"]:\n",
    "                    for drop_columns in drop_columns_list:\n",
    "                        print(target, lang, model, features, drop_columns, dimensionality_reduction, 'param=', model_param)\n",
    "                        if target == 'regression':\n",
    "                            model_cols = [\n",
    "                                \"mean_train_mse\", \"mean_train_rmse\", \"mean_train_mae\", \"mean_train_r2\", \n",
    "                                \"mean_train_corr\", \"mean_validation_mse\", \"mean_validation_rmse\", \n",
    "                                \"mean_validation_mae\", \"mean_validation_r2\", \"mean_validation_corr\", \n",
    "                                \"mean_p_value\"]\n",
    "                            \n",
    "                            experiment = Regression(\n",
    "                                language=lang,\n",
    "                                features=features,\n",
    "                                drop_columns=drop_columns,\n",
    "                                dimensionality_reduction = dimensionality_reduction,\n",
    "                                model_param=model_param,\n",
    "                                model=model,\n",
    "                                verbose=True,\n",
    "                                target = target)\n",
    "                            \n",
    "                        if target ==\"library\":\n",
    "                            labels = library_scores####################################3\n",
    "                            model_cols = [\"mean_train_book_acc\", \"mean_validation_book_acc\"]\n",
    "                            experiment = LibraryClassification(\n",
    "                                language=lang,\n",
    "                                features=features,\n",
    "                                drop_columns=drop_columns,\n",
    "                                dimensionality_reduction=dimensionality_reduction,\n",
    "                                model_param=model_param,\n",
    "                                model=model,\n",
    "                                verbose=True,\n",
    "                                target = target)\n",
    "                            \n",
    "                        elif target == 'twoclass':\n",
    "                            model_cols = [\"mean_train_book_acc\", \"mean_validation_book_acc\"]\n",
    "                            experiment = TwoclassClassification(\n",
    "                                language=lang,\n",
    "                                features=features,\n",
    "                                drop_columns=drop_columns,\n",
    "                                dimensionality_reduction=dimensionality_reduction,\n",
    "                                model_param=model_param,\n",
    "                                model=model,\n",
    "                                verbose=True,\n",
    "                                target = target)\n",
    "                            \n",
    "                        elif target == 'multiclass':\n",
    "                            model_cols = [\"mean_train_f1\", \"mean_validation_f1\"]\n",
    "                            experiment = MulticlassClassification(\n",
    "                                language=lang,\n",
    "                                features=features,\n",
    "                                drop_columns=drop_columns,\n",
    "                                dimensionality_reduction=dimensionality_reduction,\n",
    "                                model_param=model_param,\n",
    "                                model=model,\n",
    "                                verbose=True,\n",
    "                                target = target)\n",
    "                            \n",
    "                        returned_results = experiment.run()\n",
    "                        results.append([lang, model, features, drop_columns, dimensionality_reduction, \n",
    "                                        model_param] + returned_results) \n",
    "                                        \n",
    "                        print(lang, model, features, drop_columns, dimensionality_reduction, model_param, \n",
    "                              returned_results)\n",
    "                        print('\\n-----------------------------------------------------------\\n')\n",
    "\n",
    "\n",
    "    results_df = pd.DataFrame(results, columns=['lang', 'model', \"features\", \"drop_columns\", \n",
    "                                                \"dimensionality_reduction\", \"model_param\"] + model_cols)\n",
    "    results_df.to_csv(f\"{results_dir}results-{lang}-{target}'.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb06cf62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f1fbc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6240b3be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ef4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
