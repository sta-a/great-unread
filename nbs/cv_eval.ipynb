{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a430d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "language = \"eng\"\n",
    "\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "sys.path.insert(0, \"../src/\")\n",
    "import os\n",
    "import pandas as pd\n",
    "get_ipython().run_line_magic(\"matplotlib\", \"inline\")\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from utils import get_labels\n",
    "from cross_validation import Regression, TwoclassClassification, MulticlassClassification\n",
    "\n",
    "features_dir = f\"../data/features/{language}/\"\n",
    "results_dir = f\"../data/results_sentiment/{language}/\"\n",
    "sentiment_labels_dir = \"../data/labels_sentiment/\"\n",
    "canonization_labels_dir = \"../data/labels_canon/\"##################1############3\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5456aa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels statistics\n",
    "# print(len(pd.unique(labels[\"book_name\"]))) #197\n",
    "# 254 labels, 197 different book_names -> 57 second/third... reviews\n",
    "# 36 book_names with more than 1 label, these 36 book_names have 93 labels\n",
    "# 93 = 36 first reviews + 57 second/third... reviews\n",
    "# 6 texts have opposing reviews (13 reviews are opposing)\n",
    "# 191 texts after aggregating (without opposing reviews)\n",
    "\n",
    "#classification_labels[\"y\"].plot.hist(grid=True, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "127ccd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parameter combinations\n",
    "'''\n",
    "\n",
    "textblob_labels = get_labels(language, sentiment_labels_dir, canonization_labels_dir, 'textblob')\n",
    "sentiart_labels = get_labels(language, sentiment_labels_dir, canonization_labels_dir, 'sentiart')\n",
    "combined_labels = get_labels(language, sentiment_labels_dir, canonization_labels_dir, 'combined')\n",
    "twoclass_labels = get_labels(language, sentiment_labels_dir, canonization_labels_dir, 'twoclass')\n",
    "multiclass_labels = get_labels(language, sentiment_labels_dir, canonization_labels_dir, 'multiclass')\n",
    "library_labels = get_labels(language, sentiment_labels_dir, canonization_labels_dir, 'library')\n",
    "           \n",
    "book_df = pd.read_csv(f\"{features_dir}book_df.csv\")\n",
    "book_and_averaged_chunk_df = pd.read_csv(f\"{features_dir}book_and_averaged_chunk_df.csv\")\n",
    "chunk_df = pd.read_csv(f\"{features_dir}chunk_df.csv\")\n",
    "chunk_and_copied_book_df = pd.read_csv(f\"{features_dir}chunk_and_copied_book_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4c763c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All parameters\n",
    "languages_list = [\"eng\", \"ger\"]\n",
    "models_list = [\"svr\", \"lasso\", \"xgboost\", \"svc\"]\n",
    "model_params_dict = {\"svr\": [1], \"lasso\": [1, 4], \"xgboost\": [None], \"svc\": [0.1, 1, 10, 100, 1000, 10000]} \n",
    "dimensionality_reduction_list = [\"ss_pca_0_95\", 'k_best_f_reg_0_10', 'k_best_mutual_info_0_10', None]\n",
    "features_list = [\"book\", \"chunk\", \"baac\", \"cacb\"]\n",
    "features_dict = {\"book\": book_df, \"chunk\": chunk_df, \"baac\": book_and_averaged_chunk_df, \n",
    "                 \"cacb\": chunk_and_copied_book_df}\n",
    "labels_list = ['textblob', 'sentiart', 'combined', 'twoclass', 'multiclass', 'library']\n",
    "labels_dict = {'textblob': textblob_labels, 'sentiart': sentiart_labels, 'combined': combined_labels, \n",
    "          'twoclass': twoclass_labels, 'multiclass': multiclass_labels, 'library': library_labels}\n",
    "\n",
    "\n",
    "drop_columns_list = [\n",
    "    [\"average_sentence_embedding\", \"doc2vec_chunk_embedding\"],\n",
    "    [\"average_sentence_embedding\", \"doc2vec_chunk_embedding\", \"pos\"]]\n",
    "if language == \"eng\":\n",
    "    drop_columns_list.extend([\n",
    "        [\"average_sentence_embedding\", \"doc2vec_chunk_embedding\", \"->\"], \n",
    "        [\"average_sentence_embedding\", \"doc2vec_chunk_embedding\", \"->\", \"pos\"]])\n",
    "    \n",
    "# Model-specific column names for writing results to file\n",
    "general_cols = ['language', 'task_type', 'model', 'model_param', 'labels_string', 'features_string',\n",
    "    'dimensionality_reduction', 'drop_columns']\n",
    "regression_cols = general_cols + [\"mean_train_mse\", \"mean_train_rmse\", \"mean_train_mae\", \"mean_train_r2\", \n",
    "    \"mean_train_corr\", \"mean_validation_mse\", \"mean_validation_rmse\", \"mean_validation_mae\", \n",
    "    \"mean_validation_r2\", \"mean_validation_corr\", \"mean_p_value\"]\n",
    "twoclass_cols = general_cols + [\"mean_train_book_acc\", \"mean_validation_book_acc\"] # also used for library\n",
    "multiclass_cols = general_cols + [\"mean_train_f1\", \"mean_validation_f1\"]\n",
    "\n",
    "\n",
    "# Link parameters to models\n",
    "regression_dict = {\n",
    "    \"model\": [\"xgboost\"], \n",
    "    \"dimensionality_reduction\": [None], \n",
    "    \"features\": features_list,\n",
    "    \"labels\": ['textblob', 'sentiart', 'combined'],\n",
    "    \"drop_columns\": drop_columns_list,\n",
    "    \"model_cols\": regression_cols}\n",
    "twoclass_dict = {\n",
    "    \"model\": [\"svc\", \"xgboost\"], \n",
    "    \"dimensionality_reduction\": [None], \n",
    "    \"features\": [\"book\", \"baac\"],\n",
    "    \"labels\": ['twoclass'],\n",
    "    \"drop_columns\": drop_columns_list,\n",
    "    \"model_cols\": twoclass_cols}\n",
    "library_dict = deepcopy(twoclass_dict)\n",
    "library_dict['labels'] = ['library']\n",
    "multiclass_dict = {\n",
    "    \"model\": [\"svc\", \"xgboost\"], \n",
    "    \"dimensionality_reduction\": [None],\n",
    "    \"features\": [\"book\", \"baac\"],\n",
    "    \"labels\": ['multiclass'],\n",
    "    \"drop_columns\": drop_columns_list,\n",
    "    \"model_cols\": multiclass_cols}\n",
    "\n",
    "testing_reg_dict = {\n",
    "    \"model\": [\"xgboost\"], \n",
    "    \"dimensionality_reduction\": [None], \n",
    "    \"features\": [\"book\"],\n",
    "    \"labels\": [\"combined\"],\n",
    "    \"drop_columns\": [drop_columns_list[-1]],\n",
    "    \"model_cols\": regression_cols}\n",
    "testing_twoclass_dict = {\n",
    "    \"model\": [\"xgboost\", 'svc'], #xgboost\n",
    "    \"dimensionality_reduction\": [None], \n",
    "    \"features\": [\"book\"], #\"baac\"\n",
    "    \"labels\": ['twoclass'],\n",
    "    \"drop_columns\": [drop_columns_list[-1]],\n",
    "    \"model_cols\": twoclass_cols}\n",
    "testing_multiclass_dict = {\n",
    "    \"model\": [\"xgboost\", 'svc'], #xgboost\n",
    "    \"dimensionality_reduction\": [None], \n",
    "    \"features\": [\"book\"], #\"baac\"\n",
    "    \"labels\": ['multiclass'],\n",
    "    \"drop_columns\": [drop_columns_list[-1]],\n",
    "    \"model_cols\": multiclass_cols}\n",
    "testing_library_dict = deepcopy(testing_twoclass_dict)\n",
    "testing_library_dict['labels'] = ['library']\n",
    "\n",
    "best_results_regression_eng_dict = {\n",
    "    \"model\": [\"xgboost\"], \n",
    "    \"dimensionality_reduction\": [None], \n",
    "    \"features\": [\"book\"], #\"baac\"\n",
    "    \"labels\": ['sentiart'],\n",
    "    \"drop_columns\": [['average_sentence_embedding', 'doc2vec_chunk_embedding', 'pos']],\n",
    "    \"model_cols\": regression_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2911327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Run Cross-Validation\n",
    "'''  \n",
    "task_type = \"library\" \n",
    "if task_type == \"regression\":\n",
    "    param_dict = regression_dict\n",
    "elif task_type == \"library\":\n",
    "    param_dict = library_dict\n",
    "elif task_type == \"twoclass\":\n",
    "    param_dict = twoclass_dict\n",
    "elif task_type == \"multiclass\":\n",
    "    param_dict = multiclass_dict\n",
    "\n",
    "# # Overwrite for testing ##########################################################\n",
    "# if task_type == 'twoclass':\n",
    "#     param_dict = testing_twoclass_dict\n",
    "# elif task_type == \"multiclass\":\n",
    "#     param_dict = testing_multiclass_dict\n",
    "# elif task_type == 'library':\n",
    "#     param_dict = testing_library_dict\n",
    "if task_type == \"regression\":\n",
    "    param_dict = best_results_regression_eng_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad36aba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ['svc', 'xgboost'],\n",
       " 'dimensionality_reduction': [None],\n",
       " 'features': ['book', 'baac'],\n",
       " 'labels': ['library'],\n",
       " 'drop_columns': [['average_sentence_embedding', 'doc2vec_chunk_embedding'],\n",
       "  ['average_sentence_embedding', 'doc2vec_chunk_embedding', 'pos'],\n",
       "  ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->'],\n",
       "  ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->', 'pos']],\n",
       " 'model_cols': ['language',\n",
       "  'task_type',\n",
       "  'model',\n",
       "  'model_param',\n",
       "  'labels_string',\n",
       "  'features_string',\n",
       "  'dimensionality_reduction',\n",
       "  'drop_columns',\n",
       "  'mean_train_book_acc',\n",
       "  'mean_validation_book_acc']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b256771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'library'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c61b47cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3addad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng library svc 0.1 library book None ['average_sentence_embedding', 'doc2vec_chunk_embedding']\n",
      "Dropped 0 columns.\n",
      "rarest label is  1\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    34\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    36\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    30\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    95\n",
      "0    22\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    24\n",
      "Name: y, dtype: int64\n",
      "--------------------------\n",
      "Crosstab\n",
      " Predicted    0    1  All\n",
      "True                    \n",
      "0          117   29  146\n",
      "1          253  204  457\n",
      "All        370  233  603 \n",
      "--------------------------\n",
      "all columns ['eng', 'library', 'svc', 0.1, 'library', 'book', None, ['average_sentence_embedding', 'doc2vec_chunk_embedding'], 0.542, 0.532]\n",
      "eng library svc 0.1 library book None ['average_sentence_embedding', 'doc2vec_chunk_embedding'] [0.542, 0.532]\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "2.52931547164917\n",
      "eng library svc 0.1 library book None ['average_sentence_embedding', 'doc2vec_chunk_embedding', 'pos']\n",
      "Dropped 0 columns.\n",
      "rarest label is  1\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    34\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    36\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    30\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    95\n",
      "0    22\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    24\n",
      "Name: y, dtype: int64\n",
      "--------------------------\n",
      "Crosstab\n",
      " Predicted    0    1  All\n",
      "True                    \n",
      "0          117   29  146\n",
      "1          253  204  457\n",
      "All        370  233  603 \n",
      "--------------------------\n",
      "all columns ['eng', 'library', 'svc', 0.1, 'library', 'book', None, ['average_sentence_embedding', 'doc2vec_chunk_embedding', 'pos'], 0.542, 0.532]\n",
      "eng library svc 0.1 library book None ['average_sentence_embedding', 'doc2vec_chunk_embedding', 'pos'] [0.542, 0.532]\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "2.1262781620025635\n",
      "eng library svc 0.1 library book None ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->']\n",
      "Dropped 0 columns.\n",
      "rarest label is  1\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    34\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    36\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    30\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    95\n",
      "0    22\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    24\n",
      "Name: y, dtype: int64\n",
      "--------------------------\n",
      "Crosstab\n",
      " Predicted    0    1  All\n",
      "True                    \n",
      "0          117   29  146\n",
      "1          253  204  457\n",
      "All        370  233  603 \n",
      "--------------------------\n",
      "all columns ['eng', 'library', 'svc', 0.1, 'library', 'book', None, ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->'], 0.542, 0.532]\n",
      "eng library svc 0.1 library book None ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->'] [0.542, 0.532]\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "2.259620428085327\n",
      "eng library svc 0.1 library book None ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->', 'pos']\n",
      "Dropped 0 columns.\n",
      "rarest label is  1\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    34\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    36\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    30\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    95\n",
      "0    22\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    24\n",
      "Name: y, dtype: int64\n",
      "--------------------------\n",
      "Crosstab\n",
      " Predicted    0    1  All\n",
      "True                    \n",
      "0          117   29  146\n",
      "1          253  204  457\n",
      "All        370  233  603 \n",
      "--------------------------\n",
      "all columns ['eng', 'library', 'svc', 0.1, 'library', 'book', None, ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->', 'pos'], 0.542, 0.532]\n",
      "eng library svc 0.1 library book None ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->', 'pos'] [0.542, 0.532]\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "2.337552785873413\n",
      "eng library svc 0.1 library baac None ['average_sentence_embedding', 'doc2vec_chunk_embedding']\n",
      "Dropped 0 columns.\n",
      "rarest label is  1\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    34\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    36\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    30\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    95\n",
      "0    22\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    24\n",
      "Name: y, dtype: int64\n",
      "--------------------------\n",
      "Crosstab\n",
      " Predicted    0    1  All\n",
      "True                    \n",
      "0          117   29  146\n",
      "1          252  205  457\n",
      "All        369  234  603 \n",
      "--------------------------\n",
      "all columns ['eng', 'library', 'svc', 0.1, 'library', 'baac', None, ['average_sentence_embedding', 'doc2vec_chunk_embedding'], 0.542, 0.534]\n",
      "eng library svc 0.1 library baac None ['average_sentence_embedding', 'doc2vec_chunk_embedding'] [0.542, 0.534]\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "3.323134660720825\n",
      "eng library svc 0.1 library baac None ['average_sentence_embedding', 'doc2vec_chunk_embedding', 'pos']\n",
      "Dropped 0 columns.\n",
      "rarest label is  1\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    34\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    36\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    30\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    95\n",
      "0    22\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    24\n",
      "Name: y, dtype: int64\n",
      "--------------------------\n",
      "Crosstab\n",
      " Predicted    0    1  All\n",
      "True                    \n",
      "0          117   29  146\n",
      "1          253  204  457\n",
      "All        370  233  603 \n",
      "--------------------------\n",
      "all columns ['eng', 'library', 'svc', 0.1, 'library', 'baac', None, ['average_sentence_embedding', 'doc2vec_chunk_embedding', 'pos'], 0.542, 0.532]\n",
      "eng library svc 0.1 library baac None ['average_sentence_embedding', 'doc2vec_chunk_embedding', 'pos'] [0.542, 0.532]\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "2.6879241466522217\n",
      "eng library svc 0.1 library baac None ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->']\n",
      "Dropped 0 columns.\n",
      "rarest label is  1\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    34\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    36\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    30\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    95\n",
      "0    22\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    24\n",
      "Name: y, dtype: int64\n",
      "--------------------------\n",
      "Crosstab\n",
      " Predicted    0    1  All\n",
      "True                    \n",
      "0          117   29  146\n",
      "1          253  204  457\n",
      "All        370  233  603 \n",
      "--------------------------\n",
      "all columns ['eng', 'library', 'svc', 0.1, 'library', 'baac', None, ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->'], 0.542, 0.532]\n",
      "eng library svc 0.1 library baac None ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->'] [0.542, 0.532]\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "3.062469244003296\n",
      "eng library svc 0.1 library baac None ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->', 'pos']\n",
      "Dropped 0 columns.\n",
      "rarest label is  1\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    34\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    36\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    30\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    95\n",
      "0    22\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    24\n",
      "Name: y, dtype: int64\n",
      "--------------------------\n",
      "Crosstab\n",
      " Predicted    0    1  All\n",
      "True                    \n",
      "0          117   29  146\n",
      "1          253  204  457\n",
      "All        370  233  603 \n",
      "--------------------------\n",
      "all columns ['eng', 'library', 'svc', 0.1, 'library', 'baac', None, ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->', 'pos'], 0.542, 0.532]\n",
      "eng library svc 0.1 library baac None ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->', 'pos'] [0.542, 0.532]\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "2.38567852973938\n",
      "eng library svc 1 library book None ['average_sentence_embedding', 'doc2vec_chunk_embedding']\n",
      "Dropped 0 columns.\n",
      "rarest label is  1\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    34\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    36\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    30\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    95\n",
      "0    22\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    24\n",
      "Name: y, dtype: int64\n",
      "--------------------------\n",
      "Crosstab\n",
      " Predicted    0    1  All\n",
      "True                    \n",
      "0          117   29  146\n",
      "1          258  199  457\n",
      "All        375  228  603 \n",
      "--------------------------\n",
      "all columns ['eng', 'library', 'svc', 1, 'library', 'book', None, ['average_sentence_embedding', 'doc2vec_chunk_embedding'], 0.541, 0.524]\n",
      "eng library svc 1 library book None ['average_sentence_embedding', 'doc2vec_chunk_embedding'] [0.541, 0.524]\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "2.852135181427002\n",
      "eng library svc 1 library book None ['average_sentence_embedding', 'doc2vec_chunk_embedding', 'pos']\n",
      "Dropped 0 columns.\n",
      "rarest label is  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    34\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    36\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    30\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    95\n",
      "0    22\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    24\n",
      "Name: y, dtype: int64\n",
      "--------------------------\n",
      "Crosstab\n",
      " Predicted    0    1  All\n",
      "True                    \n",
      "0          117   29  146\n",
      "1          258  199  457\n",
      "All        375  228  603 \n",
      "--------------------------\n",
      "all columns ['eng', 'library', 'svc', 1, 'library', 'book', None, ['average_sentence_embedding', 'doc2vec_chunk_embedding', 'pos'], 0.541, 0.524]\n",
      "eng library svc 1 library book None ['average_sentence_embedding', 'doc2vec_chunk_embedding', 'pos'] [0.541, 0.524]\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "2.526721954345703\n",
      "eng library svc 1 library book None ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->']\n",
      "Dropped 0 columns.\n",
      "rarest label is  1\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    34\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    36\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    30\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    95\n",
      "0    22\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    24\n",
      "Name: y, dtype: int64\n",
      "--------------------------\n",
      "Crosstab\n",
      " Predicted    0    1  All\n",
      "True                    \n",
      "0          117   29  146\n",
      "1          258  199  457\n",
      "All        375  228  603 \n",
      "--------------------------\n",
      "all columns ['eng', 'library', 'svc', 1, 'library', 'book', None, ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->'], 0.541, 0.524]\n",
      "eng library svc 1 library book None ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->'] [0.541, 0.524]\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "2.6936724185943604\n",
      "eng library svc 1 library book None ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->', 'pos']\n",
      "Dropped 0 columns.\n",
      "rarest label is  1\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    34\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    36\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    30\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    95\n",
      "0    22\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    24\n",
      "Name: y, dtype: int64\n",
      "--------------------------\n",
      "Crosstab\n",
      " Predicted    0    1  All\n",
      "True                    \n",
      "0          117   29  146\n",
      "1          258  199  457\n",
      "All        375  228  603 \n",
      "--------------------------\n",
      "all columns ['eng', 'library', 'svc', 1, 'library', 'book', None, ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->', 'pos'], 0.541, 0.524]\n",
      "eng library svc 1 library book None ['average_sentence_embedding', 'doc2vec_chunk_embedding', '->', 'pos'] [0.541, 0.524]\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "2.3597567081451416\n",
      "eng library svc 1 library baac None ['average_sentence_embedding', 'doc2vec_chunk_embedding']\n",
      "Dropped 0 columns.\n",
      "rarest label is  1\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    34\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    36\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    87\n",
      "0    30\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    95\n",
      "0    22\n",
      "Name: y, dtype: int64\n",
      "labels per split\n",
      "\n",
      " 1    94\n",
      "0    24\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "with open(f\"{results_dir}results-{language}-{task_type}-log.csv\", 'a') as f:\n",
    "    f.write(\"\\t\".join(param_dict['model_cols']) + '\\n')\n",
    "for model in param_dict['model']:\n",
    "    model_param = model_params_dict[model]\n",
    "    for model_param in model_param:\n",
    "        for labels_string in param_dict['labels']:\n",
    "            labels = deepcopy(labels_dict[labels_string])\n",
    "            for features_string in param_dict[\"features\"]:\n",
    "                df = deepcopy(features_dict[features_string])\n",
    "                for dimensionality_reduction in param_dict[\"dimensionality_reduction\"]:\n",
    "                    for drop_columns in param_dict[\"drop_columns\"]:\n",
    "                        print(language, task_type, model, model_param, labels_string, features_string,\n",
    "                            dimensionality_reduction, drop_columns)\n",
    "                        inner_start = time.time()\n",
    "                        if task_type == 'regression':\n",
    "                            experiment = Regression(\n",
    "                                results_dir=results_dir,\n",
    "                                language=language,\n",
    "                                task_type=task_type,\n",
    "                                model=model,\n",
    "                                model_param=model_param,\n",
    "                                labels_string=labels_string,\n",
    "                                labels=labels,\n",
    "                                features_string=features_string,\n",
    "                                df=df,\n",
    "                                dimensionality_reduction=dimensionality_reduction,\n",
    "                                drop_columns=drop_columns,\n",
    "                                verbose=True)\n",
    "\n",
    "                        elif (task_type == 'twoclass') or (task_type == 'library'):\n",
    "                            experiment = TwoclassClassification(\n",
    "                                results_dir=results_dir,\n",
    "                                language=language,\n",
    "                                task_type=task_type,\n",
    "                                model=model,\n",
    "                                model_param=model_param,\n",
    "                                labels_string=labels_string,\n",
    "                                labels=labels,\n",
    "                                features_string=features_string,\n",
    "                                df=df,\n",
    "                                dimensionality_reduction=dimensionality_reduction,\n",
    "                                drop_columns=drop_columns,\n",
    "                                verbose=True)\n",
    "\n",
    "                        elif task_type == 'multiclass':\n",
    "                            experiment = MulticlassClassification(\n",
    "                                results_dir=results_dir,\n",
    "                                language=language,\n",
    "                                task_type=task_type,\n",
    "                                model=model,\n",
    "                                model_param=model_param,\n",
    "                                labels_string=labels_string,\n",
    "                                labels=labels,\n",
    "                                features_string=features_string,\n",
    "                                df=df,\n",
    "                                dimensionality_reduction=dimensionality_reduction,\n",
    "                                drop_columns=drop_columns,\n",
    "                                verbose=True)\n",
    "\n",
    "                        returned_values = experiment.run()\n",
    "                        all_columns = [language, task_type, model, model_param, labels_string, features_string,\n",
    "                                       dimensionality_reduction, drop_columns] + returned_values\n",
    "                        print('all columns', all_columns)\n",
    "                        \n",
    "                        with open(f\"{results_dir}results-{language}-{task_type}-log.csv\", 'a') as f:\n",
    "                            f.write(\"\\t\".join([str(x) for x in all_columns]) + '\\n')\n",
    "                            results.append(all_columns) \n",
    "\n",
    "                        print(language, task_type, model, model_param, labels_string, features_string,\n",
    "                                dimensionality_reduction, drop_columns, returned_values)\n",
    "                        print('\\n-----------------------------------------------------------\\n')\n",
    "                        inner_end = time.time()\n",
    "                        print(inner_end - inner_start)\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=param_dict['model_cols'])\n",
    "results_df.to_csv(f\"{results_dir}results-{language}-{task_type}-final.csv\", index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b935adde",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6c024e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3a01cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d9a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f5ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results\n",
    "#results_df = results_df.sort_values(by=[\"mean_validation_corr\", \"mean_p_value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec328d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_df = results_df[results_df[\"mean_p_value\"]<=0.1].sort_values(by=[\"mean_validation_corr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6bd172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee00aae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9656004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2cd679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd98959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7362d91d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d74664f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294f8a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
