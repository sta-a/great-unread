{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48086b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "lang = \"ger\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"../src/\")\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from feature_extraction.doc2vec_chunk_vectorizer import Doc2VecChunkVectorizer\n",
    "from feature_extraction.doc_based_feature_extractor import DocBasedFeatureExtractor\n",
    "from feature_extraction.corpus_based_feature_extractor import CorpusBasedFeatureExtractor\n",
    "from utils import get_doc_paths\n",
    "from chunk import Chunk\n",
    "import time\n",
    "\n",
    "raw_docs_dir = f\"../data/raw_docs/{lang}/\"\n",
    "labels_dir = \"../data/labels/\"\n",
    "features_dir = f\"../data/features/{lang}/\"\n",
    "\n",
    "if not os.path.exists(features_dir):\n",
    "    os.makedirs(features_dir)\n",
    "\n",
    "doc_paths = get_doc_paths(raw_docs_dir, lang)[:3]\n",
    "\n",
    "sentences_per_chunk = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "429ca3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create doc2vec embeddings\n",
    "# d2vcv =  (lang, sentences_per_chunk)\n",
    "# d2vcv.fit_transform(doc_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89f3c240",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6508d994",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]/home/annina/anaconda3/envs/nlp/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/annina/anaconda3/envs/nlp/lib/python3.9/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 3/3 [00:10<00:00,  3.34s/it]\n"
     ]
    }
   ],
   "source": [
    "## Document-based features\n",
    "document_chunk_features = []\n",
    "document_book_features = [] \n",
    "\n",
    "for doc_path in tqdm(doc_paths):\n",
    "    fe = DocBasedFeatureExtractor(lang, doc_path, sentences_per_chunk)\n",
    "    chunk_features, book_features = fe.get_all_features()  \n",
    "    document_chunk_features.extend(chunk_features)\n",
    "    document_book_features.append(book_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7db6734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:08<00:00,  2.74s/it]\n"
     ]
    }
   ],
   "source": [
    "# Recalculate the chunk features for the whole book, which is considered as one chunk\n",
    "document_chunk_features_fulltext = [] #Chunk features calculated for whole book\n",
    "\n",
    "for doc_path in tqdm(doc_paths):\n",
    "    fe = DocBasedFeatureExtractor(lang, doc_path, sentences_per_chunk=None)\n",
    "    chunk_features_fulltext, _ = fe.get_all_features()\n",
    "    document_chunk_features_fulltext.extend(chunk_features_fulltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ecfdc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle document-based features\n",
    "with open(features_dir + 'document_chunk_features' + '.pkl', 'wb') as f:\n",
    "    pickle.dump(document_chunk_features, f, -1)\n",
    "\n",
    "with open(features_dir + 'document_book_features' + '.pkl', 'wb') as f:\n",
    "    pickle.dump(document_book_features, f, -1)\n",
    "\n",
    "with open(features_dir + 'document_chunk_features_fulltext' + '.pkl', 'wb') as f:\n",
    "    pickle.dump(document_chunk_features_fulltext, f, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a71a8e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load document-based features  \n",
    "with open(features_dir + 'document_chunk_features' + '.pkl', 'rb') as f:\n",
    "    document_chunk_features = pickle.load(f)\n",
    "\n",
    "with open(features_dir + 'document_book_features' + '.pkl', 'rb') as f:\n",
    "    document_book_features = pickle.load(f)\n",
    "\n",
    "with open(features_dir + 'document_chunk_features_fulltext' + '.pkl', 'rb') as f:\n",
    "    document_chunk_features_fulltext = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e73136a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "## Corpus-based features\n",
    "cbfe = CorpusBasedFeatureExtractor(lang, doc_paths, sentences_per_chunk, nr_features=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ab3d69f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method CorpusBasedFeatureExtractor.get_unigram_distance of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe501743ca0>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:08<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for corpus_chunk_feature_mapping <bound method CorpusBasedFeatureExtractor.get_unigram_distance of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe501743ca0>>: 42.8352530002594\n",
      "<bound method CorpusBasedFeatureExtractor.get_unigram_distance_limited of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe501743ca0>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:05<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for corpus_chunk_feature_mapping <bound method CorpusBasedFeatureExtractor.get_unigram_distance_limited of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe501743ca0>>: 40.16433596611023\n",
      "<bound method CorpusBasedFeatureExtractor.get_bigram_distance of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe501743ca0>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.50s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for corpus_chunk_feature_mapping <bound method CorpusBasedFeatureExtractor.get_bigram_distance of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe501743ca0>>: 4.7468955516815186\n",
      "<bound method CorpusBasedFeatureExtractor.get_trigram_distance of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe501743ca0>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.59s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for corpus_chunk_feature_mapping <bound method CorpusBasedFeatureExtractor.get_trigram_distance of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe501743ca0>>: 4.976939678192139\n",
      "<bound method CorpusBasedFeatureExtractor.get_tag_distribution of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe501743ca0>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.38s/it]\n",
      "100%|██████████| 3/3 [00:04<00:00,  1.39s/it]\n",
      "100%|██████████| 3/3 [00:04<00:00,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for corpus_chunk_feature_mapping <bound method CorpusBasedFeatureExtractor.get_tag_distribution of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe501743ca0>>: 12.568570613861084\n",
      "Time for <bound method CorpusBasedFeatureExtractor.get_overlap_score_doc2vec of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe501743ca0>>: 0.001676321029663086\n",
      "Time for <bound method CorpusBasedFeatureExtractor.get_overlap_score_sbert of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe501743ca0>>: 0.003639698028564453\n",
      "Time for <bound method CorpusBasedFeatureExtractor.get_outlier_score_doc2vec of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe501743ca0>>: 0.0029480457305908203\n",
      "Time for <bound method CorpusBasedFeatureExtractor.get_outlier_score_sbert of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe501743ca0>>: 0.0029861927032470703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_chunk_features, corpus_book_features = cbfe.get_all_features()\n",
    "\n",
    "with open(features_dir + 'corpus_chunk_features' + '.pkl', 'wb') as f:\n",
    "    pickle.dump(corpus_chunk_features, f, -1)\n",
    "\n",
    "with open(features_dir + 'corpus_book_features' + '.pkl', 'wb') as f:\n",
    "    pickle.dump(corpus_book_features, f, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba5b045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.40s/it]\n"
     ]
    }
   ],
   "source": [
    "# # Recalculate the chunk features for the whole book, which is considered as one chunk\n",
    "cbfe_fulltext = CorpusBasedFeatureExtractor(lang, doc_paths, sentences_per_chunk=None, nr_features=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae90145a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method CorpusBasedFeatureExtractor.get_unigram_distance of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe4fece0c70>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:05<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for corpus_chunk_feature_mapping <bound method CorpusBasedFeatureExtractor.get_unigram_distance of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe4fece0c70>>: 39.06505727767944\n",
      "<bound method CorpusBasedFeatureExtractor.get_unigram_distance_limited of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe4fece0c70>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for corpus_chunk_feature_mapping <bound method CorpusBasedFeatureExtractor.get_unigram_distance_limited of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe4fece0c70>>: 40.08614683151245\n",
      "<bound method CorpusBasedFeatureExtractor.get_bigram_distance of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe4fece0c70>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.58s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for corpus_chunk_feature_mapping <bound method CorpusBasedFeatureExtractor.get_bigram_distance of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe4fece0c70>>: 4.98028302192688\n",
      "<bound method CorpusBasedFeatureExtractor.get_trigram_distance of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe4fece0c70>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.57s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for corpus_chunk_feature_mapping <bound method CorpusBasedFeatureExtractor.get_trigram_distance of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe4fece0c70>>: 4.917870044708252\n",
      "<bound method CorpusBasedFeatureExtractor.get_tag_distribution of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe4fece0c70>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.39s/it]\n",
      "100%|██████████| 3/3 [00:04<00:00,  1.44s/it]\n",
      "100%|██████████| 3/3 [00:04<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for corpus_chunk_feature_mapping <bound method CorpusBasedFeatureExtractor.get_tag_distribution of <feature_extraction.corpus_based_feature_extractor.CorpusBasedFeatureExtractor object at 0x7fe4fece0c70>>: 12.559510707855225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_chunk_features_fulltext, _ = cbfe_fulltext.get_all_features()\n",
    "with open(features_dir + 'corpus_chunk_features_fulltext' + '.pkl', 'wb') as f:\n",
    "    pickle.dump(corpus_chunk_features_fulltext, f, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "561c023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load corpus-based features  \n",
    "with open(features_dir + 'corpus_chunk_features' + '.pkl', 'rb') as f:\n",
    "    corpus_chunk_features = pickle.load(f)\n",
    "\n",
    "with open(features_dir + 'corpus_book_features' + '.pkl', 'rb') as f:\n",
    "    corpus_book_features = pickle.load(f)\n",
    "\n",
    "with open(features_dir + 'corpus_chunk_features_fulltext' + '.pkl', 'rb') as f:\n",
    "    corpus_chunk_features_fulltext = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76116d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_name</th>\n",
       "      <th>unigram_distance</th>\n",
       "      <th>unigram_distance_limited</th>\n",
       "      <th>bigram_distance</th>\n",
       "      <th>trigram_distance</th>\n",
       "      <th>pos_unigram_PUNCT</th>\n",
       "      <th>pos_unigram_NOUN</th>\n",
       "      <th>pos_unigram_ADV</th>\n",
       "      <th>pos_unigram_PRON</th>\n",
       "      <th>pos_unigram_DET</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_trigram_NOUN_ADV_ADV</th>\n",
       "      <th>pos_trigram_PUNCT_SCONJ_DET</th>\n",
       "      <th>pos_trigram_VERB_PUNCT_PUNCT</th>\n",
       "      <th>pos_trigram_PUNCT_ADV_PUNCT</th>\n",
       "      <th>pos_trigram_PRON_ADV_VERB</th>\n",
       "      <th>pos_trigram_ADP_NOUN_PUNCT</th>\n",
       "      <th>pos_trigram_BOS_BOS_ADP</th>\n",
       "      <th>pos_trigram_ADP_PRON_VERB</th>\n",
       "      <th>pos_trigram_VERB_PRON_DET</th>\n",
       "      <th>pos_trigram_VERB_PUNCT_CCONJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raabe_Wilhelm_Eine-Grabrede-aus-dem-Jahr-1609_...</td>\n",
       "      <td>0.082029</td>\n",
       "      <td>0.785397</td>\n",
       "      <td>0.011187</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.141230</td>\n",
       "      <td>0.176958</td>\n",
       "      <td>0.094498</td>\n",
       "      <td>0.071845</td>\n",
       "      <td>0.116246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003267</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>0.002765</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>0.007288</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>0.005026</td>\n",
       "      <td>0.003518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Moellhausen_Balduin_Die-Mandanen-Waise_1865</td>\n",
       "      <td>0.045865</td>\n",
       "      <td>0.625736</td>\n",
       "      <td>0.005807</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.151232</td>\n",
       "      <td>0.150216</td>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.106444</td>\n",
       "      <td>0.115176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.006359</td>\n",
       "      <td>0.004172</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.004476</td>\n",
       "      <td>0.004183</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>0.005152</td>\n",
       "      <td>0.005457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Conradi_Hermann_Adam-Mensch_1889</td>\n",
       "      <td>0.049122</td>\n",
       "      <td>0.858093</td>\n",
       "      <td>0.003680</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.200356</td>\n",
       "      <td>0.127888</td>\n",
       "      <td>0.138919</td>\n",
       "      <td>0.105587</td>\n",
       "      <td>0.088104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004870</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>0.005166</td>\n",
       "      <td>0.008709</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.003627</td>\n",
       "      <td>0.004009</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.003261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 222 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           book_name  unigram_distance  \\\n",
       "0  Raabe_Wilhelm_Eine-Grabrede-aus-dem-Jahr-1609_...          0.082029   \n",
       "1        Moellhausen_Balduin_Die-Mandanen-Waise_1865          0.045865   \n",
       "2                   Conradi_Hermann_Adam-Mensch_1889          0.049122   \n",
       "\n",
       "   unigram_distance_limited  bigram_distance  trigram_distance  \\\n",
       "0                  0.785397         0.011187          0.002480   \n",
       "1                  0.625736         0.005807          0.000905   \n",
       "2                  0.858093         0.003680          0.001020   \n",
       "\n",
       "   pos_unigram_PUNCT  pos_unigram_NOUN  pos_unigram_ADV  pos_unigram_PRON  \\\n",
       "0           0.141230          0.176958         0.094498          0.071845   \n",
       "1           0.151232          0.150216         0.103993          0.106444   \n",
       "2           0.200356          0.127888         0.138919          0.105587   \n",
       "\n",
       "   pos_unigram_DET  ...  pos_trigram_NOUN_ADV_ADV  \\\n",
       "0         0.116246  ...                  0.003267   \n",
       "1         0.115176  ...                  0.004431   \n",
       "2         0.088104  ...                  0.004870   \n",
       "\n",
       "   pos_trigram_PUNCT_SCONJ_DET  pos_trigram_VERB_PUNCT_PUNCT  \\\n",
       "0                     0.004021                      0.002765   \n",
       "1                     0.006359                      0.004172   \n",
       "2                     0.002371                      0.005166   \n",
       "\n",
       "   pos_trigram_PUNCT_ADV_PUNCT  pos_trigram_PRON_ADV_VERB  \\\n",
       "0                     0.001257                   0.004021   \n",
       "1                     0.001398                   0.004476   \n",
       "2                     0.008709                   0.004573   \n",
       "\n",
       "   pos_trigram_ADP_NOUN_PUNCT  pos_trigram_BOS_BOS_ADP  \\\n",
       "0                    0.007288                 0.011561   \n",
       "1                    0.004183                 0.004859   \n",
       "2                    0.004743                 0.003627   \n",
       "\n",
       "   pos_trigram_ADP_PRON_VERB  pos_trigram_VERB_PRON_DET  \\\n",
       "0                   0.004021                   0.005026   \n",
       "1                   0.004893                   0.005152   \n",
       "2                   0.004009                   0.003571   \n",
       "\n",
       "   pos_trigram_VERB_PUNCT_CCONJ  \n",
       "0                      0.003518  \n",
       "1                      0.005457  \n",
       "2                      0.003261  \n",
       "\n",
       "[3 rows x 222 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_chunk_features_fulltext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "713327fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1118) (60, 1110) (3, 2227) (60, 2227)\n",
      "True\n",
      "['doc2vec_stepwise_distance', 'sbert_stepwise_distance']\n",
      "True\n",
      "['doc2vec_stepwise_distance', 'sbert_stepwise_distance']\n",
      "False\n",
      "[]\n",
      "True\n",
      "['doc2vec_stepwise_distance', 'sbert_stepwise_distance']\n"
     ]
    }
   ],
   "source": [
    "# Book features\n",
    "document_book_features = pd.DataFrame(document_book_features)\n",
    "document_chunk_features_fulltext = pd.DataFrame(document_chunk_features_fulltext)\n",
    "book_df = document_book_features\\\n",
    "            .merge(right=document_chunk_features_fulltext, on='book_name', how='outer', validate='one_to_one')\\\n",
    "            .merge(right=corpus_book_features, on='book_name', validate='one_to_one')\\\n",
    "            .merge(right=corpus_chunk_features_fulltext, on='book_name', validate='one_to_one')\n",
    "\n",
    "# Chunk features\n",
    "document_chunk_features = pd.DataFrame(document_chunk_features)\n",
    "chunk_df = document_chunk_features.merge(right=corpus_chunk_features, on='book_name', how='outer', validate='one_to_one')\n",
    "chunk_df\n",
    "\n",
    "# Remove chunk id from book_name\n",
    "chunk_df['book_name'] = chunk_df['book_name'].str.split('_').str[:4].str.join('_')\n",
    "\n",
    "# Combine book features and averages of chunksaveraged chunk features\n",
    "book_and_averaged_chunk_df = book_df.merge(chunk_df.groupby(\"book_name\").mean().reset_index(drop=False), on=\"book_name\")\n",
    "book_and_averaged_chunk_df\n",
    "\n",
    "chunk_and_copied_book_df = chunk_df.merge(right=book_df, on='book_name', how='outer', validate='many_to_one')\n",
    "chunk_and_copied_book_df\n",
    "\n",
    "print(book_df.shape, chunk_df.shape, book_and_averaged_chunk_df.shape, chunk_and_copied_book_df.shape)\n",
    "\n",
    "dfs = {'book_df': book_df, 'book_and_averaged_chunk_df': book_and_averaged_chunk_df, 'chunk_df': chunk_df, 'chunk_and_copied_book_df': chunk_and_copied_book_df}\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    df = df.sort_values(by='book_name', axis=0, ascending=True, na_position='first')\n",
    "    df.to_csv(f\"{features_dir}{name}.csv\", index=False)\n",
    "    \n",
    "    print(df.isnull().values.any())\n",
    "    print(df.columns[df.isna().any()].tolist())\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cf2bec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238.25999474525452"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067b3038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfdd6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56fbfe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dde37d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf0d256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ce0ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
